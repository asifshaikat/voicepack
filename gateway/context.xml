This file is a merged representation of the entire codebase, combined into a single document by Repomix. The content has been processed where comments have been removed, empty lines have been removed, line numbers have been added, security check has been disabled.


<file_summary>
Code for  failover and HA for setup integrates WebRTC, SIP, OpenSIPS, RTPengine, and Asterisk, connecting internal WebRTC clients with external SIP trunks via UDP. Hereâ€™s a structured breakdown:

1. WebRTC-SIP Communication via WebSocket
Protocol: SIP over WebSocket (WSS) using OpenSIPS.

Security: TLS encryption for WebSocket connections.

WebSocket Server: OpenSIPS running on port 10443.

Client-side Implementation:

Built using React.js.

Uses SIP.js for SIP signaling and WebRTC for media.

Listens for SIP messages from OpenSIPS.

2. Media Handling with RTP Engine
RTP Handling: RTPengine relays media between WebRTC and SIP.

Function:

Translates WebRTC codecs (Opus, VP8, VP9).

Relays RTP streams between WebRTC and SIP trunks.

Ensures NAT traversal for WebRTC clients.

3. Backend SIP Server and Call Routing
SIP Proxy: OpenSIPS manages WebRTC-SIP signaling.

Call Processing:

Asterisk running on port 5060 (UDP).

Handles internal call logic, IVRs, voicemail, call recordings.

Interacts with SIP trunks for external calls.

4. SIP Trunking and External Communication
Trunk Configuration:

Asterisk connects to remote SIP providers via UDP on port 5060.

Supports inbound and outbound calls.

Handles codec negotiation between WebRTC clients and SIP trunks.

5. Node.js Backend for Call Control
Uses Asterisk Manager Interface (AMI):

Manages call routing, authentication, and call states.

Provides API endpoints for controlling calls (originate, hangup, transfer).

Logs call details for reporting and analytics.

Application Integration:

Node.js can enable WebRTC softphones, dashboards, and analytics tools.

Supports WebSocket-based real-time call event updates.

6. Call Flow Summary
WebRTC Client (React/SIP.js) registers with OpenSIPS via WebSocket (WSS on 10443).

OpenSIPS routes SIP signaling between WebRTC clients and Asterisk.

RTPengine handles media relay and codec conversion.

Asterisk (port 5060 UDP) processes calls:

Internal call logic.

Routes external calls via SIP trunk.

SIP Trunking (5060 UDP) connects Asterisk with external VoIP/PSTN providers.

Node.js Backend manages call control using Asterisk AMI.

<purpose>
This file contains a packed representation of the entire repository's contents.
to have the context of undertsanding the codebase and help me understand health function and monitoring and failover it is working for single backend but now i want to make it workable for multiple backend for high avialbility 
</purpose>

</file_summary>

<directory_structure>
gateway/
  cmd/
    gateway/
      main.go
  pkg/
    ami/
      ami.go
      manager.go
      proxy.go
    common/
      circuit_breaker.go
      context.go
      goroutine.go
      metrics.go
    config/
      config.go
    coordinator/
      coordination.go
    health/
      health.go
    rtpengine/
      manager.go
      rtpengine.go
    sip/
      proxy.go
      sip.go
    storage/
      memory.go
      storage.go
    websocket/
      server.go
  go.mod
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="gateway/cmd/gateway/main.go">
  1: package main
  2: import (
  3: 	"context"
  4: 	"encoding/json"
  5: 	"errors"
  6: 	"flag"
  7: 	"net/http"
  8: 	"os"
  9: 	"os/signal"
 10: 	"runtime"
 11: 	"strings"
 12: 	"syscall"
 13: 	"time"
 14: 	"go.uber.org/zap"
 15: 	"go.uber.org/zap/zapcore"
 16: 	"gateway/pkg/ami"
 17: 	"gateway/pkg/common"
 18: 	"gateway/pkg/config"
 19: 	"gateway/pkg/coordinator"
 20: 	"gateway/pkg/health"
 21: 	"gateway/pkg/rtpengine"
 22: 	"gateway/pkg/sip"
 23: 	"gateway/pkg/storage"
 24: 	"gateway/pkg/websocket"
 25: )
 26: func main() {
 27: 	logger := setupLogger("info")
 28: 	defer logger.Sync()
 29: 	configPath := flag.String("config", "config.yaml", "Path to configuration file")
 30: 	flag.Parse()
 31: 	logger.Info("program starting",
 32: 		zap.String("config_path", *configPath))
 33: 	cfg, err := config.LoadConfig(*configPath)
 34: 	if err != nil {
 35: 		logger.Fatal("failed to load configuration",
 36: 			zap.Error(err))
 37: 	}
 38: 	logger.Info("configuration loaded",
 39: 		zap.Bool("sip_processing_disabled", cfg.SIP.DisableSIPProcessing))
 40: 		sipCfg := sip.SIPConfig{
 41: 			UDPBindAddr:             cfg.SIP.UDPBindAddr,
 42: 			ProxyURI:                cfg.SIP.ProxyURI,
 43: 			DefaultNextHop:          cfg.SIP.DefaultNextHop,
 44: 			MaxForwards:             cfg.SIP.MaxForwards,
 45: 			UserAgent:               cfg.SIP.UserAgent,
 46: 			DisableUDPSIPProcessing: cfg.SIP.DisableUDPSIPProcessing,
 47: 			DisableWSSIPProcessing:  cfg.SIP.DisableWSSIPProcessing,
 48: 		}
 49: 		logger.Info("SIP configuration prepared",
 50: 		zap.String("UDPBindAddr", sipCfg.UDPBindAddr),
 51: 		zap.String("DefaultNextHop", sipCfg.DefaultNextHop),
 52: 		zap.Bool("DisableUDPSIPProcessing", sipCfg.DisableUDPSIPProcessing),
 53: 		zap.Bool("DisableWSSIPProcessing", sipCfg.DisableWSSIPProcessing))
 54: 	logger.Info("creating storage")
 55: 	var stateStorage storage.StateStorage
 56: 	if cfg.Redis.Enabled {
 57: 		logger.Info("Redis storage not implemented; using in-memory storage")
 58: 		stateStorage, err = storage.NewMemoryStorage(storage.MemoryConfig{
 59: 			MaxKeys:         cfg.MemoryStorage.MaxKeys,
 60: 			CleanupInterval: time.Duration(cfg.MemoryStorage.CleanupIntervalSeconds) * time.Second,
 61: 			PersistPath:     cfg.MemoryStorage.PersistPath,
 62: 		}, logger)
 63: 	} else {
 64: 		logger.Info("creating in-memory storage",
 65: 			zap.String("path", cfg.MemoryStorage.PersistPath))
 66: 		stateStorage, err = storage.NewMemoryStorage(storage.MemoryConfig{
 67: 			MaxKeys:         cfg.MemoryStorage.MaxKeys,
 68: 			CleanupInterval: time.Duration(cfg.MemoryStorage.CleanupIntervalSeconds) * time.Second,
 69: 			PersistPath:     cfg.MemoryStorage.PersistPath,
 70: 		}, logger)
 71: 	}
 72: 	if err != nil {
 73: 		logger.Fatal("failed to create storage", zap.Error(err))
 74: 	}
 75: 	logger.Info("storage created successfully")
 76: 	ctx := context.Background()
 77: 	logger.Info("background context created")
 78: 	logger.Info("creating coordinator")
 79: 	coordinator, err := coordinator.NewCoordinator(stateStorage, coordinator.CoordinatorConfig{
 80: 		HeartbeatInterval: cfg.GetHeartbeatInterval(),
 81: 		LeaseTimeout:      cfg.GetLeaseTimeout(),
 82: 	}, logger)
 83: 	if err != nil {
 84: 		logger.Fatal("failed to create coordinator", zap.Error(err))
 85: 	}
 86: 	logger.Info("coordinator created, starting it")
 87: 	if err := coordinator.Start(ctx); err != nil {
 88: 		logger.Fatal("failed to start coordinator", zap.Error(err))
 89: 	}
 90: 	logger.Info("coordinator started successfully")
 91: 	defer coordinator.Stop()
 92: 	logger.Info("registering components for leadership")
 93: 	coordinator.RegisterComponentLeadership("rtpengine")
 94: 	coordinator.RegisterComponentLeadership("ami")
 95: 	coordinator.RegisterComponentLeadership("sip")
 96: 	coordinator.RegisterComponentLeadership("websocket")
 97: 	logger.Info("components registered for leadership")
 98: 	logger.Info("creating RTPEngine manager")
 99: 	rtpManager, err := rtpengine.NewManager(cfg.ToRTPEngineManagerConfig(), logger, common.NewGoroutineRegistry(logger), stateStorage, coordinator)
100: 	if err != nil {
101: 		logger.Fatal("failed to create RTPEngine manager", zap.Error(err))
102: 	}
103: 	logger.Info("RTPEngine manager created successfully")
104: 	logger.Info("creating AMI manager")
105: 	amiManager, err := ami.NewManager(cfg.ToAsteriskManagerConfig(), logger, common.NewGoroutineRegistry(logger), stateStorage, coordinator)
106: 	if err != nil {
107: 		logger.Fatal("failed to create AMI manager", zap.Error(err))
108: 	}
109: 	logger.Info("AMI manager created successfully")
110: 	logger.Info("creating SIP proxy")
111: 	sipProxy, err := sip.NewProxy(sipCfg, stateStorage, rtpManager, logger)
112: 	if err != nil {
113: 		logger.Fatal("failed to create SIP proxy", zap.Error(err))
114: 	}
115: 	logger.Info("SIP proxy created successfully")
116: 	logger.Info("creating UDP transport at", zap.String("address", cfg.SIP.UDPBindAddr))
117: 	udpTransport, err := sip.NewUDPTransport(cfg.SIP.UDPBindAddr, logger)
118: 	if err != nil {
119: 		logger.Fatal("failed to create UDP transport", zap.Error(err))
120: 	}
121: 	sipProxy.AddTransport(udpTransport)
122: 	logger.Info("UDP transport created and added to SIP proxy")
123: logger.Info("preparing WebSocket configuration")
124: wsConfig := websocket.ServerConfig{
125:     BindAddr:             cfg.WebSocket.BindAddr,
126:     CertFile:             cfg.WebSocket.CertFile,
127:     KeyFile:              cfg.WebSocket.KeyFile,
128:     MaxConnections:       cfg.WebSocket.MaxConnections,
129:     ReadTimeout:          cfg.GetWebSocketReadTimeout(),
130:     WriteTimeout:         cfg.GetWebSocketWriteTimeout(),
131:     IdleTimeout:          cfg.GetWebSocketIdleTimeout(),
132:     EnableIPv4Only:       cfg.WebSocket.EnableIPv4Only,
133:     ServerName:           cfg.WebSocket.ServerName,
134:     BackendServers:       cfg.WebSocket.BackendServers,
135:     FailoverThreshold:    cfg.WebSocket.FailoverThreshold,
136:     DisableSIPProcessing: cfg.WebSocket.DisableSIPProcessing,
137:     DisableWSSIPProcessing: cfg.WebSocket.DisableWSSIPProcessing,
138: }
139: 	logger.Info("WebSocket config prepared",
140: 		zap.String("bindAddr", wsConfig.BindAddr),
141: 		zap.String("certFile", wsConfig.CertFile),
142: 		zap.String("serverName", wsConfig.ServerName))
143: 	logger.Info("creating WebSocket server")
144: 	logger.Debug("Creating WebSocket server with configuration",
145: 		zap.String("bindAddr", wsConfig.BindAddr),
146: 		zap.String("certFile", wsConfig.CertFile),
147: 		zap.String("keyFile", wsConfig.KeyFile),
148: 		zap.Int("maxConnections", wsConfig.MaxConnections),
149: 		zap.Duration("readTimeout", wsConfig.ReadTimeout),
150: 		zap.Duration("writeTimeout", wsConfig.WriteTimeout),
151: 		zap.Duration("idleTimeout", wsConfig.IdleTimeout),
152: 		zap.Bool("enableIPv4Only", wsConfig.EnableIPv4Only),
153: 		zap.String("serverName", wsConfig.ServerName))
154: 	wsServer, err := websocket.NewServer(wsConfig, stateStorage, logger)
155: 	if err != nil {
156: 		logger.Fatal("failed to create WebSocket server", zap.Error(err))
157: 	}
158: 	logger.Info("WebSocket server created successfully")
159: 	logger.Debug("WebSocket server created successfully, setting SIP handler")
160: 	logger.Info("setting SIP handler for WebSocket server")
161: 	wsServer.SetSIPHandler(sipProxy)
162: 	logger.Info("SIP handler set for WebSocket server")
163: 	logger.Info("creating shutdown context")
164: 	shutdownCtx, cancel := context.WithCancel(context.Background())
165: 	defer cancel()
166: 	logger.Info("shutdown context created")
167: 	logger.Info("starting WebRTC-SIP Gateway components")
168: 	logger.Info("Starting WebRTC-SIP Gateway...")
169: 	logger.Info("starting RTPEngine manager")
170: 	rtpManager.Start(shutdownCtx)
171: 	logger.Info("RTPEngine manager started")
172: 	logger.Info("starting AMI manager")
173: 	if err := amiManager.Start(shutdownCtx); err != nil {
174: 		logger.Fatal("failed to start AMI manager", zap.Error(err))
175: 	}
176: 	logger.Info("AMI manager started successfully")
177: 	logger.Info("starting SIP proxy")
178: 	sipReadyChan := make(chan error, 1)
179: 	go func() {
180: 		err := sipProxy.Start(shutdownCtx)
181: 		if err != nil && !errors.Is(err, context.Canceled) {
182: 			logger.Error("SIP proxy server failed", zap.Error(err))
183: 		}
184: 		select {
185: 		case sipReadyChan <- err:
186: 		default:
187: 		}
188: 	}()
189: 	select {
190: 	case err := <-sipReadyChan:
191: 		if err != nil {
192: 			logger.Error("failed to start SIP proxy", zap.Error(err))
193: 		} else {
194: 			logger.Info("SIP proxy started successfully")
195: 		}
196: 	case <-time.After(2 * time.Second):
197: 		logger.Info("SIP proxy initialization in progress, continuing startup")
198: 		logger.Info("SIP proxy initialization in progress, continuing startup")
199: 	}
200: 	logger.Info("about to start WebSocket server")
201: 	defer func() {
202: 		if r := recover(); r != nil {
203: 			logger.Error("PANIC RECOVERED during WebSocket start", zap.Any("panic", r))
204: 			buf := make([]byte, 4096)
205: 			n := runtime.Stack(buf, false)
206: 			logger.Error("Stack trace", zap.String("trace", string(buf[:n])))
207: 		}
208: 	}()
209: 	logger.Debug("Preparing to start WebSocket server...")
210: 	logger.Info("starting WebSocket server on", zap.String("bindAddr", wsConfig.BindAddr))
211: 	if err := wsServer.Start(shutdownCtx); err != nil {
212: 		logger.Error("WebSocket server start failed with error",
213: 			zap.Error(err),
214: 			zap.String("bindAddr", wsConfig.BindAddr),
215: 			zap.String("certFile", wsConfig.CertFile))
216: 		logger.Fatal("failed to start WebSocket server", zap.Error(err))
217: 	}
218: 	logger.Info("WebSocket server started successfully")
219: 	logger.Info("setting up health monitoring system")
220: 	opensipsHost := cfg.SIP.DefaultNextHop
221: 	if idx := strings.LastIndex(opensipsHost, ":"); idx > 0 {
222: 		opensipsHost = opensipsHost[:idx]
223: 	}
224: 	healthConfig := health.HealthConfig{
225: 		OpenSIPSAddress: opensipsHost,
226: 		CheckInterval:   15 * time.Second,
227: 		EnableFailover:  cfg.HighAvailability.Enabled,
228: 	}
229: 	logger.Debug("Health monitor configuration",
230: 		zap.String("opensipsAddress", healthConfig.OpenSIPSAddress),
231: 		zap.Duration("checkInterval", healthConfig.CheckInterval),
232: 		zap.Bool("enableFailover", healthConfig.EnableFailover))
233: 	healthMonitor := health.NewHealthMonitor(
234: 		udpTransport,
235: 		amiManager,
236: 		rtpManager,
237: 		wsServer,
238: 		coordinator,
239: 		stateStorage,
240: 		logger.Named("health"),
241: 		healthConfig,
242: 	)
243: 	logger.Info("starting health monitoring")
244: 	if err := healthMonitor.Start(shutdownCtx); err != nil {
245: 		logger.Error("failed to start health monitoring", zap.Error(err))
246: 	} else {
247: 		logger.Info("health monitoring started successfully")
248: 	}
249: 	logger.Info("setting up HTTP server for health endpoints")
250: 	httpMux := http.NewServeMux()
251: 	httpMux.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
252: 		logger.Debug("Received health check request",
253: 			zap.String("remoteAddr", r.RemoteAddr),
254: 			zap.String("userAgent", r.UserAgent()))
255: 		status := healthMonitor.GetAllComponentHealth()
256: 		allHealthy := true
257: 		for _, comp := range status {
258: 			if comp.Status != health.StatusHealthy {
259: 				allHealthy = false
260: 				logger.Debug("Unhealthy component detected",
261: 					zap.String("component", comp.Component),
262: 					zap.String("status", string(comp.Status)),
263: 					zap.String("message", comp.Message))
264: 				break
265: 			}
266: 		}
267: 		w.Header().Set("Content-Type", "application/json")
268: 		if !allHealthy {
269: 			w.WriteHeader(http.StatusServiceUnavailable)
270: 			logger.Debug("Returning unhealthy status (503)")
271: 		} else {
272: 			logger.Debug("Returning healthy status (200)")
273: 		}
274: 		statusText := "unhealthy"
275: 		if allHealthy {
276: 			statusText = "healthy"
277: 		}
278: 		response := map[string]interface{}{
279: 			"status":     statusText,
280: 			"components": status,
281: 			"timestamp":  time.Now(),
282: 		}
283: 		if err := json.NewEncoder(w).Encode(response); err != nil {
284: 			logger.Error("failed to encode health response", zap.Error(err))
285: 		}
286: 	})
287: 	httpMux.HandleFunc("/health/opensips", func(w http.ResponseWriter, r *http.Request) {
288: 		status := healthMonitor.GetComponentHealth("opensips")
289: 		w.Header().Set("Content-Type", "application/json")
290: 		if status == nil || status.Status != health.StatusHealthy {
291: 			w.WriteHeader(http.StatusServiceUnavailable)
292: 		}
293: 		json.NewEncoder(w).Encode(status)
294: 	})
295: 	httpMux.HandleFunc("/health/asterisk", func(w http.ResponseWriter, r *http.Request) {
296: 		status := healthMonitor.GetComponentHealth("asterisk")
297: 		w.Header().Set("Content-Type", "application/json")
298: 		if status == nil || status.Status != health.StatusHealthy {
299: 			w.WriteHeader(http.StatusServiceUnavailable)
300: 		}
301: 		json.NewEncoder(w).Encode(status)
302: 	})
303: 	httpMux.HandleFunc("/health/rtpengine", func(w http.ResponseWriter, r *http.Request) {
304: 		status := healthMonitor.GetComponentHealth("rtpengine")
305: 		w.Header().Set("Content-Type", "application/json")
306: 		if status == nil || status.Status != health.StatusHealthy {
307: 			w.WriteHeader(http.StatusServiceUnavailable)
308: 		}
309: 		json.NewEncoder(w).Encode(status)
310: 	})
311: 	httpServer := &http.Server{
312: 		Addr:    ":8080",
313: 		Handler: httpMux,
314: 	}
315: 	logger.Info("starting HTTP server for health endpoints", zap.String("address", ":8080"))
316: 	go func() {
317: 		if err := httpServer.ListenAndServe(); err != nil && err != http.ErrServerClosed {
318: 			logger.Error("HTTP server failed", zap.Error(err))
319: 		}
320: 	}()
321: 	logger.Info("HTTP server for health endpoints started")
322: 	logger.Info("WebRTC-SIP Gateway started successfully")
323: 	logger.Info("setting up signal handler for graceful shutdown")
324: 	sigCh := make(chan os.Signal, 1)
325: 	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
326: 	logger.Info("waiting for shutdown signal")
327: 	sig := <-sigCh
328: 	logger.Info("shutdown signal received", zap.String("signal", sig.String()))
329: 	cancel()
330: 	logger.Info("starting component shutdown sequence")
331: 	logger.Info("Shutting down components...")
332: 	logger.Info("shutting down HTTP server")
333: 	httpShutdownCtx, httpCancel := context.WithTimeout(context.Background(), 5*time.Second)
334: 	defer httpCancel()
335: 	if err := httpServer.Shutdown(httpShutdownCtx); err != nil {
336: 		logger.Error("failed to gracefully shut down HTTP server", zap.Error(err))
337: 	}
338: 	logger.Info("HTTP server shut down")
339: 	logger.Info("stopping WebSocket server")
340: 	if err := wsServer.Stop(); err != nil {
341: 		logger.Error("failed to stop WebSocket server", zap.Error(err))
342: 	}
343: 	logger.Info("WebSocket server stopped")
344: 	logger.Info("stopping SIP proxy")
345: 	if err := sipProxy.Stop(); err != nil {
346: 		logger.Error("failed to stop SIP proxy", zap.Error(err))
347: 	}
348: 	logger.Info("SIP proxy stopped")
349: 	logger.Info("shutting down AMI manager")
350: 	amiManager.Shutdown()
351: 	logger.Info("AMI manager shut down")
352: 	logger.Info("closing storage")
353: 	if err := stateStorage.Close(); err != nil {
354: 		logger.Error("failed to close storage", zap.Error(err))
355: 	}
356: 	logger.Info("storage closed")
357: 	logger.Info("shutdown complete")
358: 	logger.Info("WebRTC-SIP Gateway started successfully")
359: 	logger.Info("program exiting")
360: }
361: func setupLogger(level string) *zap.Logger {
362: 	var logLevel zapcore.Level
363: 	switch level {
364: 	case "debug":
365: 		logLevel = zapcore.DebugLevel
366: 	case "info":
367: 		logLevel = zapcore.InfoLevel
368: 	case "warn":
369: 		logLevel = zapcore.WarnLevel
370: 	case "error":
371: 		logLevel = zapcore.ErrorLevel
372: 	default:
373: 		logLevel = zapcore.InfoLevel
374: 	}
375: 	encoderConfig := zapcore.EncoderConfig{
376: 		TimeKey:        "time",
377: 		LevelKey:       "level",
378: 		NameKey:        "logger",
379: 		CallerKey:      "caller",
380: 		FunctionKey:    zapcore.OmitKey,
381: 		MessageKey:     "message",
382: 		StacktraceKey:  "stacktrace",
383: 		LineEnding:     zapcore.DefaultLineEnding,
384: 		EncodeLevel:    zapcore.LowercaseColorLevelEncoder,
385: 		EncodeTime:     zapcore.ISO8601TimeEncoder,
386: 		EncodeDuration: zapcore.StringDurationEncoder,
387: 		EncodeCaller:   zapcore.ShortCallerEncoder,
388: 	}
389: 	consoleCore := zapcore.NewCore(
390: 		zapcore.NewConsoleEncoder(encoderConfig),
391: 		zapcore.AddSync(os.Stdout),
392: 		logLevel,
393: 	)
394: 	jsonConfig := encoderConfig
395: 	jsonConfig.EncodeLevel = zapcore.LowercaseLevelEncoder
396: 	jsonCore := zapcore.NewCore(
397: 		zapcore.NewJSONEncoder(jsonConfig),
398: 		zapcore.AddSync(os.Stderr),
399: 		logLevel,
400: 	)
401: 	core := zapcore.NewTee(consoleCore, jsonCore)
402: 	logger := zap.New(core,
403: 		zap.AddCaller(),
404: 		zap.AddStacktrace(zapcore.ErrorLevel),
405: 	)
406: 	return logger
407: }
</file>

<file path="gateway/pkg/ami/ami.go">
  1: package ami
  2: import (
  3: 	"bufio"
  4: 	"context"
  5: 	"fmt"
  6: 	"net"
  7: 	"strings"
  8: 	"sync"
  9: 	"time"
 10: 	"go.uber.org/zap"
 11: 	"gateway/pkg/common"
 12: )
 13: type AMIClient struct {
 14: 	address               string
 15: 	username              string
 16: 	secret                string
 17: 	timeout               time.Duration
 18: 	conn                  net.Conn
 19: 	mu                    sync.Mutex
 20: 	connectionLock        sync.Mutex
 21: 	connected             bool
 22: 	bannerReceived        bool
 23: 	responseChans         map[string]chan map[string]string
 24: 	eventHandlers         map[string][]func(event map[string]string)
 25: 	eventChan             chan map[string]string
 26: 	circuitBreaker        *common.CircuitBreaker
 27: 	logger                *zap.Logger
 28: 	stopChan              chan struct{}
 29: 	doneChan              chan struct{}
 30: 	connectedChan         chan bool
 31: 	loginInProgress       bool
 32: 	connectionAttemptTime time.Time
 33: }
 34: type Config struct {
 35: 	Address        string                      `json:"address"`
 36: 	Username       string                      `json:"username"`
 37: 	Secret         string                      `json:"secret"`
 38: 	Timeout        time.Duration               `json:"timeout"`
 39: 	CircuitBreaker common.CircuitBreakerConfig `json:"circuit_breaker"`
 40: }
 41: type BackendManager struct {
 42: 	backends       []*AMIClient
 43: 	activeBackend  int
 44: 	mutex          sync.RWMutex
 45: 	logger         *zap.Logger
 46: 	reconnectDelay time.Duration
 47: }
 48: var (
 49: 	globalManagerMutex sync.Mutex
 50: 	globalManager      *BackendManager
 51: )
 52: func GetBackendManager(configs []Config, logger *zap.Logger) (*BackendManager, error) {
 53: 	globalManagerMutex.Lock()
 54: 	defer globalManagerMutex.Unlock()
 55: 	if globalManager != nil {
 56: 		return globalManager, nil
 57: 	}
 58: 	manager, err := NewBackendManager(configs, logger)
 59: 	if err != nil {
 60: 		return nil, err
 61: 	}
 62: 	globalManager = manager
 63: 	return manager, nil
 64: }
 65: func NewBackendManager(configs []Config, logger *zap.Logger) (*BackendManager, error) {
 66: 	if len(configs) == 0 {
 67: 		return nil, fmt.Errorf("no backend configurations provided")
 68: 	}
 69: 	manager := &BackendManager{
 70: 		backends:       make([]*AMIClient, 0, len(configs)),
 71: 		activeBackend:  0,
 72: 		logger:         logger,
 73: 		reconnectDelay: 30 * time.Second,
 74: 	}
 75: 	for _, cfg := range configs {
 76: 		client, err := New(cfg, logger)
 77: 		if err != nil {
 78: 			return nil, fmt.Errorf("failed to create AMI client for %s: %w", cfg.Address, err)
 79: 		}
 80: 		manager.backends = append(manager.backends, client)
 81: 	}
 82: 	for i := range manager.backends {
 83: 		go func(idx int) {
 84: 			time.Sleep(time.Duration(idx) * 2 * time.Second)
 85: 			manager.monitorBackend(idx)
 86: 		}(i)
 87: 	}
 88: 	ctx := context.Background()
 89: 	if err := manager.backends[0].Connect(ctx); err != nil {
 90: 		logger.Warn("Failed to connect to primary backend",
 91: 			zap.String("address", configs[0].Address),
 92: 			zap.Error(err))
 93: 		time.Sleep(1 * time.Second)
 94: 		for i := 1; i < len(manager.backends); i++ {
 95: 			if err := manager.backends[i].Connect(ctx); err == nil {
 96: 				manager.setActiveBackend(i)
 97: 				break
 98: 			}
 99: 			time.Sleep(500 * time.Millisecond)
100: 		}
101: 	}
102: 	return manager, nil
103: }
104: func (m *BackendManager) monitorBackend(index int) {
105: 	ticker := time.NewTicker(15 * time.Second)
106: 	defer ticker.Stop()
107: 	for range ticker.C {
108: 		backend := m.backends[index]
109: 		isConnected := backend.IsConnected()
110: 		if !isConnected {
111: 			timeSinceLastAttempt := time.Since(backend.getLastConnectionAttempt())
112: 			if timeSinceLastAttempt < m.reconnectDelay {
113: 				m.logger.Debug("Skipping reconnection attempt - too soon after last attempt",
114: 					zap.String("address", backend.address),
115: 					zap.Duration("timeSince", timeSinceLastAttempt),
116: 					zap.Duration("minDelay", m.reconnectDelay))
117: 				continue
118: 			}
119: 			ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
120: 			err := backend.Connect(ctx)
121: 			cancel()
122: 			if err == nil {
123: 				isConnected = true
124: 				m.logger.Info("Successfully reconnected to backend",
125: 					zap.String("address", backend.address),
126: 					zap.Int("backendIndex", index))
127: 			}
128: 		}
129: 		if isConnected {
130: 			if err := backend.Ping(); err != nil {
131: 				m.logger.Warn("Ping failed but keeping connection",
132: 					zap.String("address", backend.address),
133: 					zap.Error(err))
134: 			}
135: 		}
136: 		if !isConnected {
137: 			m.handleBackendFailure(index)
138: 		} else if index != m.getActiveBackend() && !m.backends[m.getActiveBackend()].IsConnected() {
139: 			m.setActiveBackend(index)
140: 			m.logger.Info("Switched to healthy backend",
141: 				zap.Int("backend", index))
142: 		}
143: 	}
144: }
145: func (m *BackendManager) handleBackendFailure(failedIndex int) {
146: 	m.mutex.RLock()
147: 	activeBackend := m.activeBackend
148: 	m.mutex.RUnlock()
149: 	if failedIndex != activeBackend {
150: 		return
151: 	}
152: 	m.mutex.Lock()
153: 	defer m.mutex.Unlock()
154: 	if failedIndex != m.activeBackend {
155: 		return
156: 	}
157: 	for i := 0; i < len(m.backends); i++ {
158: 		if i == failedIndex {
159: 			continue
160: 		}
161: 		if m.backends[i].IsConnected() {
162: 			m.activeBackend = i
163: 			m.logger.Info("Switched active backend after failure",
164: 				zap.Int("oldBackend", failedIndex),
165: 				zap.Int("newBackend", i))
166: 			return
167: 		}
168: 	}
169: 	m.logger.Warn("No connected backends available, attempting reconnection")
170: 	go m.attemptReconnectAll()
171: }
172: func (m *BackendManager) attemptReconnectAll() {
173: 	ctx := context.Background()
174: 	for i, backend := range m.backends {
175: 		if backend.IsConnected() {
176: 			continue
177: 		}
178: 		timeSinceLastAttempt := time.Since(backend.getLastConnectionAttempt())
179: 		if timeSinceLastAttempt < m.reconnectDelay {
180: 			m.logger.Debug("Skipping reconnection for backend - too recent",
181: 				zap.Int("backendIndex", i),
182: 				zap.String("address", backend.address),
183: 				zap.Duration("timeSince", timeSinceLastAttempt))
184: 			continue
185: 		}
186: 		if err := backend.Connect(ctx); err == nil {
187: 			m.setActiveBackend(i)
188: 			m.logger.Info("Reconnected to backend",
189: 				zap.Int("backend", i))
190: 			return
191: 		}
192: 		time.Sleep(1 * time.Second)
193: 	}
194: }
195: func (m *BackendManager) setActiveBackend(index int) {
196: 	m.mutex.Lock()
197: 	defer m.mutex.Unlock()
198: 	m.activeBackend = index
199: }
200: func (m *BackendManager) getActiveBackend() int {
201: 	m.mutex.RLock()
202: 	defer m.mutex.RUnlock()
203: 	return m.activeBackend
204: }
205: func (m *BackendManager) GetActiveClient() *AMIClient {
206: 	m.mutex.RLock()
207: 	defer m.mutex.RUnlock()
208: 	return m.backends[m.activeBackend]
209: }
210: func (m *BackendManager) SendAction(action map[string]string) (map[string]string, error) {
211: 	client := m.GetActiveClient()
212: 	response, err := client.SendAction(action)
213: 	if err != nil {
214: 		m.handleBackendFailure(m.getActiveBackend())
215: 		client = m.GetActiveClient()
216: 		return client.SendAction(action)
217: 	}
218: 	return response, nil
219: }
220: func New(config Config, logger *zap.Logger) (*AMIClient, error) {
221: 	if logger == nil {
222: 		var err error
223: 		logger, err = zap.NewProduction()
224: 		if err != nil {
225: 			return nil, err
226: 		}
227: 	}
228: 	if config.Address == "" {
229: 		return nil, fmt.Errorf("address is required")
230: 	}
231: 	if config.Username == "" {
232: 		return nil, fmt.Errorf("username is required")
233: 	}
234: 	if config.Secret == "" {
235: 		return nil, fmt.Errorf("secret is required")
236: 	}
237: 	if config.Timeout <= 0 {
238: 		config.Timeout = 10 * time.Second
239: 	}
240: 	cbName := fmt.Sprintf("ami-%s", config.Address)
241: 	cb := common.NewCircuitBreaker(cbName, config.CircuitBreaker, logger)
242: 	client := &AMIClient{
243: 		address:         config.Address,
244: 		username:        config.Username,
245: 		secret:          config.Secret,
246: 		timeout:         config.Timeout,
247: 		responseChans:   make(map[string]chan map[string]string),
248: 		eventHandlers:   make(map[string][]func(event map[string]string)),
249: 		eventChan:       make(chan map[string]string, 100),
250: 		circuitBreaker:  cb,
251: 		logger:          logger,
252: 		stopChan:        make(chan struct{}),
253: 		doneChan:        make(chan struct{}),
254: 		connectedChan:   make(chan bool, 1),
255: 		loginInProgress: false,
256: 	}
257: 	return client, nil
258: }
259: func (c *AMIClient) getLastConnectionAttempt() time.Time {
260: 	c.mu.Lock()
261: 	defer c.mu.Unlock()
262: 	return c.connectionAttemptTime
263: }
264: func (c *AMIClient) Connect(ctx context.Context) error {
265: 	c.connectionLock.Lock()
266: 	defer c.connectionLock.Unlock()
267: 	c.mu.Lock()
268: 	if c.connected {
269: 		c.mu.Unlock()
270: 		return nil
271: 	}
272: 	timeSinceLastAttempt := time.Since(c.connectionAttemptTime)
273: 	if timeSinceLastAttempt < 5*time.Second {
274: 		c.mu.Unlock()
275: 		c.logger.Debug("Skipping connection attempt - too soon after previous attempt",
276: 			zap.String("address", c.address),
277: 			zap.Duration("timeSince", timeSinceLastAttempt))
278: 		return fmt.Errorf("connection throttled (last attempt: %v ago)", timeSinceLastAttempt)
279: 	}
280: 	c.connectionAttemptTime = time.Now()
281: 	c.mu.Unlock()
282: 	return c.connectImpl(ctx)
283: }
284: func (c *AMIClient) connectImpl(ctx context.Context) error {
285: 	c.mu.Lock()
286: 	defer c.mu.Unlock()
287: 	if c.connected {
288: 		return nil
289: 	}
290: 	c.logger.Debug("Starting AMI connection attempt",
291: 		zap.String("address", c.address))
292: 	if !c.circuitBreaker.AllowRequest() {
293: 		return fmt.Errorf("circuit breaker open for AMI %s", c.address)
294: 	}
295: 	if c.conn != nil {
296: 		c.logger.Debug("Closing existing connection before reconnect",
297: 			zap.String("address", c.address))
298: 		_, _ = c.conn.Write([]byte("Action: Logoff\r\n\r\n"))
299: 		time.Sleep(100 * time.Millisecond)
300: 		c.closeConn()
301: 		close(c.stopChan)
302: 		select {
303: 		case <-c.doneChan:
304: 		case <-time.After(500 * time.Millisecond):
305: 			c.logger.Warn("Timeout waiting for loops to terminate during reconnect",
306: 				zap.String("address", c.address))
307: 		}
308: 		c.stopChan = make(chan struct{})
309: 		c.doneChan = make(chan struct{})
310: 	}
311: 	dialer := net.Dialer{
312: 		Timeout: c.timeout,
313: 	}
314: 	c.logger.Debug("Dialing AMI server",
315: 		zap.String("address", c.address))
316: 	conn, err := dialer.DialContext(ctx, "tcp", c.address)
317: 	if err != nil {
318: 		c.circuitBreaker.RecordFailure()
319: 		return fmt.Errorf("failed to connect to AMI: %w", err)
320: 	}
321: 	c.conn = conn
322: 	conn.SetReadDeadline(time.Now().Add(c.timeout))
323: 	reader := bufio.NewReader(conn)
324: 	banner, err := reader.ReadString('\n')
325: 	if err != nil {
326: 		conn.Close()
327: 		c.circuitBreaker.RecordFailure()
328: 		return fmt.Errorf("failed to read AMI banner: %w", err)
329: 	}
330: 	c.logger.Debug("Connected to Asterisk",
331: 		zap.String("address", c.address),
332: 		zap.String("banner", strings.TrimSpace(banner)))
333: 	c.bannerReceived = true
334: 	select {
335: 	case c.connectedChan <- true:
336: 	default:
337: 	}
338: 	conn.SetReadDeadline(time.Time{})
339: 	go c.eventDispatcher()
340: 	go c.readLoop()
341: 	time.Sleep(100 * time.Millisecond)
342: 	c.logger.Debug("Sending AMI login request directly",
343: 		zap.String("address", c.address),
344: 		zap.String("username", c.username))
345: 	loginCmd := fmt.Sprintf(
346: 		"Action: Login\r\nUsername: %s\r\nSecret: %s\r\nEvents: on\r\n\r\n",
347: 		c.username, c.secret)
348: 	_, err = c.conn.Write([]byte(loginCmd))
349: 	if err != nil {
350: 		c.logger.Error("Failed to send login command",
351: 			zap.String("address", c.address),
352: 			zap.Error(err))
353: 		close(c.stopChan)
354: 		c.closeConn()
355: 		c.circuitBreaker.RecordFailure()
356: 		<-c.doneChan
357: 		return fmt.Errorf("failed to send login command: %w", err)
358: 	}
359: 	c.logger.Debug("Login command sent, waiting for processing",
360: 		zap.String("address", c.address))
361: 	time.Sleep(2 * time.Second)
362: 	c.logger.Debug("Verifying AMI connection after login with direct ping",
363: 		zap.String("address", c.address))
364: 	pingCmd := "Action: Ping\r\n\r\n"
365: 	_, err = c.conn.Write([]byte(pingCmd))
366: 	if err != nil {
367: 		c.logger.Error("Failed to send verification ping",
368: 			zap.String("address", c.address),
369: 			zap.Error(err))
370: 		close(c.stopChan)
371: 		c.closeConn()
372: 		c.circuitBreaker.RecordFailure()
373: 		<-c.doneChan
374: 		return fmt.Errorf("login verification failed - ping error: %w", err)
375: 	}
376: 	c.logger.Info("AMI connection and login successful",
377: 		zap.String("address", c.address))
378: 	c.connected = true
379: 	c.circuitBreaker.RecordSuccess()
380: 	return nil
381: }
382: func (c *AMIClient) closeConn() {
383: 	c.logger.Debug("Closing AMI connection",
384: 		zap.String("address", c.address))
385: 	if c.conn != nil {
386: 		c.conn.Close()
387: 		c.conn = nil
388: 	}
389: 	c.bannerReceived = false
390: }
391: func (c *AMIClient) ConnectNonBlocking(ctx context.Context) {
392: 	select {
393: 	case <-c.connectedChan:
394: 	default:
395: 	}
396: 	c.mu.Lock()
397: 	if c.connected {
398: 		c.mu.Unlock()
399: 		c.connectedChan <- true
400: 		return
401: 	}
402: 	c.mu.Unlock()
403: 	go func() {
404: 		c.logger.Debug("Starting background connection attempt",
405: 			zap.String("address", c.address))
406: 		err := c.Connect(ctx)
407: 		if err != nil {
408: 			c.logger.Error("Background AMI connection failed",
409: 				zap.String("address", c.address),
410: 				zap.Error(err))
411: 			select {
412: 			case c.connectedChan <- false:
413: 			default:
414: 			}
415: 		}
416: 	}()
417: }
418: func (c *AMIClient) Disconnect() {
419: 	c.mu.Lock()
420: 	if !c.connected {
421: 		c.mu.Unlock()
422: 		return
423: 	}
424: 	c.logger.Debug("Disconnecting from AMI",
425: 		zap.String("address", c.address))
426: 	close(c.stopChan)
427: 	if c.conn != nil {
428: 		_, _ = c.conn.Write([]byte("Action: Logoff\r\n\r\n"))
429: 		time.Sleep(100 * time.Millisecond)
430: 	}
431: 	c.closeConn()
432: 	c.connected = false
433: 	for id, ch := range c.responseChans {
434: 		close(ch)
435: 		delete(c.responseChans, id)
436: 	}
437: 	c.mu.Unlock()
438: 	select {
439: 	case <-c.doneChan:
440: 	case <-time.After(2 * time.Second):
441: 		c.logger.Warn("Timeout waiting for dispatcher during disconnect",
442: 			zap.String("address", c.address))
443: 	}
444: }
445: func (c *AMIClient) Reconnect(ctx context.Context) error {
446: 	return c.Connect(ctx)
447: }
448: func (c *AMIClient) IsConnected() bool {
449: 	c.mu.Lock()
450: 	defer c.mu.Unlock()
451: 	return c.connected
452: }
453: func (c *AMIClient) IsBannerReceived() bool {
454: 	c.mu.Lock()
455: 	defer c.mu.Unlock()
456: 	return c.bannerReceived
457: }
458: func (c *AMIClient) WaitForBanner(timeout time.Duration) bool {
459: 	select {
460: 	case result := <-c.connectedChan:
461: 		return result
462: 	case <-time.After(timeout):
463: 		return false
464: 	}
465: }
466: func (c *AMIClient) eventDispatcher() {
467: 	c.logger.Debug("Starting AMI event dispatcher",
468: 		zap.String("address", c.address))
469: 	defer func() {
470: 		c.logger.Debug("Event dispatcher shutting down",
471: 			zap.String("address", c.address))
472: 		close(c.doneChan)
473: 	}()
474: 	for {
475: 		select {
476: 		case <-c.stopChan:
477: 			c.logger.Debug("Event dispatcher received stop signal",
478: 				zap.String("address", c.address))
479: 			return
480: 		case event := <-c.eventChan:
481: 			if eventName, ok := event["Event"]; ok {
482: 				c.mu.Lock()
483: 				handlers := c.eventHandlers[eventName]
484: 				handlersCopy := make([]func(map[string]string), len(handlers))
485: 				copy(handlersCopy, handlers)
486: 				c.mu.Unlock()
487: 				for _, handler := range handlersCopy {
488: 					go handler(event)
489: 				}
490: 				c.mu.Lock()
491: 				wildcardHandlers := c.eventHandlers["*"]
492: 				handlersCopy = make([]func(map[string]string), len(wildcardHandlers))
493: 				copy(handlersCopy, wildcardHandlers)
494: 				c.mu.Unlock()
495: 				for _, handler := range handlersCopy {
496: 					go handler(event)
497: 				}
498: 			}
499: 		}
500: 	}
501: }
502: func (c *AMIClient) SendAction(action map[string]string) (map[string]string, error) {
503: 	c.mu.Lock()
504: 	defer c.mu.Unlock()
505: 	if !c.connected {
506: 		if err := c.connectImpl(context.Background()); err != nil {
507: 			return nil, fmt.Errorf("not connected: %w", err)
508: 		}
509: 	}
510: 	return c.sendActionLocked(action)
511: }
512: func (c *AMIClient) sendActionLocked(action map[string]string) (map[string]string, error) {
513: 	actionName := action["Action"]
514: 	if c.conn == nil {
515: 		c.circuitBreaker.RecordFailure()
516: 		return nil, fmt.Errorf("no active connection for action %s", actionName)
517: 	}
518: 	if _, ok := action["ActionID"]; !ok {
519: 		action["ActionID"] = fmt.Sprintf("AMI-%d", time.Now().UnixNano())
520: 	}
521: 	actionID := action["ActionID"]
522: 	c.logger.Debug("Sending AMI action",
523: 		zap.String("address", c.address),
524: 		zap.String("action", actionName),
525: 		zap.String("actionID", actionID))
526: 	var buf strings.Builder
527: 	for k, v := range action {
528: 		buf.WriteString(fmt.Sprintf("%s: %s\r\n", k, v))
529: 	}
530: 	buf.WriteString("\r\n")
531: 	responseCh := make(chan map[string]string, 1)
532: 	c.responseChans[actionID] = responseCh
533: 	_, err := c.conn.Write([]byte(buf.String()))
534: 	if err != nil {
535: 		delete(c.responseChans, actionID)
536: 		c.circuitBreaker.RecordFailure()
537: 		c.connected = false
538: 		c.logger.Error("Failed to send AMI action",
539: 			zap.String("address", c.address),
540: 			zap.String("action", actionName),
541: 			zap.Error(err))
542: 		return nil, fmt.Errorf("failed to send action: %w", err)
543: 	}
544: 	timer := time.NewTimer(c.timeout)
545: 	defer timer.Stop()
546: 	var defaultResponse map[string]string
547: 	if actionName == "Ping" {
548: 		defaultResponse = map[string]string{
549: 			"Response": "Success",
550: 			"Ping":     "Pong",
551: 			"ActionID": actionID,
552: 		}
553: 	}
554: 	select {
555: 	case resp, ok := <-responseCh:
556: 		delete(c.responseChans, actionID)
557: 		if !ok {
558: 			c.circuitBreaker.RecordFailure()
559: 			c.logger.Error("Response channel closed",
560: 				zap.String("address", c.address),
561: 				zap.String("action", actionName))
562: 			return nil, fmt.Errorf("response channel closed")
563: 		}
564: 		if resp["Response"] == "Error" {
565: 			c.circuitBreaker.RecordFailure()
566: 			c.logger.Error("AMI returned error response",
567: 				zap.String("address", c.address),
568: 				zap.String("action", actionName),
569: 				zap.String("message", resp["Message"]))
570: 			return resp, fmt.Errorf("AMI error: %s", resp["Message"])
571: 		}
572: 		c.circuitBreaker.RecordSuccess()
573: 		c.logger.Debug("Received successful AMI response",
574: 			zap.String("address", c.address),
575: 			zap.String("action", actionName))
576: 		return resp, nil
577: 	case <-timer.C:
578: 		delete(c.responseChans, actionID)
579: 		if actionName == "Ping" && c.connected {
580: 			c.logger.Warn("Timeout waiting for Ping response, but connection still active - returning synthetic success",
581: 				zap.String("address", c.address))
582: 			return defaultResponse, nil
583: 		}
584: 		c.circuitBreaker.RecordFailure()
585: 		c.logger.Error("Timeout waiting for AMI response",
586: 			zap.String("address", c.address),
587: 			zap.String("action", actionName),
588: 			zap.Duration("timeout", c.timeout))
589: 		return nil, fmt.Errorf("timeout waiting for response")
590: 	}
591: }
592: func (c *AMIClient) readLoop() {
593: 	c.logger.Debug("AMI readLoop starting",
594: 		zap.String("address", c.address))
595: 	defer func() {
596: 		if r := recover(); r != nil {
597: 			c.logger.Error("Recovered from panic in AMI readLoop",
598: 				zap.String("address", c.address),
599: 				zap.Any("error", r))
600: 		}
601: 	}()
602: 	defer func() {
603: 		c.mu.Lock()
604: 		c.logger.Debug("AMI readLoop cleanup",
605: 			zap.String("address", c.address),
606: 			zap.Bool("wasConnected", c.connected))
607: 		c.connected = false
608: 		if c.conn != nil {
609: 			c.conn.Close()
610: 		}
611: 		for id, ch := range c.responseChans {
612: 			close(ch)
613: 			delete(c.responseChans, id)
614: 		}
615: 		c.conn = nil
616: 		c.mu.Unlock()
617: 		c.logger.Debug("AMI readLoop exiting",
618: 			zap.String("address", c.address))
619: 	}()
620: 	c.mu.Lock()
621: 	if c.conn == nil {
622: 		c.mu.Unlock()
623: 		c.logger.Error("AMI connection is nil in readLoop",
624: 			zap.String("address", c.address))
625: 		return
626: 	}
627: 	reader := bufio.NewReader(c.conn)
628: 	c.mu.Unlock()
629: 	rawDataBuffer := &strings.Builder{}
630: 	rawLogTicker := time.NewTicker(2 * time.Second)
631: 	defer rawLogTicker.Stop()
632: 	go func() {
633: 		for {
634: 			select {
635: 			case <-c.stopChan:
636: 				return
637: 			case <-rawLogTicker.C:
638: 				if rawDataBuffer.Len() > 0 {
639: 					data := rawDataBuffer.String()
640: 					if len(data) > 0 {
641: 						c.logger.Debug("Raw AMI data received",
642: 							zap.String("address", c.address),
643: 							zap.String("data", data))
644: 					}
645: 					rawDataBuffer.Reset()
646: 				}
647: 			}
648: 		}
649: 	}()
650: 	c.logger.Debug("AMI readLoop main loop starting",
651: 		zap.String("address", c.address))
652: 	for {
653: 		select {
654: 		case <-c.stopChan:
655: 			c.logger.Debug("AMI readLoop received stop signal",
656: 				zap.String("address", c.address))
657: 			return
658: 		default:
659: 		}
660: 		c.mu.Lock()
661: 		if c.conn == nil {
662: 			c.mu.Unlock()
663: 			c.logger.Debug("AMI connection closed, exiting readLoop",
664: 				zap.String("address", c.address))
665: 			return
666: 		}
667: 		c.conn.SetReadDeadline(time.Now().Add(5 * time.Minute))
668: 		c.mu.Unlock()
669: 		response := make(map[string]string)
670: 		readingMessage := true
671: 		for readingMessage {
672: 			c.mu.Lock()
673: 			if c.conn == nil {
674: 				c.mu.Unlock()
675: 				c.logger.Debug("AMI connection nil during message read",
676: 					zap.String("address", c.address))
677: 				return
678: 			}
679: 			c.mu.Unlock()
680: 			line, err := reader.ReadString('\n')
681: 			if err != nil {
682: 				c.logger.Error("AMI read error",
683: 					zap.String("address", c.address),
684: 					zap.Error(err))
685: 				return
686: 			}
687: 			rawDataBuffer.WriteString(line)
688: 			line = strings.TrimRight(line, "\r\n")
689: 			if line == "" {
690: 				readingMessage = false
691: 				continue
692: 			}
693: 			// Parse key-value pair
694: 			parts := strings.SplitN(line, ":", 2)
695: 			if len(parts) != 2 {
696: 				c.logger.Warn("Invalid AMI message format",
697: 					zap.String("address", c.address),
698: 					zap.String("line", line))
699: 				continue
700: 			}
701: 			key := strings.TrimSpace(parts[0])
702: 			value := strings.TrimSpace(parts[1])
703: 			response[key] = value
704: 		}
705: 		c.logger.Debug("AMI message received",
706: 			zap.String("address", c.address),
707: 			zap.Any("message", response))
708: 		if respType, hasResponse := response["Response"]; hasResponse {
709: 			actionID, hasActionID := response["ActionID"]
710: 			c.logger.Debug("Processing AMI response",
711: 				zap.String("address", c.address),
712: 				zap.String("response", respType),
713: 				zap.Bool("hasActionID", hasActionID),
714: 				zap.String("actionID", actionID))
715: 			if hasActionID {
716: 				c.mu.Lock()
717: 				if ch, ok := c.responseChans[actionID]; ok {
718: 					select {
719: 					case ch <- response:
720: 						c.logger.Debug("Sent response to channel",
721: 							zap.String("address", c.address),
722: 							zap.String("actionID", actionID))
723: 					default:
724: 						c.logger.Warn("Response channel buffer full",
725: 							zap.String("address", c.address),
726: 							zap.String("actionID", actionID))
727: 					}
728: 				} else {
729: 					c.logger.Warn("No response channel for actionID",
730: 						zap.String("address", c.address),
731: 						zap.String("actionID", actionID))
732: 				}
733: 				c.mu.Unlock()
734: 			} else {
735: 				c.logger.Warn("Response without ActionID",
736: 					zap.String("address", c.address),
737: 					zap.Any("response", response))
738: 			}
739: 		} else if eventName, ok := response["Event"]; ok {
740: 			c.logger.Debug("Received AMI event",
741: 				zap.String("address", c.address),
742: 				zap.String("event", eventName))
743: 			select {
744: 			case c.eventChan <- response:
745: 			default:
746: 				c.logger.Warn("Event channel full, discarding event",
747: 					zap.String("address", c.address),
748: 					zap.String("event", eventName))
749: 			}
750: 		} else {
751: 			c.logger.Warn("Unknown AMI message type",
752: 				zap.String("address", c.address),
753: 				zap.Any("message", response))
754: 		}
755: 	}
756: }
757: func (c *AMIClient) RegisterEventHandler(event string, handler func(event map[string]string)) {
758: 	c.mu.Lock()
759: 	defer c.mu.Unlock()
760: 	c.eventHandlers[event] = append(c.eventHandlers[event], handler)
761: }
762: func (c *AMIClient) Ping() error {
763: 	_, err := c.SendAction(map[string]string{
764: 		"Action": "Ping",
765: 	})
766: 	return err
767: }
768: func (c *AMIClient) Originate(channel, exten, context, priority, application, data, callerId string, timeout int) (map[string]string, error) {
769: 	action := map[string]string{
770: 		"Action": "Originate",
771: 	}
772: 	if channel != "" {
773: 		action["Channel"] = channel
774: 	}
775: 	if exten != "" {
776: 		action["Exten"] = exten
777: 	}
778: 	if context != "" {
779: 		action["Context"] = context
780: 	}
781: 	if priority != "" {
782: 		action["Priority"] = priority
783: 	}
784: 	if application != "" {
785: 		action["Application"] = application
786: 	}
787: 	if data != "" {
788: 		action["Data"] = data
789: 	}
790: 	if callerId != "" {
791: 		action["CallerID"] = callerId
792: 	}
793: 	if timeout > 0 {
794: 		action["Timeout"] = fmt.Sprintf("%d", timeout)
795: 	}
796: 	return c.SendAction(action)
797: }
798: func (c *AMIClient) GetStatus(channel string) (map[string]string, error) {
799: 	action := map[string]string{
800: 		"Action": "Status",
801: 	}
802: 	if channel != "" {
803: 		action["Channel"] = channel
804: 	}
805: 	return c.SendAction(action)
806: }
807: func (c *AMIClient) Hangup(channel, cause string) (map[string]string, error) {
808: 	action := map[string]string{
809: 		"Action":  "Hangup",
810: 		"Channel": channel,
811: 	}
812: 	if cause != "" {
813: 		action["Cause"] = cause
814: 	}
815: 	return c.SendAction(action)
816: }
</file>

<file path="gateway/pkg/ami/manager.go">
  1: package ami
  2: import (
  3: 	"context"
  4: 	"errors"
  5: 	"fmt"
  6: 	"math"
  7: 	"sync"
  8: 	"sync/atomic"
  9: 	"time"
 10: 	"go.uber.org/zap"
 11: 	"gateway/pkg/common"
 12: 	"gateway/pkg/coordinator"
 13: 	"gateway/pkg/storage"
 14: )
 15: type Manager struct {
 16: 	clients      []*AMIClient
 17: 	activeIdx    int32
 18: 	mu           sync.RWMutex
 19: 	logger       *zap.Logger
 20: 	registry     *common.GoroutineRegistry
 21: 	storage      storage.StateStorage
 22: 	coordinator  *coordinator.Coordinator
 23: 	maxRetries   int
 24: 	retryDelay   time.Duration
 25: 	initializing int32
 26: 	proxyServer  *AMIProxyServer
 27: }
 28: type ManagerConfig struct {
 29: 	Clients           []Config `json:"clients"`
 30: 	MaxRetries        int      `json:"max_retries"`
 31: 	RetryDelay        string   `json:"retry_delay"`
 32: 	EnableHAProxy     bool     `json:"enable_ha_proxy"`
 33: 	OriginalAddresses []string `json:"original_addresses"`
 34: }
 35: type IsLeaderAdapter struct {
 36: 	coord *coordinator.Coordinator
 37: }
 38: func (a *IsLeaderAdapter) IsLeader(component string) bool {
 39: 	return a.coord.IsLeader(component)
 40: }
 41: func NewManager(config ManagerConfig, logger *zap.Logger, registry *common.GoroutineRegistry,
 42: 	storage storage.StateStorage, coord *coordinator.Coordinator) (*Manager, error) {
 43: 	if logger == nil {
 44: 		var err error
 45: 		logger, err = zap.NewProduction()
 46: 		if err != nil {
 47: 			return nil, err
 48: 		}
 49: 	}
 50: 	if len(config.Clients) == 0 {
 51: 		return nil, errors.New("at least one AMI client required")
 52: 	}
 53: 	var clients []*AMIClient
 54: 	for _, clientConfig := range config.Clients {
 55: 		client, err := New(clientConfig, logger)
 56: 		if err != nil {
 57: 			logger.Warn("Failed to create AMI client",
 58: 				zap.String("address", clientConfig.Address),
 59: 				zap.Error(err))
 60: 			continue
 61: 		}
 62: 		clients = append(clients, client)
 63: 	}
 64: 	if len(clients) == 0 {
 65: 		return nil, errors.New("all AMI clients failed to initialize")
 66: 	}
 67: 	maxRetries := 3
 68: 	if config.MaxRetries > 0 {
 69: 		maxRetries = config.MaxRetries
 70: 	}
 71: 	retryDelay := 5 * time.Second
 72: 	if config.RetryDelay != "" {
 73: 		if parsedDelay, err := time.ParseDuration(config.RetryDelay); err == nil && parsedDelay > 0 {
 74: 			retryDelay = parsedDelay
 75: 		}
 76: 	}
 77: 	manager := &Manager{
 78: 		clients:     clients,
 79: 		logger:      logger,
 80: 		registry:    registry,
 81: 		storage:     storage,
 82: 		coordinator: coord,
 83: 		maxRetries:  maxRetries,
 84: 		retryDelay:  retryDelay,
 85: 	}
 86: 	// If high availability proxy is enabled
 87: 	if config.EnableHAProxy && len(config.OriginalAddresses) > 0 {
 88: 		// Create AMI proxy server configuration
 89: 		proxyConfig := ProxyConfig{
 90: 			OriginalAddresses: config.OriginalAddresses,
 91: 			AmiConfigs:        make([]Config, 0, len(config.Clients)),
 92: 		}
 93: 		// Convert server configs
 94: 		for _, clientConfig := range config.Clients {
 95: 			proxyConfig.AmiConfigs = append(proxyConfig.AmiConfigs, clientConfig)
 96: 		}
 97: 		// Create proxy server
 98: 		proxyServer, err := NewProxyServer(proxyConfig, coord, logger)
 99: 		if err != nil {
100: 			logger.Warn("Failed to create AMI proxy server", zap.Error(err))
101: 		} else {
102: 			manager.proxyServer = proxyServer
103: 			logger.Info("AMI proxy server created successfully",
104: 				zap.Strings("addresses", config.OriginalAddresses))
105: 		}
106: 	}
107: 	return manager, nil
108: }
109: func (m *Manager) Start(ctx context.Context) error {
110: 	atomic.StoreInt32(&m.initializing, 1)
111: 	defer atomic.StoreInt32(&m.initializing, 0)
112: 	m.logger.Info("Starting non-blocking AMI connection",
113: 		zap.String("address", m.clients[0].address))
114: 	m.clients[0].ConnectNonBlocking(ctx)
115: 	bannerReceived := m.clients[0].WaitForBanner(3 * time.Second)
116: 	if bannerReceived {
117: 		m.logger.Info("AMI banner received from primary server, continuing startup",
118: 			zap.String("address", m.clients[0].address))
119: 	} else {
120: 		m.logger.Warn("AMI initial connection not completed quickly, continuing startup",
121: 			zap.String("address", m.clients[0].address))
122: 		for i := 1; i < len(m.clients); i++ {
123: 			m.clients[i].ConnectNonBlocking(ctx)
124: 			if m.clients[i].WaitForBanner(1 * time.Second) {
125: 				atomic.StoreInt32(&m.activeIdx, int32(i))
126: 				m.logger.Info("Connected to backup AMI (banner received)",
127: 					zap.String("address", m.clients[i].address))
128: 				break
129: 			}
130: 		}
131: 		go m.retryAllConnections(ctx)
132: 	}
133: 	for i, client := range m.clients {
134: 		i, client := i, client
135: 		m.registry.Go(fmt.Sprintf("ami-health-%d", i), func(ctx context.Context) {
136: 			ticker := time.NewTicker(10 * time.Second)
137: 			defer ticker.Stop()
138: 			for {
139: 				select {
140: 				case <-ctx.Done():
141: 					return
142: 				case <-ticker.C:
143: 					if !client.IsConnected() {
144: 						continue
145: 					}
146: 					if err := client.Ping(); err != nil {
147: 						m.logger.Warn("AMI health check failed",
148: 							zap.String("address", client.address),
149: 							zap.Error(err))
150: 						if atomic.LoadInt32(&m.activeIdx) == int32(i) {
151: 							m.tryReconnectOrFailover(ctx, i)
152: 						}
153: 					} else {
154: 						m.logger.Debug("AMI health check succeeded",
155: 							zap.String("address", client.address))
156: 					}
157: 				}
158: 			}
159: 		})
160: 	}
161: 	m.registerEventHandlers()
162: 	m.registry.Go("ami-connection-monitor", func(ctx context.Context) {
163: 		m.monitorConnections(ctx)
164: 	})
165: 	if m.proxyServer != nil {
166: 		if err := m.proxyServer.Start(); err != nil {
167: 			m.logger.Error("Failed to start AMI proxy server", zap.Error(err))
168: 		} else {
169: 			m.logger.Info("AMI proxy server started successfully")
170: 		}
171: 	}
172: 	return nil
173: }
174: func (m *Manager) retryAllConnections(ctx context.Context) {
175: 	baseDelay := m.retryDelay
176: 	for i, client := range m.clients {
177: 		i, client := i, client
178: 		if client.IsConnected() {
179: 			continue
180: 		}
181: 		go func() {
182: 			retryCount := 0
183: 			for retryCount < m.maxRetries {
184: 				if client.IsConnected() {
185: 					return
186: 				}
187: 				delay := time.Duration(float64(baseDelay) * math.Pow(1.5, float64(retryCount)))
188: 				if delay > 2*time.Minute {
189: 					delay = 2 * time.Minute
190: 				}
191: 				m.logger.Info("Retrying AMI connection",
192: 					zap.String("address", client.address),
193: 					zap.Int("attempt", retryCount+1),
194: 					zap.Duration("delay", delay))
195: 				select {
196: 				case <-ctx.Done():
197: 					return
198: 				case <-time.After(delay):
199: 				}
200: 				err := client.Reconnect(ctx)
201: 				if err != nil {
202: 					retryCount++
203: 					m.logger.Error("AMI reconnection failed",
204: 						zap.String("address", client.address),
205: 						zap.Error(err),
206: 						zap.Int("retryCount", retryCount))
207: 				} else {
208: 					m.logger.Info("AMI reconnection successful",
209: 						zap.String("address", client.address),
210: 						zap.Int("attempts", retryCount+1))
211: 					if i == 0 && atomic.LoadInt32(&m.activeIdx) == 0 {
212: 						return
213: 					}
214: 					activeIdx := atomic.LoadInt32(&m.activeIdx)
215: 					if !m.clients[activeIdx].IsConnected() {
216: 						atomic.StoreInt32(&m.activeIdx, int32(i))
217: 						m.logger.Info("Switched to newly connected AMI client",
218: 							zap.String("address", client.address))
219: 					}
220: 					return
221: 				}
222: 			}
223: 			m.logger.Warn("Maximum AMI reconnection attempts reached",
224: 				zap.String("address", client.address),
225: 				zap.Int("maxRetries", m.maxRetries))
226: 		}()
227: 	}
228: }
229: func (m *Manager) monitorConnections(ctx context.Context) {
230: 	ticker := time.NewTicker(30 * time.Second)
231: 	defer ticker.Stop()
232: 	for {
233: 		select {
234: 		case <-ctx.Done():
235: 			return
236: 		case <-ticker.C:
237: 			activeIdx := atomic.LoadInt32(&m.activeIdx)
238: 			if !m.clients[activeIdx].IsConnected() {
239: 				m.logger.Warn("Active AMI client disconnected, looking for alternative",
240: 					zap.String("address", m.clients[activeIdx].address))
241: 				foundConnected := false
242: 				for i, client := range m.clients {
243: 					if i != int(activeIdx) && client.IsConnected() {
244: 						atomic.StoreInt32(&m.activeIdx, int32(i))
245: 						m.logger.Info("Switched to connected AMI client",
246: 							zap.String("from", m.clients[activeIdx].address),
247: 							zap.String("to", client.address))
248: 						foundConnected = true
249: 						break
250: 					}
251: 				}
252: 				if !foundConnected {
253: 					for i, client := range m.clients {
254: 						i, client := i, client
255: 						go func() {
256: 							connCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
257: 							defer cancel()
258: 							if err := client.Reconnect(connCtx); err != nil {
259: 								m.logger.Debug("Reconnection attempt failed",
260: 									zap.String("address", client.address),
261: 									zap.Error(err))
262: 							} else {
263: 								m.logger.Info("Reconnected AMI client",
264: 									zap.String("address", client.address))
265: 								if !foundConnected {
266: 									atomic.StoreInt32(&m.activeIdx, int32(i))
267: 									foundConnected = true
268: 								}
269: 							}
270: 						}()
271: 					}
272: 				}
273: 			}
274: 		}
275: 	}
276: }
277: func (m *Manager) tryReconnectOrFailover(ctx context.Context, currentIdx int) {
278: 	ctx, cancel := common.ContextWithTimeout(ctx, 15*time.Second)
279: 	defer cancel()
280: 	if err := m.clients[currentIdx].Reconnect(ctx); err != nil {
281: 		m.logger.Error("Failed to reconnect to AMI",
282: 			zap.String("address", m.clients[currentIdx].address),
283: 			zap.Error(err))
284: 		for i := 0; i < len(m.clients); i++ {
285: 			if i == currentIdx {
286: 				continue
287: 			}
288: 			if err := m.clients[i].Connect(ctx); err != nil {
289: 				m.logger.Error("Failed to connect to backup AMI",
290: 					zap.String("address", m.clients[i].address),
291: 					zap.Error(err))
292: 				continue
293: 			}
294: 			atomic.StoreInt32(&m.activeIdx, int32(i))
295: 			m.logger.Info("Switched to backup AMI",
296: 				zap.String("from", m.clients[currentIdx].address),
297: 				zap.String("to", m.clients[i].address))
298: 			m.replayPendingActions(ctx)
299: 			break
300: 		}
301: 	}
302: }
303: func (m *Manager) replayPendingActions(ctx context.Context) {
304: 	if m.storage == nil {
305: 		return
306: 	}
307: 	m.logger.Info("Replaying pending AMI actions")
308: 	timeoutCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
309: 	defer cancel()
310: 	actionIDs, err := m.storage.ListAMIActionIDs(timeoutCtx)
311: 	if err != nil {
312: 		m.logger.Error("Failed to retrieve pending AMI actions", zap.Error(err))
313: 		return
314: 	}
315: 	if len(actionIDs) == 0 {
316: 		m.logger.Info("No pending AMI actions to replay")
317: 		return
318: 	}
319: 	m.logger.Info("Found pending AMI actions to replay", zap.Int("count", len(actionIDs)))
320: 	client := m.GetActiveClient()
321: 	for _, actionID := range actionIDs {
322: 		action, err := m.storage.GetAMIAction(timeoutCtx, actionID)
323: 		if err != nil {
324: 			m.logger.Error("Failed to retrieve AMI action",
325: 				zap.String("actionID", actionID),
326: 				zap.Error(err))
327: 			continue
328: 		}
329: 		if !action.ExpireTime.IsZero() && action.ExpireTime.Before(time.Now()) {
330: 			m.logger.Debug("Skipping expired AMI action",
331: 				zap.String("actionID", actionID),
332: 				zap.Time("expireTime", action.ExpireTime))
333: 			m.storage.DeleteAMIAction(timeoutCtx, actionID)
334: 			continue
335: 		}
336: 		if action.Retries > 3 {
337: 			m.logger.Warn("AMI action exceeded retry limit",
338: 				zap.String("actionID", actionID),
339: 				zap.Int("retries", action.Retries))
340: 			m.storage.DeleteAMIAction(timeoutCtx, actionID)
341: 			continue
342: 		}
343: 		action.Retries++
344: 		m.storage.StoreAMIAction(timeoutCtx, action)
345: 		actionParams := make(map[string]string)
346: 		for k, v := range action.Params {
347: 			actionParams[k] = v
348: 		}
349: 		m.logger.Info("Replaying AMI action",
350: 			zap.String("actionID", actionID),
351: 			zap.String("command", action.Command),
352: 			zap.Int("retry", action.Retries))
353: 		response, err := client.SendAction(actionParams)
354: 		if err != nil {
355: 			m.logger.Error("Failed to replay AMI action",
356: 				zap.String("actionID", actionID),
357: 				zap.Error(err))
358: 			continue
359: 		}
360: 		if response["Response"] == "Success" {
361: 			m.logger.Info("Successfully replayed AMI action",
362: 				zap.String("actionID", actionID))
363: 			m.storage.DeleteAMIAction(timeoutCtx, actionID)
364: 		} else {
365: 			m.logger.Error("AMI action replay returned error",
366: 				zap.String("actionID", actionID),
367: 				zap.String("message", response["Message"]))
368: 		}
369: 	}
370: }
371: func (m *Manager) registerEventHandlers() {
372: 	for _, client := range m.clients {
373: 		client.RegisterEventHandler("*", func(event map[string]string) {
374: 			if eventName, ok := event["Event"]; ok {
375: 				m.logger.Debug("Received AMI event",
376: 					zap.String("event", eventName),
377: 					zap.String("address", client.address))
378: 				switch eventName {
379: 				case "Hangup":
380: 					m.handleHangupEvent(event)
381: 				case "NewChannel":
382: 					m.handleNewChannelEvent(event)
383: 				}
384: 			}
385: 		})
386: 	}
387: }
388: func (m *Manager) handleHangupEvent(event map[string]string) {
389: 	channel := event["Channel"]
390: 	cause := event["Cause"]
391: 	uniqueID := event["Uniqueid"]
392: 	m.logger.Info("Channel hangup",
393: 		zap.String("channel", channel),
394: 		zap.String("cause", cause),
395: 		zap.String("uniqueID", uniqueID))
396: }
397: func (m *Manager) handleNewChannelEvent(event map[string]string) {
398: 	channel := event["Channel"]
399: 	state := event["ChannelState"]
400: 	uniqueID := event["Uniqueid"]
401: 	m.logger.Info("New channel created",
402: 		zap.String("channel", channel),
403: 		zap.String("state", state),
404: 		zap.String("uniqueID", uniqueID))
405: }
406: func (m *Manager) GetActiveClient() *AMIClient {
407: 	idx := atomic.LoadInt32(&m.activeIdx)
408: 	return m.clients[idx]
409: }
410: func (m *Manager) IsConnected() bool {
411: 	if atomic.LoadInt32(&m.initializing) == 1 {
412: 		return true
413: 	}
414: 	client := m.GetActiveClient()
415: 	return client != nil && client.IsConnected()
416: }
417: func (m *Manager) SendAction(action map[string]string) (map[string]string, error) {
418: 	if _, ok := action["ActionID"]; !ok {
419: 		action["ActionID"] = fmt.Sprintf("AMI-%d", time.Now().UnixNano())
420: 	}
421: 	actionID := action["ActionID"]
422: 	if m.storage != nil {
423: 		ctx := context.Background()
424: 		m.storage.StoreAMIAction(ctx, &storage.AMIAction{
425: 			ActionID:   actionID,
426: 			Command:    "action",
427: 			Params:     action,
428: 			Timestamp:  time.Now(),
429: 			ExpireTime: time.Now().Add(1 * time.Hour),
430: 		})
431: 	}
432: 	client := m.GetActiveClient()
433: 	if !client.IsConnected() {
434: 		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
435: 		defer cancel()
436: 		if err := client.Connect(ctx); err != nil {
437: 			m.logger.Warn("Active AMI client not connected and reconnection failed",
438: 				zap.String("address", client.address),
439: 				zap.Error(err))
440: 			return m.failoverAction(context.Background(), action)
441: 		}
442: 	}
443: 	response, err := client.SendAction(action)
444: 	if err != nil {
445: 		m.logger.Warn("AMI action failed, trying failover",
446: 			zap.String("address", client.address),
447: 			zap.Error(err))
448: 		return m.failoverAction(context.Background(), action)
449: 	}
450: 	if m.storage != nil {
451: 		ctx := context.Background()
452: 		m.storage.DeleteAMIAction(ctx, actionID)
453: 	}
454: 	return response, nil
455: }
456: func (m *Manager) failoverAction(ctx context.Context, action map[string]string) (map[string]string, error) {
457: 	ctx, cancel := common.ContextWithTimeout(ctx, 10*time.Second)
458: 	defer cancel()
459: 	currentIdx := atomic.LoadInt32(&m.activeIdx)
460: 	for i := 0; i < len(m.clients); i++ {
461: 		idx := (int(currentIdx) + i + 1) % len(m.clients)
462: 		if idx == int(currentIdx) {
463: 			continue
464: 		}
465: 		client := m.clients[idx]
466: 		if err := client.Connect(ctx); err != nil {
467: 			m.logger.Warn("AMI failover connection failed",
468: 				zap.String("address", client.address),
469: 				zap.Error(err))
470: 			continue
471: 		}
472: 		response, err := client.SendAction(action)
473: 		if err != nil {
474: 			m.logger.Warn("AMI failover action failed",
475: 				zap.String("address", client.address),
476: 				zap.Error(err))
477: 			continue
478: 		}
479: 		atomic.StoreInt32(&m.activeIdx, int32(idx))
480: 		m.logger.Info("Switched active AMI client",
481: 			zap.String("from", m.clients[currentIdx].address),
482: 			zap.String("to", client.address))
483: 		if m.storage != nil {
484: 			actionID := action["ActionID"]
485: 			m.storage.DeleteAMIAction(ctx, actionID)
486: 		}
487: 		return response, nil
488: 	}
489: 	actionID := action["ActionID"]
490: 	if m.storage != nil {
491: 		amiAction, err := m.storage.GetAMIAction(ctx, actionID)
492: 		if err == nil && amiAction != nil {
493: 			amiAction.Retries++
494: 			m.storage.StoreAMIAction(ctx, amiAction)
495: 		}
496: 	}
497: 	return nil, fmt.Errorf("all AMI clients failed")
498: }
499: func (m *Manager) Originate(channel, exten, context, priority, application, data, callerId string, timeout int) (map[string]string, error) {
500: 	action := map[string]string{
501: 		"Action": "Originate",
502: 	}
503: 	if channel != "" {
504: 		action["Channel"] = channel
505: 	}
506: 	if exten != "" {
507: 		action["Exten"] = exten
508: 	}
509: 	if context != "" {
510: 		action["Context"] = context
511: 	}
512: 	if priority != "" {
513: 		action["Priority"] = priority
514: 	}
515: 	if application != "" {
516: 		action["Application"] = application
517: 	}
518: 	if data != "" {
519: 		action["Data"] = data
520: 	}
521: 	if callerId != "" {
522: 		action["CallerID"] = callerId
523: 	}
524: 	if timeout > 0 {
525: 		action["Timeout"] = fmt.Sprintf("%d", timeout)
526: 	}
527: 	return m.SendAction(action)
528: }
529: func (m *Manager) Hangup(channel, cause string) (map[string]string, error) {
530: 	action := map[string]string{
531: 		"Action":  "Hangup",
532: 		"Channel": channel,
533: 	}
534: 	if cause != "" {
535: 		action["Cause"] = cause
536: 	}
537: 	return m.SendAction(action)
538: }
539: func (m *Manager) Reconnect() error {
540: 	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
541: 	defer cancel()
542: 	activeIdx := atomic.LoadInt32(&m.activeIdx)
543: 	if err := m.clients[activeIdx].Reconnect(ctx); err == nil {
544: 		m.logger.Info("Reconnected active AMI client",
545: 			zap.String("address", m.clients[activeIdx].address))
546: 		return nil
547: 	}
548: 	for i, client := range m.clients {
549: 		if i == int(activeIdx) {
550: 			continue
551: 		}
552: 		if err := client.Reconnect(ctx); err == nil {
553: 			atomic.StoreInt32(&m.activeIdx, int32(i))
554: 			m.logger.Info("Reconnected and switched to backup AMI client",
555: 				zap.String("address", client.address))
556: 			return nil
557: 		}
558: 	}
559: 	return errors.New("failed to reconnect any AMI client")
560: }
561: func (m *Manager) Shutdown() {
562: 	m.mu.Lock()
563: 	defer m.mu.Unlock()
564: 	for _, client := range m.clients {
565: 		client.Disconnect()
566: 	}
567: }
</file>

<file path="gateway/pkg/ami/proxy.go">
  1: package ami
  2: import (
  3: 	"bufio"
  4: 	"fmt"
  5: 	"net"
  6: 	"strings"
  7: 	"sync"
  8: 	"time"
  9: 	"go.uber.org/zap"
 10: )
 11: type AMIProxyServer struct {
 12: 	listeners      map[string]net.Listener
 13: 	backendManager *BackendManager
 14: 	clients        map[net.Conn]clientInfo
 15: 	clientsMutex   sync.Mutex
 16: 	logger         *zap.Logger
 17: 	stopChan       chan struct{}
 18: 	coordinator    interface {
 19: 		IsLeader(components ...string) bool
 20: 	}
 21: 	running      bool
 22: 	runningMutex sync.Mutex
 23: }
 24: type clientInfo struct {
 25: 	reader        *bufio.Reader
 26: 	writer        *bufio.Writer
 27: 	authenticated bool
 28: 	username      string
 29: 	sourceAddr    string
 30: }
 31: type ProxyConfig struct {
 32: 	OriginalAddresses []string
 33: 	AmiConfigs        []Config
 34: }
 35: func NewProxyServer(config ProxyConfig, coordinator interface {
 36: 	IsLeader(components ...string) bool
 37: }, logger *zap.Logger) (*AMIProxyServer, error) {
 38: 	backendManager, err := NewBackendManager(config.AmiConfigs, logger)
 39: 	if err != nil {
 40: 		return nil, fmt.Errorf("failed to create backend manager: %w", err)
 41: 	}
 42: 	server := &AMIProxyServer{
 43: 		listeners:      make(map[string]net.Listener),
 44: 		backendManager: backendManager,
 45: 		clients:        make(map[net.Conn]clientInfo),
 46: 		logger:         logger,
 47: 		stopChan:       make(chan struct{}),
 48: 		coordinator:    coordinator,
 49: 		running:        false,
 50: 	}
 51: 	for _, addr := range config.OriginalAddresses {
 52: 		listener, err := net.Listen("tcp", addr)
 53: 		if err != nil {
 54: 			logger.Error("Failed to listen on original AMI address",
 55: 				zap.String("address", addr),
 56: 				zap.Error(err))
 57: 			continue
 58: 		}
 59: 		server.listeners[addr] = listener
 60: 		logger.Info("Created AMI proxy listener", zap.String("address", addr))
 61: 	}
 62: 	if len(server.listeners) == 0 {
 63: 		return nil, fmt.Errorf("failed to create any listeners for original AMI addresses")
 64: 	}
 65: 	return server, nil
 66: }
 67: func (s *AMIProxyServer) Start() error {
 68: 	s.runningMutex.Lock()
 69: 	if s.running {
 70: 		s.runningMutex.Unlock()
 71: 		return nil
 72: 	}
 73: 	s.running = true
 74: 	s.runningMutex.Unlock()
 75: 	for addr, listener := range s.listeners {
 76: 		go s.acceptLoop(addr, listener)
 77: 	}
 78: 	s.logger.Info("AMI proxy server started",
 79: 		zap.Int("listenerCount", len(s.listeners)))
 80: 	return nil
 81: }
 82: func (s *AMIProxyServer) Stop() error {
 83: 	s.runningMutex.Lock()
 84: 	if !s.running {
 85: 		s.runningMutex.Unlock()
 86: 		return nil
 87: 	}
 88: 	s.running = false
 89: 	s.runningMutex.Unlock()
 90: 	close(s.stopChan)
 91: 	for addr, listener := range s.listeners {
 92: 		if err := listener.Close(); err != nil {
 93: 			s.logger.Error("Error closing listener",
 94: 				zap.String("address", addr),
 95: 				zap.Error(err))
 96: 		}
 97: 	}
 98: 	s.clientsMutex.Lock()
 99: 	for conn := range s.clients {
100: 		conn.Close()
101: 	}
102: 	s.clientsMutex.Unlock()
103: 	s.logger.Info("AMI proxy server stopped")
104: 	return nil
105: }
106: func (s *AMIProxyServer) acceptLoop(addr string, listener net.Listener) {
107: 	s.logger.Info("Starting accept loop for AMI address", zap.String("address", addr))
108: 	for {
109: 		select {
110: 		case <-s.stopChan:
111: 			return
112: 		default:
113: 			if !s.coordinator.IsLeader("ami") {
114: 				time.Sleep(1 * time.Second)
115: 				continue
116: 			}
117: 			conn, err := listener.Accept()
118: 			if err != nil {
119: 				select {
120: 				case <-s.stopChan:
121: 					return
122: 				default:
123: 					s.logger.Error("Error accepting connection",
124: 						zap.String("address", addr),
125: 						zap.Error(err))
126: 					time.Sleep(100 * time.Millisecond)
127: 					continue
128: 				}
129: 			}
130: 			s.clientsMutex.Lock()
131: 			s.clients[conn] = clientInfo{
132: 				reader:     bufio.NewReader(conn),
133: 				writer:     bufio.NewWriter(conn),
134: 				sourceAddr: addr,
135: 			}
136: 			s.clientsMutex.Unlock()
137: 			go s.handleClient(conn)
138: 		}
139: 	}
140: }
141: func (s *AMIProxyServer) handleClient(conn net.Conn) {
142: 	defer func() {
143: 		conn.Close()
144: 		s.clientsMutex.Lock()
145: 		delete(s.clients, conn)
146: 		s.clientsMutex.Unlock()
147: 		s.logger.Debug("Client disconnected", zap.String("remote", conn.RemoteAddr().String()))
148: 	}()
149: 	s.clientsMutex.Lock()
150: 	info := s.clients[conn]
151: 	s.clientsMutex.Unlock()
152: 	banner := "Asterisk Call Manager/1.4\r\n"
153: 	_, err := info.writer.WriteString(banner)
154: 	if err != nil {
155: 		s.logger.Error("Failed to send banner", zap.Error(err))
156: 		return
157: 	}
158: 	info.writer.Flush()
159: 	activeBackend := s.backendManager.GetActiveClient()
160: 	clientConn := conn
161: 	activeBackend.RegisterEventHandler("*", func(event map[string]string) {
162: 		s.clientsMutex.Lock()
163: 		if clientInfo, exists := s.clients[clientConn]; exists {
164: 			if !clientInfo.authenticated {
165: 				s.clientsMutex.Unlock()
166: 				return
167: 			}
168: 			var buf strings.Builder
169: 			for k, v := range event {
170: 				buf.WriteString(fmt.Sprintf("%s: %s\r\n", k, v))
171: 			}
172: 			buf.WriteString("\r\n")
173: 			_, err := clientInfo.writer.WriteString(buf.String())
174: 			if err == nil {
175: 				clientInfo.writer.Flush()
176: 			}
177: 		}
178: 		s.clientsMutex.Unlock()
179: 	})
180: 	for {
181: 		action, err := s.readAction(conn)
182: 		if err != nil {
183: 			s.logger.Debug("Client connection closed",
184: 				zap.String("remote", conn.RemoteAddr().String()),
185: 				zap.Error(err))
186: 			return
187: 		}
188: 		if strings.EqualFold(action["Action"], "login") {
189: 			s.handleLoginAction(conn, action)
190: 			continue
191: 		}
192: 		s.clientsMutex.Lock()
193: 		authenticated := s.clients[conn].authenticated
194: 		s.clientsMutex.Unlock()
195: 		if !authenticated {
196: 			s.sendErrorResponse(conn, "Not authenticated")
197: 			continue
198: 		}
199: 		response, err := s.backendManager.SendAction(action)
200: 		if err != nil {
201: 			s.sendErrorResponse(conn, err.Error())
202: 			continue
203: 		}
204: 		s.sendResponse(conn, response)
205: 	}
206: }
207: func (s *AMIProxyServer) readAction(conn net.Conn) (map[string]string, error) {
208: 	s.clientsMutex.Lock()
209: 	info, exists := s.clients[conn]
210: 	if !exists {
211: 		s.clientsMutex.Unlock()
212: 		return nil, fmt.Errorf("client not found")
213: 	}
214: 	reader := info.reader
215: 	s.clientsMutex.Unlock()
216: 	action := make(map[string]string)
217: 	for {
218: 		line, err := reader.ReadString('\n')
219: 		if err != nil {
220: 			return nil, err
221: 		}
222: 		line = strings.TrimSpace(line)
223: 		if line == "" {
224: 			break // End of action
225: 		}
226: 		parts := strings.SplitN(line, ":", 2)
227: 		if len(parts) != 2 {
228: 			continue // Invalid line
229: 		}
230: 		key := strings.TrimSpace(parts[0])
231: 		value := strings.TrimSpace(parts[1])
232: 		action[key] = value
233: 	}
234: 	return action, nil
235: }
236: // handleLoginAction processes a login action
237: func (s *AMIProxyServer) handleLoginAction(conn net.Conn, action map[string]string) {
238: 	username := action["Username"]
239: 	secret := action["Secret"]
240: 	if username == "" || secret == "" {
241: 		s.sendErrorResponse(conn, "Missing credentials")
242: 		return
243: 	}
244: 	activeClient := s.backendManager.GetActiveClient()
245: 	loginAction := map[string]string{
246: 		"Action":   "Login",
247: 		"Username": username,
248: 		"Secret":   secret,
249: 	}
250: 	response, err := activeClient.SendAction(loginAction)
251: 	if err != nil || response["Response"] != "Success" {
252: 		s.sendErrorResponse(conn, "Authentication failed")
253: 		return
254: 	}
255: 	s.clientsMutex.Lock()
256: 	info := s.clients[conn]
257: 	info.authenticated = true
258: 	info.username = username
259: 	s.clients[conn] = info
260: 	s.clientsMutex.Unlock()
261: 	s.sendResponse(conn, map[string]string{
262: 		"Response": "Success",
263: 		"Message":  "Authentication accepted",
264: 	})
265: }
266: func (s *AMIProxyServer) sendErrorResponse(conn net.Conn, message string) {
267: 	s.sendResponse(conn, map[string]string{
268: 		"Response": "Error",
269: 		"Message":  message,
270: 	})
271: }
272: func (s *AMIProxyServer) sendResponse(conn net.Conn, response map[string]string) {
273: 	s.clientsMutex.Lock()
274: 	info, exists := s.clients[conn]
275: 	if !exists {
276: 		s.clientsMutex.Unlock()
277: 		return
278: 	}
279: 	writer := info.writer
280: 	s.clientsMutex.Unlock()
281: 	var buf strings.Builder
282: 	for k, v := range response {
283: 		buf.WriteString(fmt.Sprintf("%s: %s\r\n", k, v))
284: 	}
285: 	buf.WriteString("\r\n")
286: 	_, err := writer.WriteString(buf.String())
287: 	if err != nil {
288: 		s.logger.Error("Failed to send response", zap.Error(err))
289: 		return
290: 	}
291: 	writer.Flush()
292: }
</file>

<file path="gateway/pkg/common/circuit_breaker.go">
  1: package common
  2: import (
  3: 	"sync"
  4: 	"sync/atomic"
  5: 	"time"
  6: 	"go.uber.org/zap"
  7: )
  8: type CircuitBreakerState int32
  9: const (
 10: 	StateClosed CircuitBreakerState = iota
 11: 	StateOpen
 12: 	StateHalfOpen
 13: )
 14: type CircuitBreaker struct {
 15: 	name                string
 16: 	state               int32
 17: 	failureThreshold    int32
 18: 	resetTimeout        time.Duration
 19: 	halfOpenMaxReqs     int32
 20: 	halfOpenReqs        int32
 21: 	consecutiveFailures int32
 22: 	lastStateChange     time.Time
 23: 	lastFailure         time.Time
 24: 	totalRequests  int64
 25: 	totalSuccesses int64
 26: 	totalFailures  int64
 27: 	opens          int64
 28: 	mu     sync.RWMutex
 29: 	logger *zap.Logger
 30: }
 31: type CircuitBreakerConfig struct {
 32: 	FailureThreshold int           `json:"failure_threshold"`
 33: 	ResetTimeout     time.Duration `json:"reset_timeout"`
 34: 	HalfOpenMaxReqs  int           `json:"half_open_max_requests"`
 35: }
 36: func NewCircuitBreaker(name string, config CircuitBreakerConfig, logger *zap.Logger) *CircuitBreaker {
 37: 	if logger == nil {
 38: 		logger, _ = zap.NewProduction()
 39: 	}
 40: 	failureThreshold := int32(config.FailureThreshold)
 41: 	if failureThreshold <= 0 {
 42: 		failureThreshold = 5
 43: 	}
 44: 	resetTimeout := config.ResetTimeout
 45: 	if resetTimeout <= 0 {
 46: 		resetTimeout = 30 * time.Second
 47: 	}
 48: 	halfOpenMaxReqs := int32(config.HalfOpenMaxReqs)
 49: 	if halfOpenMaxReqs <= 0 {
 50: 		halfOpenMaxReqs = 3
 51: 	}
 52: 	return &CircuitBreaker{
 53: 		name:             name,
 54: 		state:            int32(StateClosed),
 55: 		failureThreshold: failureThreshold,
 56: 		resetTimeout:     resetTimeout,
 57: 		halfOpenMaxReqs:  halfOpenMaxReqs,
 58: 		lastStateChange:  time.Now(),
 59: 		logger:           logger,
 60: 	}
 61: }
 62: func (cb *CircuitBreaker) GetState() CircuitBreakerState {
 63: 	return CircuitBreakerState(atomic.LoadInt32(&cb.state))
 64: }
 65: func (cb *CircuitBreaker) AllowRequest() bool {
 66: 	atomic.AddInt64(&cb.totalRequests, 1)
 67: 	for {
 68: 		state := CircuitBreakerState(atomic.LoadInt32(&cb.state))
 69: 		switch state {
 70: 		case StateClosed:
 71: 			return true
 72: 		case StateOpen:
 73: 			cb.mu.RLock()
 74: 			timeout := time.Since(cb.lastStateChange) > cb.resetTimeout
 75: 			cb.mu.RUnlock()
 76: 			if !timeout {
 77: 				return false
 78: 			}
 79: 			if atomic.CompareAndSwapInt32(&cb.state, int32(StateOpen), int32(StateHalfOpen)) {
 80: 				cb.mu.Lock()
 81: 				cb.lastStateChange = time.Now()
 82: 				cb.halfOpenReqs = 0
 83: 				cb.mu.Unlock()
 84: 				cb.logger.Info("Circuit half-open - testing recovery",
 85: 					zap.String("circuit", cb.name))
 86: 				continue
 87: 			}
 88: 			continue
 89: 		case StateHalfOpen:
 90: 			reqs := atomic.AddInt32(&cb.halfOpenReqs, 1)
 91: 			return reqs <= cb.halfOpenMaxReqs
 92: 		}
 93: 		return false
 94: 	}
 95: }
 96: func (cb *CircuitBreaker) RecordSuccess() {
 97: 	atomic.AddInt64(&cb.totalSuccesses, 1)
 98: 	atomic.StoreInt32(&cb.consecutiveFailures, 0)
 99: 	state := CircuitBreakerState(atomic.LoadInt32(&cb.state))
100: 	if state == StateHalfOpen {
101: 		if atomic.CompareAndSwapInt32(&cb.state, int32(StateHalfOpen), int32(StateClosed)) {
102: 			cb.mu.Lock()
103: 			cb.lastStateChange = time.Now()
104: 			cb.mu.Unlock()
105: 			cb.logger.Info("Circuit closed - service recovered",
106: 				zap.String("circuit", cb.name))
107: 		}
108: 	}
109: }
110: func (cb *CircuitBreaker) RecordFailure() {
111: 	atomic.AddInt64(&cb.totalFailures, 1)
112: 	failures := atomic.AddInt32(&cb.consecutiveFailures, 1)
113: 	cb.mu.Lock()
114: 	cb.lastFailure = time.Now()
115: 	cb.mu.Unlock()
116: 	state := CircuitBreakerState(atomic.LoadInt32(&cb.state))
117: 	threshold := atomic.LoadInt32(&cb.failureThreshold)
118: 	if (state == StateClosed && failures >= threshold) || state == StateHalfOpen {
119: 		if atomic.CompareAndSwapInt32(&cb.state, int32(state), int32(StateOpen)) {
120: 			atomic.AddInt64(&cb.opens, 1)
121: 			cb.mu.Lock()
122: 			cb.lastStateChange = time.Now()
123: 			cb.mu.Unlock()
124: 			cb.logger.Warn("Circuit opened due to failures",
125: 				zap.String("circuit", cb.name),
126: 				zap.Int32("failures", failures),
127: 				zap.Int32("threshold", threshold))
128: 		}
129: 	}
130: }
131: func (cb *CircuitBreaker) GetMetrics() map[string]int64 {
132: 	return map[string]int64{
133: 		"requests":  atomic.LoadInt64(&cb.totalRequests),
134: 		"successes": atomic.LoadInt64(&cb.totalSuccesses),
135: 		"failures":  atomic.LoadInt64(&cb.totalFailures),
136: 		"opens":     atomic.LoadInt64(&cb.opens),
137: 	}
138: }
139: func (cb *CircuitBreaker) Reset() {
140: 	atomic.StoreInt32(&cb.state, int32(StateClosed))
141: 	atomic.StoreInt32(&cb.consecutiveFailures, 0)
142: 	cb.mu.Lock()
143: 	cb.lastStateChange = time.Now()
144: 	cb.mu.Unlock()
145: 	cb.logger.Info("Circuit manually reset", zap.String("circuit", cb.name))
146: }
</file>

<file path="gateway/pkg/common/context.go">
 1: package common
 2: import (
 3: 	"context"
 4: 	"time"
 5: )
 6: const DefaultTimeout = 30 * time.Second
 7: func EnsureTimeout(ctx context.Context, timeout time.Duration) (context.Context, context.CancelFunc) {
 8: 	if deadline, ok := ctx.Deadline(); ok {
 9: 		remaining := time.Until(deadline)
10: 		if remaining > 0 {
11: 			return ctx, func() {}
12: 		}
13: 	}
14: 	return context.WithTimeout(ctx, timeout)
15: }
16: func ContextWithTimeout(parent context.Context, timeout time.Duration) (context.Context, context.CancelFunc) {
17: 	return EnsureTimeout(parent, timeout)
18: }
19: func QuickTimeout(parent context.Context) (context.Context, context.CancelFunc) {
20: 	return EnsureTimeout(parent, 5*time.Second)
21: }
22: func LongTimeout(parent context.Context) (context.Context, context.CancelFunc) {
23: 	return EnsureTimeout(parent, 2*time.Minute)
24: }
</file>

<file path="gateway/pkg/common/goroutine.go">
 1: package common
 2: import (
 3: 	"context"
 4: 	"fmt"
 5: 	"runtime"
 6: 	"sync"
 7: 	"sync/atomic"
 8: 	"time"
 9: 	"go.uber.org/zap"
10: )
11: type GoroutineRegistry struct {
12: 	wg         sync.WaitGroup
13: 	ctx        context.Context
14: 	cancel     context.CancelFunc
15: 	total      int64
16: 	active     int64
17: 	panicCount int64
18: 	logger     *zap.Logger
19: }
20: func NewGoroutineRegistry(logger *zap.Logger) *GoroutineRegistry {
21: 	if logger == nil {
22: 		logger, _ = zap.NewProduction()
23: 	}
24: 	ctx, cancel := context.WithCancel(context.Background())
25: 	return &GoroutineRegistry{
26: 		ctx:    ctx,
27: 		cancel: cancel,
28: 		logger: logger,
29: 	}
30: }
31: func (gr *GoroutineRegistry) Go(name string, f func(ctx context.Context)) {
32: 	gr.wg.Add(1)
33: 	id := atomic.AddInt64(&gr.total, 1)
34: 	atomic.AddInt64(&gr.active, 1)
35: 	go func() {
36: 		defer gr.wg.Done()
37: 		defer atomic.AddInt64(&gr.active, -1)
38: 		defer func() {
39: 			if r := recover(); r != nil {
40: 				atomic.AddInt64(&gr.panicCount, 1)
41: 				stack := make([]byte, 4096)
42: 				stack = stack[:runtime.Stack(stack, false)]
43: 				gr.logger.Error("Goroutine panic",
44: 					zap.String("name", name),
45: 					zap.Int64("id", id),
46: 					zap.Any("panic", r),
47: 					zap.String("stack", string(stack)))
48: 			}
49: 		}()
50: 		gr.logger.Debug("Starting goroutine",
51: 			zap.String("name", name),
52: 			zap.Int64("id", id))
53: 		f(gr.ctx)
54: 		gr.logger.Debug("Goroutine completed",
55: 			zap.String("name", name),
56: 			zap.Int64("id", id))
57: 	}()
58: }
59: func (gr *GoroutineRegistry) Shutdown(timeout time.Duration) error {
60: 	gr.logger.Info("Shutting down goroutine registry",
61: 		zap.Int64("activeCount", atomic.LoadInt64(&gr.active)))
62: 	gr.cancel()
63: 	done := make(chan struct{})
64: 	ctx, cancel := context.WithTimeout(context.Background(), timeout)
65: 	defer cancel()
66: 	go func() {
67: 		gr.wg.Wait()
68: 		close(done)
69: 	}()
70: 	select {
71: 	case <-done:
72: 		gr.logger.Info("All goroutines have exited")
73: 		return nil
74: 	case <-ctx.Done():
75: 		gr.logger.Warn("Shutdown timed out, some goroutines didn't exit",
76: 			zap.Int64("remaining", atomic.LoadInt64(&gr.active)),
77: 			zap.Duration("timeout", timeout))
78: 		return fmt.Errorf("shutdown timed out, %d goroutines didn't exit",
79: 			atomic.LoadInt64(&gr.active))
80: 	}
81: }
82: func (gr *GoroutineRegistry) ActiveCount() int64 {
83: 	return atomic.LoadInt64(&gr.active)
84: }
85: func (gr *GoroutineRegistry) Context() context.Context {
86: 	return gr.ctx
87: }
88: func (gr *GoroutineRegistry) TotalCount() int64 {
89: 	return atomic.LoadInt64(&gr.total)
90: }
91: func (gr *GoroutineRegistry) PanicCount() int64 {
92: 	return atomic.LoadInt64(&gr.panicCount)
93: }
</file>

<file path="gateway/pkg/common/metrics.go">
  1: package common
  2: import (
  3: 	"context"
  4: 	"net/http"
  5: 	"sync"
  6: 	"time"
  7: 	"github.com/prometheus/client_golang/prometheus"
  8: 	"github.com/prometheus/client_golang/prometheus/promhttp"
  9: 	"go.uber.org/zap"
 10: )
 11: type MetricsServer struct {
 12: 	registry        *prometheus.Registry
 13: 	server          *http.Server
 14: 	collectors      []prometheus.Collector
 15: 	logger          *zap.Logger
 16: 	callsActive     prometheus.Gauge
 17: 	callsTotal      prometheus.Counter
 18: 	callDuration    prometheus.Histogram
 19: 	errors          *prometheus.CounterVec
 20: 	rtpSessions     prometheus.Gauge
 21: 	sipTransactions prometheus.Gauge
 22: 	mu              sync.Mutex
 23: }
 24: func NewMetricsServer(addr string, logger *zap.Logger) (*MetricsServer, error) {
 25: 	if logger == nil {
 26: 		var err error
 27: 		logger, err = zap.NewProduction()
 28: 		if err != nil {
 29: 			return nil, err
 30: 		}
 31: 	}
 32: 	registry := prometheus.NewRegistry()
 33: 	callsActive := prometheus.NewGauge(prometheus.GaugeOpts{
 34: 		Name: "gateway_calls_active",
 35: 		Help: "The number of currently active calls",
 36: 	})
 37: 	callsTotal := prometheus.NewCounter(prometheus.CounterOpts{
 38: 		Name: "gateway_calls_total",
 39: 		Help: "The total number of calls processed",
 40: 	})
 41: 	callDuration := prometheus.NewHistogram(prometheus.HistogramOpts{
 42: 		Name:    "gateway_call_duration_seconds",
 43: 		Help:    "The duration of calls in seconds",
 44: 		Buckets: prometheus.ExponentialBuckets(10, 2, 10),
 45: 	})
 46: 	errors := prometheus.NewCounterVec(prometheus.CounterOpts{
 47: 		Name: "gateway_errors_total",
 48: 		Help: "The total number of errors by type",
 49: 	}, []string{"type"})
 50: 	rtpSessions := prometheus.NewGauge(prometheus.GaugeOpts{
 51: 		Name: "gateway_rtp_sessions",
 52: 		Help: "The number of active RTP sessions",
 53: 	})
 54: 	sipTransactions := prometheus.NewGauge(prometheus.GaugeOpts{
 55: 		Name: "gateway_sip_transactions",
 56: 		Help: "The number of active SIP transactions",
 57: 	})
 58: 	registry.MustRegister(callsActive)
 59: 	registry.MustRegister(callsTotal)
 60: 	registry.MustRegister(callDuration)
 61: 	registry.MustRegister(errors)
 62: 	registry.MustRegister(rtpSessions)
 63: 	registry.MustRegister(sipTransactions)
 64: 	registry.MustRegister(prometheus.NewGoCollector())
 65: 	registry.MustRegister(prometheus.NewProcessCollector(prometheus.ProcessCollectorOpts{}))
 66: 	mux := http.NewServeMux()
 67: 	mux.Handle("/metrics", promhttp.HandlerFor(registry, promhttp.HandlerOpts{}))
 68: 	server := &http.Server{
 69: 		Addr:    addr,
 70: 		Handler: mux,
 71: 	}
 72: 	return &MetricsServer{
 73: 		registry:        registry,
 74: 		server:          server,
 75: 		logger:          logger,
 76: 		callsActive:     callsActive,
 77: 		callsTotal:      callsTotal,
 78: 		callDuration:    callDuration,
 79: 		errors:          errors,
 80: 		rtpSessions:     rtpSessions,
 81: 		sipTransactions: sipTransactions,
 82: 	}, nil
 83: }
 84: func (m *MetricsServer) Start(ctx context.Context) error {
 85: 	go func() {
 86: 		m.logger.Info("Starting metrics server", zap.String("addr", m.server.Addr))
 87: 		if err := m.server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
 88: 			m.logger.Error("Metrics server failed", zap.Error(err))
 89: 		}
 90: 	}()
 91: 	<-ctx.Done()
 92: 	shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
 93: 	defer cancel()
 94: 	m.logger.Info("Shutting down metrics server")
 95: 	return m.server.Shutdown(shutdownCtx)
 96: }
 97: func (m *MetricsServer) RegisterCollector(collector prometheus.Collector) {
 98: 	m.mu.Lock()
 99: 	defer m.mu.Unlock()
100: 	m.registry.MustRegister(collector)
101: 	m.collectors = append(m.collectors, collector)
102: }
103: func (m *MetricsServer) IncrementCallsActive() {
104: 	m.callsActive.Inc()
105: }
106: func (m *MetricsServer) DecrementCallsActive() {
107: 	m.callsActive.Dec()
108: }
109: func (m *MetricsServer) IncrementCallsTotal() {
110: 	m.callsTotal.Inc()
111: }
112: func (m *MetricsServer) ObserveCallDuration(duration time.Duration) {
113: 	m.callDuration.Observe(duration.Seconds())
114: }
115: func (m *MetricsServer) IncrementError(errorType string) {
116: 	m.errors.WithLabelValues(errorType).Inc()
117: }
118: func (m *MetricsServer) SetRTPSessions(count int) {
119: 	m.rtpSessions.Set(float64(count))
120: }
121: func (m *MetricsServer) SetSIPTransactions(count int) {
122: 	m.sipTransactions.Set(float64(count))
123: }
</file>

<file path="gateway/pkg/config/config.go">
  1: package config
  2: import (
  3: 	"fmt"
  4: 	"io/ioutil"
  5: 	"time"
  6: 	"gopkg.in/yaml.v3"
  7: 	"gateway/pkg/ami"
  8: 	"gateway/pkg/common"
  9: 	"gateway/pkg/rtpengine"
 10: )
 11: type Config struct {
 12: 	LogLevel            string          `yaml:"log_level"`
 13: 	ShutdownWaitSeconds int             `yaml:"shutdown_wait_seconds"`
 14: 	Redis               RedisConfig     `yaml:"redis"`
 15: 	MemoryStorage       MemoryConfig    `yaml:"memory_storage"`
 16: 	RTPEngine           RTPEngineConfig `yaml:"rtpengine"`
 17: 	Asterisk            AsteriskConfig  `yaml:"asterisk"`
 18: 	SIP                 SIPConfig       `yaml:"sip"`
 19: 	WebSocket           WebSocketConfig `yaml:"websocket"`
 20: 	Metrics             MetricsConfig   `yaml:"metrics"`
 21: 	HighAvailability    HAConfig        `yaml:"high_availability"`
 22: }
 23: type RedisConfig struct {
 24: 	Enabled     bool     `yaml:"enabled"`
 25: 	Addresses   []string `yaml:"addresses"`
 26: 	Password    string   `yaml:"password"`
 27: 	DB          int      `yaml:"db"`
 28: 	PoolSize    int      `yaml:"pool_size"`
 29: 	MaxRetries  int      `yaml:"max_retries"`
 30: 	DialTimeout int      `yaml:"dial_timeout_ms"`
 31: }
 32: type MemoryConfig struct {
 33: 	MaxKeys                int    `yaml:"max_keys"`
 34: 	CleanupIntervalSeconds int    `yaml:"cleanup_interval_seconds"`
 35: 	PersistPath            string `yaml:"persist_path"`
 36: 	PersistOnShutdown      bool   `yaml:"persist_on_shutdown"`
 37: 	ShardCount             int    `yaml:"shard_count"`
 38: }
 39: type RTPEngineConfig struct {
 40: 	Engines []RTPEngineInstanceConfig `yaml:"engines"`
 41: }
 42: type RTPEngineInstanceConfig struct {
 43: 	Address        string               `yaml:"address"`
 44: 	Port           int                  `yaml:"port"`
 45: 	TimeoutMS      int                  `yaml:"timeout_ms"`
 46: 	Weight         int                  `yaml:"weight"`
 47: 	CircuitBreaker CircuitBreakerConfig `yaml:"circuit_breaker"`
 48: }
 49: type AsteriskConfig struct {
 50: 	Clients                    []AsteriskClientConfig `yaml:"clients"`
 51: 	DefaultClient              int                    `yaml:"default_client"`
 52: 	HealthCheckIntervalSeconds int                    `yaml:"health_check_interval_seconds"`
 53: 	ConnectionTimeoutSeconds   int                    `yaml:"connection_timeout_seconds"`
 54: 	EnableReconnect            bool                   `yaml:"enable_reconnect"`
 55: 	ReconnectIntervalSeconds   int                    `yaml:"reconnect_interval_seconds"`
 56: 	MaxReconnectAttempts       int                    `yaml:"max_reconnect_attempts"`
 57: 	MaxRetries                 int                    `yaml:"max_retries"`
 58: 	RetryDelay                 string                 `yaml:"retry_delay"`
 59: 	EnableHAProxy     bool     `yaml:"enable_ha_proxy"`
 60: 	OriginalAddresses []string `yaml:"original_addresses"`
 61: }
 62: type AsteriskClientConfig struct {
 63: 	Address        string               `yaml:"address"`
 64: 	Username       string               `yaml:"username"`
 65: 	Secret         string               `yaml:"secret"`
 66: 	TimeoutMS      int                  `yaml:"timeout_ms"`
 67: 	CircuitBreaker CircuitBreakerConfig `yaml:"circuit_breaker"`
 68: }
 69: type SIPConfig struct {
 70: 	UDPBindAddr             string `yaml:"udp_bind_addr"`
 71: 	ProxyURI                string `yaml:"proxy_uri"`
 72: 	DefaultNextHop          string `yaml:"default_next_hop"`
 73: 	MaxForwards             int    `yaml:"max_forwards"`
 74: 	UserAgent               string `yaml:"user_agent"`
 75: 	DisableSIPProcessing    bool   `yaml:"disable_sip_processing"`
 76: 	DisableUDPSIPProcessing bool   `yaml:"disable_udp_sip_processing"`
 77: 	DisableWSSIPProcessing  bool   `yaml:"disable_ws_sip_processing"`
 78: }
 79: type WebSocketConfig struct {
 80: 	BindAddr                string   `yaml:"bind_addr"`
 81: 	CertFile                string   `yaml:"cert_file"`
 82: 	KeyFile                 string   `yaml:"key_file"`
 83: 	MaxConnections          int      `yaml:"max_connections"`
 84: 	ReadTimeoutMS           int      `yaml:"read_timeout_ms"`
 85: 	WriteTimeoutMS          int      `yaml:"write_timeout_ms"`
 86: 	IdleTimeoutMS           int      `yaml:"idle_timeout_ms"`
 87: 	EnableIPv4Only          bool     `yaml:"enable_ipv4_only"`
 88: 	ServerName              string   `yaml:"server_name"`
 89: 	BackendServers          []string `yaml:"backend_servers"`
 90: 	FailoverThreshold       int      `yaml:"failover_threshold"`
 91: 	DisableUDPSIPProcessing bool     `yaml:"disable_udp_sip_processing"`
 92: 	DisableSIPProcessing    bool     `yaml:"disable_sip_processing"`
 93: 	DisableWSSIPProcessing  bool     `yaml:"disable_ws_sip_processing"`
 94: }
 95: type MetricsConfig struct {
 96: 	Enabled  bool   `yaml:"enabled"`
 97: 	BindAddr string `yaml:"bind_addr"`
 98: }
 99: type HAConfig struct {
100: 	Enabled           bool   `yaml:"enabled"`
101: 	HeartbeatInterval int    `yaml:"heartbeat_interval_ms"`
102: 	LeaseTimeout      int    `yaml:"lease_timeout_ms"`
103: 	NodeID            string `yaml:"node_id"`
104: }
105: type CircuitBreakerConfig struct {
106: 	FailureThreshold int `yaml:"failure_threshold"`
107: 	ResetSeconds     int `yaml:"reset_seconds"`
108: 	HalfOpenMax      int `yaml:"half_open_max"`
109: }
110: func LoadConfig(path string) (*Config, error) {
111: 	data, err := ioutil.ReadFile(path)
112: 	if err != nil {
113: 		return nil, fmt.Errorf("failed to read config file: %w", err)
114: 	}
115: 	var config Config
116: 	if err := yaml.Unmarshal(data, &config); err != nil {
117: 		return nil, fmt.Errorf("failed to parse config file: %w", err)
118: 	}
119: 	if config.LogLevel == "" {
120: 		config.LogLevel = "info"
121: 	}
122: 	if config.ShutdownWaitSeconds <= 0 {
123: 		config.ShutdownWaitSeconds = 30
124: 	}
125: 	if config.MemoryStorage.MaxKeys <= 0 {
126: 		config.MemoryStorage.MaxKeys = 10000
127: 	}
128: 	if config.MemoryStorage.CleanupIntervalSeconds <= 0 {
129: 		config.MemoryStorage.CleanupIntervalSeconds = 300
130: 	}
131: 	if config.MemoryStorage.ShardCount <= 0 {
132: 		config.MemoryStorage.ShardCount = 32
133: 	}
134: 	if config.SIP.MaxForwards <= 0 {
135: 		config.SIP.MaxForwards = 70
136: 	}
137: 	if config.SIP.UserAgent == "" {
138: 		config.SIP.UserAgent = "WebRTC-SIP Gateway"
139: 	}
140: 	if config.WebSocket.MaxConnections <= 0 {
141: 		config.WebSocket.MaxConnections = 1000
142: 	}
143: 	if config.WebSocket.ReadTimeoutMS <= 0 {
144: 		config.WebSocket.ReadTimeoutMS = 30000
145: 	}
146: 	if config.WebSocket.WriteTimeoutMS <= 0 {
147: 		config.WebSocket.WriteTimeoutMS = 30000
148: 	}
149: 	if config.WebSocket.IdleTimeoutMS <= 0 {
150: 		config.WebSocket.IdleTimeoutMS = 120000
151: 	}
152: 	if config.WebSocket.ServerName == "" {
153: 		config.WebSocket.ServerName = "WebRTC-SIP Gateway"
154: 	}
155: 	if config.HighAvailability.HeartbeatInterval <= 0 {
156: 		config.HighAvailability.HeartbeatInterval = 5000
157: 	}
158: 	if config.HighAvailability.LeaseTimeout <= 0 {
159: 		config.HighAvailability.LeaseTimeout = 15000
160: 	}
161: 	return &config, nil
162: }
163: func (c *Config) ToRTPEngineManagerConfig() rtpengine.ManagerConfig {
164: 	engines := make([]rtpengine.Config, 0, len(c.RTPEngine.Engines))
165: 	for _, eng := range c.RTPEngine.Engines {
166: 		engines = append(engines, rtpengine.Config{
167: 			Address: eng.Address,
168: 			Port:    eng.Port,
169: 			Timeout: time.Duration(eng.TimeoutMS) * time.Millisecond,
170: 			Weight:  eng.Weight,
171: 			CircuitBreaker: common.CircuitBreakerConfig{
172: 				FailureThreshold: eng.CircuitBreaker.FailureThreshold,
173: 				ResetTimeout:     time.Duration(eng.CircuitBreaker.ResetSeconds) * time.Second,
174: 				HalfOpenMaxReqs:  eng.CircuitBreaker.HalfOpenMax,
175: 			},
176: 		})
177: 	}
178: 	return rtpengine.ManagerConfig{
179: 		Engines: engines,
180: 	}
181: }
182: func (c *Config) ToAsteriskManagerConfig() ami.ManagerConfig {
183: 	clients := make([]ami.Config, 0, len(c.Asterisk.Clients))
184: 	for _, client := range c.Asterisk.Clients {
185: 		timeout := time.Duration(client.TimeoutMS) * time.Millisecond
186: 		if timeout <= 0 {
187: 			timeout = 5 * time.Second
188: 		}
189: 		clients = append(clients, ami.Config{
190: 			Address:  client.Address,
191: 			Username: client.Username,
192: 			Secret:   client.Secret,
193: 			Timeout:  timeout,
194: 			CircuitBreaker: common.CircuitBreakerConfig{
195: 				FailureThreshold: client.CircuitBreaker.FailureThreshold,
196: 				ResetTimeout:     time.Duration(client.CircuitBreaker.ResetSeconds) * time.Second,
197: 				HalfOpenMaxReqs:  client.CircuitBreaker.HalfOpenMax,
198: 			},
199: 		})
200: 	}
201: 	return ami.ManagerConfig{
202: 		Clients:           clients,
203: 		MaxRetries:        c.Asterisk.MaxRetries,
204: 		RetryDelay:        c.Asterisk.RetryDelay,
205: 		EnableHAProxy:     c.Asterisk.EnableHAProxy,
206: 		OriginalAddresses: c.Asterisk.OriginalAddresses,
207: 	}
208: }
209: func (c *Config) GetWebSocketReadTimeout() time.Duration {
210: 	return time.Duration(c.WebSocket.ReadTimeoutMS) * time.Millisecond
211: }
212: func (c *Config) GetWebSocketWriteTimeout() time.Duration {
213: 	return time.Duration(c.WebSocket.WriteTimeoutMS) * time.Millisecond
214: }
215: func (c *Config) GetWebSocketIdleTimeout() time.Duration {
216: 	return time.Duration(c.WebSocket.IdleTimeoutMS) * time.Millisecond
217: }
218: func (c *Config) GetHeartbeatInterval() time.Duration {
219: 	return time.Duration(c.HighAvailability.HeartbeatInterval) * time.Millisecond
220: }
221: func (c *Config) GetLeaseTimeout() time.Duration {
222: 	return time.Duration(c.HighAvailability.LeaseTimeout) * time.Millisecond
223: }
</file>

<file path="gateway/pkg/coordinator/coordination.go">
  1: package coordinator
  2: import (
  3: 	"context"
  4: 	"encoding/json"
  5: 	"fmt"
  6: 	"net"
  7: 	"os"
  8: 	"sync"
  9: 	"time"
 10: 	"go.uber.org/zap"
 11: 	"gateway/pkg/common"
 12: 	"gateway/pkg/storage"
 13: )
 14: type Coordinator struct {
 15: 	instanceID      string
 16: 	storage         storage.StateStorage
 17: 	logger          *zap.Logger
 18: 	registry        *common.GoroutineRegistry
 19: 	leaderLock      sync.RWMutex
 20: 	isLeader        bool
 21: 	leaseExpiration time.Time
 22: 	leadership      map[string]bool
 23: 	componentMu     sync.RWMutex
 24: 	leadershipCh chan string
 25: 	heartbeatInterval time.Duration
 26: 	leaseTimeout      time.Duration
 27: }
 28: type CoordinatorConfig struct {
 29: 	HeartbeatInterval time.Duration `json:"heartbeat_interval"`
 30: 	LeaseTimeout      time.Duration `json:"lease_timeout"`
 31: }
 32: func NewCoordinator(storage storage.StateStorage, config CoordinatorConfig, logger *zap.Logger) (*Coordinator, error) {
 33: 	if logger == nil {
 34: 		var err error
 35: 		logger, err = zap.NewProduction()
 36: 		if err != nil {
 37: 			return nil, err
 38: 		}
 39: 	}
 40: 	if storage == nil {
 41: 		return nil, fmt.Errorf("storage is required")
 42: 	}
 43: 	if config.HeartbeatInterval <= 0 {
 44: 		config.HeartbeatInterval = 5 * time.Second
 45: 	}
 46: 	if config.LeaseTimeout <= 0 {
 47: 		config.LeaseTimeout = 15 * time.Second
 48: 	}
 49: 	hostname, err := os.Hostname()
 50: 	if err != nil {
 51: 		hostname = "unknown"
 52: 	}
 53: 	instanceID := fmt.Sprintf("%s-%d", hostname, time.Now().UnixNano())
 54: 	return &Coordinator{
 55: 		instanceID:        instanceID,
 56: 		storage:           storage,
 57: 		logger:            logger,
 58: 		registry:          common.NewGoroutineRegistry(logger),
 59: 		leadership:        make(map[string]bool),
 60: 		leadershipCh:      make(chan string, 10),
 61: 		heartbeatInterval: config.HeartbeatInterval,
 62: 		leaseTimeout:      config.LeaseTimeout,
 63: 	}, nil
 64: }
 65: func (c *Coordinator) Start(ctx context.Context) error {
 66: 	if err := c.registerInstance(ctx); err != nil {
 67: 		return err
 68: 	}
 69: 	c.registry.Go("leadership-monitor", func(ctx context.Context) {
 70: 		ticker := time.NewTicker(c.heartbeatInterval)
 71: 		defer ticker.Stop()
 72: 		c.tryAcquireLeadership(ctx)
 73: 		for {
 74: 			select {
 75: 			case <-ctx.Done():
 76: 				return
 77: 			case <-ticker.C:
 78: 				if c.IsLeader() {
 79: 					c.renewLeadership(ctx)
 80: 				} else {
 81: 					c.tryAcquireLeadership(ctx)
 82: 				}
 83: 			}
 84: 		}
 85: 	})
 86: 	c.registry.Go("component-leadership", func(ctx context.Context) {
 87: 		ticker := time.NewTicker(c.heartbeatInterval)
 88: 		defer ticker.Stop()
 89: 		for {
 90: 			select {
 91: 			case <-ctx.Done():
 92: 				return
 93: 			case <-ticker.C:
 94: 				c.monitorComponentLeadership(ctx)
 95: 			}
 96: 		}
 97: 	})
 98: 	return nil
 99: }
100: func (c *Coordinator) Stop() error {
101: 	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
102: 	defer cancel()
103: 	if c.IsLeader() {
104: 		c.releaseLeadership(ctx)
105: 	}
106: 	c.unregisterInstance(ctx)
107: 	return c.registry.Shutdown(10 * time.Second)
108: }
109: func (c *Coordinator) IsLeader(component ...string) bool {
110: 	c.leaderLock.RLock()
111: 	isGlobalLeader := c.isLeader && time.Now().Before(c.leaseExpiration)
112: 	c.leaderLock.RUnlock()
113: 	if len(component) == 0 {
114: 		return isGlobalLeader
115: 	}
116: 	if !isGlobalLeader {
117: 		return false
118: 	}
119: 	c.componentMu.RLock()
120: 	defer c.componentMu.RUnlock()
121: 	leader, exists := c.leadership[component[0]]
122: 	return exists && leader
123: }
124: func (c *Coordinator) RegisterComponentLeadership(component string) {
125: 	c.componentMu.Lock()
126: 	defer c.componentMu.Unlock()
127: 	c.leadership[component] = false
128: }
129: func (c *Coordinator) IsComponentLeader(component string) bool {
130: 	c.componentMu.RLock()
131: 	defer c.componentMu.RUnlock()
132: 	leader, exists := c.leadership[component]
133: 	return exists && leader && c.IsLeader()
134: }
135: func (c *Coordinator) WaitForLeadership(ctx context.Context) bool {
136: 	if c.IsLeader() {
137: 		return true
138: 	}
139: 	for {
140: 		select {
141: 		case <-ctx.Done():
142: 			return false
143: 		case component := <-c.leadershipCh:
144: 			if component == "global" && c.IsLeader() {
145: 				return true
146: 			}
147: 		case <-time.After(c.heartbeatInterval):
148: 			if c.IsLeader() {
149: 				return true
150: 			}
151: 		}
152: 	}
153: }
154: func (c *Coordinator) GetLeaderInfo(ctx context.Context) (map[string]interface{}, error) {
155: 	leaderKey := "coordinator:leader"
156: 	data, err := c.storage.Get(ctx, leaderKey)
157: 	if err != nil {
158: 		if err == storage.ErrNotFound {
159: 			return nil, fmt.Errorf("no leader elected")
160: 		}
161: 		return nil, err
162: 	}
163: 	var leaderInfo map[string]interface{}
164: 	if err := json.Unmarshal(data, &leaderInfo); err != nil {
165: 		return nil, fmt.Errorf("failed to parse leader info: %w", err)
166: 	}
167: 	return leaderInfo, nil
168: }
169: func (c *Coordinator) registerInstance(ctx context.Context) error {
170: 	instanceKey := fmt.Sprintf("coordinator:instance:%s", c.instanceID)
171: 	addrs, err := net.InterfaceAddrs()
172: 	if err != nil {
173: 		return fmt.Errorf("failed to get interface addresses: %w", err)
174: 	}
175: 	ipAddr := "unknown"
176: 	for _, addr := range addrs {
177: 		ipNet, ok := addr.(*net.IPNet)
178: 		if ok && !ipNet.IP.IsLoopback() && ipNet.IP.To4() != nil {
179: 			ipAddr = ipNet.IP.String()
180: 			break
181: 		}
182: 	}
183: 	instanceInfo := map[string]interface{}{
184: 		"id":        c.instanceID,
185: 		"host":      c.instanceID,
186: 		"ip":        ipAddr,
187: 		"startTime": time.Now().Unix(),
188: 		"lastSeen":  time.Now().Unix(),
189: 	}
190: 	data, err := json.Marshal(instanceInfo)
191: 	if err != nil {
192: 		return fmt.Errorf("failed to serialize instance info: %w", err)
193: 	}
194: 	if err := c.storage.Set(ctx, instanceKey, data, c.leaseTimeout*2); err != nil {
195: 		return fmt.Errorf("failed to register instance: %w", err)
196: 	}
197: 	c.logger.Info("Instance registered",
198: 		zap.String("instanceID", c.instanceID),
199: 		zap.String("ip", ipAddr))
200: 	return nil
201: }
202: func (c *Coordinator) unregisterInstance(ctx context.Context) error {
203: 	instanceKey := fmt.Sprintf("coordinator:instance:%s", c.instanceID)
204: 	if err := c.storage.Delete(ctx, instanceKey); err != nil {
205: 		if err != storage.ErrNotFound {
206: 			return fmt.Errorf("failed to unregister instance: %w", err)
207: 		}
208: 	}
209: 	c.logger.Info("Instance unregistered", zap.String("instanceID", c.instanceID))
210: 	return nil
211: }
212: func (c *Coordinator) tryAcquireLeadership(ctx context.Context) {
213: 	leaderKey := "coordinator:leader"
214: 	data, err := c.storage.Get(ctx, leaderKey)
215: 	if err == nil {
216: 		var leaderInfo map[string]interface{}
217: 		if err := json.Unmarshal(data, &leaderInfo); err != nil {
218: 			c.logger.Error("Failed to parse leader info", zap.Error(err))
219: 			return
220: 		}
221: 		if expireTime, ok := leaderInfo["expireTime"].(float64); ok {
222: 			expiration := time.Unix(int64(expireTime), 0)
223: 			if time.Now().Before(expiration) {
224: 				return
225: 			}
226: 		}
227: 	}
228: 	leaderInfo := map[string]interface{}{
229: 		"instanceID":  c.instanceID,
230: 		"acquireTime": time.Now().Unix(),
231: 		"expireTime":  time.Now().Add(c.leaseTimeout).Unix(),
232: 	}
233: 	data, err = json.Marshal(leaderInfo)
234: 	if err != nil {
235: 		c.logger.Error("Failed to serialize leader info", zap.Error(err))
236: 		return
237: 	}
238: 	if err := c.storage.Set(ctx, leaderKey, data, c.leaseTimeout); err != nil {
239: 		c.logger.Error("Failed to acquire leadership", zap.Error(err))
240: 		return
241: 	}
242: 	data, err = c.storage.Get(ctx, leaderKey)
243: 	if err != nil {
244: 		c.logger.Error("Failed to verify leadership", zap.Error(err))
245: 		return
246: 	}
247: 	var verifyInfo map[string]interface{}
248: 	if err := json.Unmarshal(data, &verifyInfo); err != nil {
249: 		c.logger.Error("Failed to parse verify info", zap.Error(err))
250: 		return
251: 	}
252: 	if instanceID, ok := verifyInfo["instanceID"].(string); ok && instanceID == c.instanceID {
253: 		c.leaderLock.Lock()
254: 		wasLeader := c.isLeader
255: 		c.isLeader = true
256: 		c.leaseExpiration = time.Now().Add(c.leaseTimeout)
257: 		c.leaderLock.Unlock()
258: 		if !wasLeader {
259: 			c.logger.Info("Acquired leadership", zap.String("instanceID", c.instanceID))
260: 			select {
261: 			case c.leadershipCh <- "global":
262: 			default:
263: 			}
264: 		}
265: 	}
266: }
267: func (c *Coordinator) renewLeadership(ctx context.Context) {
268: 	leaderKey := "coordinator:leader"
269: 	data, err := c.storage.Get(ctx, leaderKey)
270: 	if err != nil {
271: 		c.logger.Error("Failed to get leader info", zap.Error(err))
272: 		c.leaderLock.Lock()
273: 		c.isLeader = false
274: 		c.leaderLock.Unlock()
275: 		return
276: 	}
277: 	var leaderInfo map[string]interface{}
278: 	if err := json.Unmarshal(data, &leaderInfo); err != nil {
279: 		c.logger.Error("Failed to parse leader info", zap.Error(err))
280: 		return
281: 	}
282: 	if instanceID, ok := leaderInfo["instanceID"].(string); !ok || instanceID != c.instanceID {
283: 		c.leaderLock.Lock()
284: 		c.isLeader = false
285: 		c.leaderLock.Unlock()
286: 		return
287: 	}
288: 	leaderInfo["expireTime"] = time.Now().Add(c.leaseTimeout).Unix()
289: 	data, err = json.Marshal(leaderInfo)
290: 	if err != nil {
291: 		c.logger.Error("Failed to serialize leader info", zap.Error(err))
292: 		return
293: 	}
294: 	if err := c.storage.Set(ctx, leaderKey, data, c.leaseTimeout); err != nil {
295: 		c.logger.Error("Failed to renew leadership", zap.Error(err))
296: 		return
297: 	}
298: 	c.leaderLock.Lock()
299: 	c.leaseExpiration = time.Now().Add(c.leaseTimeout)
300: 	c.leaderLock.Unlock()
301: }
302: func (c *Coordinator) releaseLeadership(ctx context.Context) {
303: 	leaderKey := "coordinator:leader"
304: 	data, err := c.storage.Get(ctx, leaderKey)
305: 	if err != nil {
306: 		return
307: 	}
308: 	var leaderInfo map[string]interface{}
309: 	if err := json.Unmarshal(data, &leaderInfo); err != nil {
310: 		return
311: 	}
312: 	if instanceID, ok := leaderInfo["instanceID"].(string); !ok || instanceID != c.instanceID {
313: 		return
314: 	}
315: 	if err := c.storage.Delete(ctx, leaderKey); err != nil {
316: 		c.logger.Error("Failed to release leadership", zap.Error(err))
317: 	}
318: 	c.logger.Info("Released leadership", zap.String("instanceID", c.instanceID))
319: 	c.leaderLock.Lock()
320: 	c.isLeader = false
321: 	c.leaderLock.Unlock()
322: }
323: func (c *Coordinator) monitorComponentLeadership(ctx context.Context) {
324: 	if !c.IsLeader() {
325: 		c.componentMu.Lock()
326: 		for component := range c.leadership {
327: 			if c.leadership[component] {
328: 				c.leadership[component] = false
329: 				select {
330: 				case c.leadershipCh <- component:
331: 				default:
332: 				}
333: 			}
334: 		}
335: 		c.componentMu.Unlock()
336: 		return
337: 	}
338: 	c.componentMu.Lock()
339: 	for component := range c.leadership {
340: 		if !c.leadership[component] {
341: 			c.leadership[component] = true
342: 			select {
343: 			case c.leadershipCh <- component:
344: 			default:
345: 			}
346: 			c.logger.Info("Acquired component leadership",
347: 				zap.String("component", component),
348: 				zap.String("instanceID", c.instanceID))
349: 		}
350: 	}
351: 	c.componentMu.Unlock()
352: }
</file>

<file path="gateway/pkg/health/health.go">
  1: package health
  2: import (
  3: 	"context"
  4: 	"encoding/json"
  5: 	"fmt"
  6: 	"net"
  7: 	"strings"
  8: 	"sync"
  9: 	"time"
 10: 	"gateway/pkg/ami"
 11: 	"gateway/pkg/coordinator"
 12: 	"gateway/pkg/rtpengine"
 13: 	"gateway/pkg/sip"
 14: 	"gateway/pkg/storage"
 15: 	"gateway/pkg/websocket"
 16: 	"go.uber.org/zap"
 17: )
 18: type Status string
 19: const (
 20: 	StatusHealthy   Status = "HEALTHY"
 21: 	StatusUnhealthy Status = "UNHEALTHY"
 22: )
 23: type ComponentHealth struct {
 24: 	Component   string    `json:"component"`
 25: 	Status      Status    `json:"status"`
 26: 	LastChecked time.Time `json:"lastChecked"`
 27: 	Message     string    `json:"message"`
 28: }
 29: type HealthMonitor struct {
 30: 	sipTransport sip.Transport
 31: 	amiManager   *ami.Manager
 32: 	rtpManager   *rtpengine.Manager
 33: 	wsServer     *websocket.Server
 34: 	coordinator  *coordinator.Coordinator
 35: 	storage      storage.StateStorage
 36: 	logger       *zap.Logger
 37: 	opensipsAddress string
 38: 	checkInterval   time.Duration
 39: 	failoverEnabled bool
 40: 	componentStatus map[string]*ComponentHealth
 41: 	mutex           sync.RWMutex
 42: 	stopChan        chan struct{}
 43: }
 44: type HealthConfig struct {
 45: 	OpenSIPSAddress string
 46: 	CheckInterval   time.Duration
 47: 	EnableFailover  bool
 48: }
 49: func NewHealthMonitor(
 50: 	sipTransport sip.Transport,
 51: 	amiManager *ami.Manager,
 52: 	rtpManager *rtpengine.Manager,
 53: 	wsServer *websocket.Server,
 54: 	coordinator *coordinator.Coordinator,
 55: 	storage storage.StateStorage,
 56: 	logger *zap.Logger,
 57: 	config HealthConfig,
 58: ) *HealthMonitor {
 59: 	return &HealthMonitor{
 60: 		sipTransport:    sipTransport,
 61: 		amiManager:      amiManager,
 62: 		rtpManager:      rtpManager,
 63: 		wsServer:        wsServer,
 64: 		coordinator:     coordinator,
 65: 		storage:         storage,
 66: 		logger:          logger,
 67: 		opensipsAddress: config.OpenSIPSAddress,
 68: 		checkInterval:   config.CheckInterval,
 69: 		failoverEnabled: config.EnableFailover,
 70: 		componentStatus: make(map[string]*ComponentHealth),
 71: 		stopChan:        make(chan struct{}),
 72: 	}
 73: }
 74: func (h *HealthMonitor) Start(ctx context.Context) error {
 75: 	h.logger.Info("Starting health monitoring")
 76: 	h.componentStatus["opensips"] = &ComponentHealth{Component: "opensips", Status: StatusUnhealthy}
 77: 	h.componentStatus["asterisk"] = &ComponentHealth{Component: "asterisk", Status: StatusUnhealthy}
 78: 	h.componentStatus["rtpengine"] = &ComponentHealth{Component: "rtpengine", Status: StatusUnhealthy}
 79: 	h.checkAllComponents(ctx)
 80: 	go h.monitorLoop(ctx)
 81: 	return nil
 82: }
 83: func (h *HealthMonitor) Stop() {
 84: 	close(h.stopChan)
 85: }
 86: func (h *HealthMonitor) GetComponentHealth(component string) *ComponentHealth {
 87: 	h.mutex.RLock()
 88: 	defer h.mutex.RUnlock()
 89: 	if status, exists := h.componentStatus[component]; exists {
 90: 		copy := *status
 91: 		return &copy
 92: 	}
 93: 	return nil
 94: }
 95: func (h *HealthMonitor) GetAllComponentHealth() map[string]*ComponentHealth {
 96: 	h.mutex.RLock()
 97: 	defer h.mutex.RUnlock()
 98: 	result := make(map[string]*ComponentHealth)
 99: 	for k, v := range h.componentStatus {
100: 		copy := *v
101: 		result[k] = &copy
102: 	}
103: 	return result
104: }
105: func (h *HealthMonitor) monitorLoop(ctx context.Context) {
106: 	ticker := time.NewTicker(h.checkInterval)
107: 	defer ticker.Stop()
108: 	for {
109: 		select {
110: 		case <-ticker.C:
111: 			h.checkAllComponents(ctx)
112: 		case <-h.stopChan:
113: 			return
114: 		case <-ctx.Done():
115: 			return
116: 		}
117: 	}
118: }
119: func (h *HealthMonitor) checkWebSocketBackends(ctx context.Context) {
120:     if h.wsServer == nil {
121:         return
122:     }
123:     h.wsServer.CheckBackendHealth(ctx)
124:     h.mutex.Lock()
125:     defer h.mutex.Unlock()
126:     if _, exists := h.componentStatus["websocket_backends"]; !exists {
127:         h.componentStatus["websocket_backends"] = &ComponentHealth{
128:             Component: "websocket_backends",
129:             Status:    StatusUnhealthy,
130:         }
131:     }
132:     status := h.componentStatus["websocket_backends"]
133:     status.LastChecked = time.Now()
134:     if h.wsServer.HasHealthyBackends() {
135:         status.Status = StatusHealthy
136:         status.Message = "At least one WebSocket backend is healthy"
137:     } else {
138:         status.Status = StatusUnhealthy
139:         status.Message = "No healthy WebSocket backends available"
140:     }
141: }
142: func (h *HealthMonitor) checkAllComponents(ctx context.Context) {
143: 	h.checkOpenSIPS(ctx)
144: 	h.checkAsterisk(ctx)
145: 	h.checkRTPEngine(ctx)
146: 	h.storeHealthStatus(ctx)
147: }
148: func (h *HealthMonitor) checkOpenSIPS(ctx context.Context) {
149: 	h.logger.Debug("Checking OpenSIPS health")
150: 	host := h.opensipsAddress
151: 	if idx := strings.LastIndex(host, ":"); idx > 0 {
152: 		host = host[:idx]
153: 	}
154: 	targetAddress := host + ":6060"
155: 	h.logger.Debug("OpenSIPS check target", zap.String("address", targetAddress))
156: 	optionsMsg := buildSipOptionsMessage(host)
157: 	udpAddr, err := net.ResolveUDPAddr("udp", targetAddress)
158: 	if err != nil {
159: 		h.mutex.Lock()
160: 		defer h.mutex.Unlock()
161: 		status := h.componentStatus["opensips"]
162: 		status.LastChecked = time.Now()
163: 		status.Status = StatusUnhealthy
164: 		status.Message = fmt.Sprintf("Failed to resolve OpenSIPS address: %v", err)
165: 		h.logger.Warn("OpenSIPS health check failed", zap.Error(err))
166: 		return
167: 	}
168: 	conn, err := net.DialUDP("udp", nil, udpAddr)
169: 	if err != nil {
170: 		h.mutex.Lock()
171: 		defer h.mutex.Unlock()
172: 		status := h.componentStatus["opensips"]
173: 		status.LastChecked = time.Now()
174: 		status.Status = StatusUnhealthy
175: 		status.Message = fmt.Sprintf("Failed to connect to OpenSIPS: %v", err)
176: 		h.logger.Warn("OpenSIPS health check failed", zap.Error(err))
177: 		return
178: 	}
179: 	defer conn.Close()
180: 	conn.SetDeadline(time.Now().Add(5 * time.Second))
181: 	_, err = conn.Write([]byte(optionsMsg))
182: 	if err != nil {
183: 		h.mutex.Lock()
184: 		defer h.mutex.Unlock()
185: 		status := h.componentStatus["opensips"]
186: 		status.LastChecked = time.Now()
187: 		status.Status = StatusUnhealthy
188: 		status.Message = fmt.Sprintf("Failed to send OPTIONS to OpenSIPS: %v", err)
189: 		h.logger.Warn("OpenSIPS health check failed", zap.Error(err))
190: 		return
191: 	}
192: 	buffer := make([]byte, 4096)
193: 	n, _, err := conn.ReadFromUDP(buffer)
194: 	h.mutex.Lock()
195: 	defer h.mutex.Unlock()
196: 	status := h.componentStatus["opensips"]
197: 	status.LastChecked = time.Now()
198: 	if err != nil {
199: 		status.Status = StatusUnhealthy
200: 		status.Message = fmt.Sprintf("Failed to read response from OpenSIPS: %v", err)
201: 		h.logger.Warn("OpenSIPS health check failed", zap.Error(err))
202: 		return
203: 	}
204: 	response := string(buffer[:n])
205: 	if strings.Contains(response, "SIP/2.0 200") ||
206: 		strings.Contains(response, "SIP/2.0 405") ||
207: 		strings.Contains(response, "SIP/2.0 403") {
208: 		status.Status = StatusHealthy
209: 		message := "OpenSIPS responding to OPTIONS"
210: 		if strings.Contains(response, "SIP/2.0 403") {
211: 			message = "OpenSIPS responding (with 403 - authentication needed)"
212: 		}
213: 		status.Message = message
214: 		h.logger.Debug("OpenSIPS health check successful")
215: 	} else {
216: 		status.Status = StatusUnhealthy
217: 		status.Message = fmt.Sprintf("Unexpected response: %s", response)
218: 		h.logger.Warn("OpenSIPS returned unexpected response",
219: 			zap.String("response", response))
220: 		if h.failoverEnabled && h.coordinator != nil && h.coordinator.IsLeader() {
221: 			h.logger.Warn("Initiating OpenSIPS failover")
222: 			h.triggerFailover("opensips")
223: 		}
224: 	}
225: }
226: func buildSipOptionsMessage(serverAddress string) string {
227: 	callID := fmt.Sprintf("health-%d", time.Now().UnixNano())
228: 	branch := fmt.Sprintf("z9hG4bK-%d", time.Now().UnixNano())
229: 	fromTag := fmt.Sprintf("fromTag-%d", time.Now().UnixNano())
230: 	return fmt.Sprintf(
231: 		"OPTIONS sip:%s SIP/2.0\r\n"+
232: 			"Via: SIP/2.0/UDP health.monitor;branch=%s;rport\r\n"+
233: 			"Max-Forwards: 69\r\n"+
234: 			"From: <sip:proxy@localhost>;tag=%s\r\n"+
235: 			"To: <sip:%s>\r\n"+
236: 			"Call-ID: %s\r\n"+
237: 			"CSeq: 1 OPTIONS\r\n"+
238: 			"User-Agent: Qalqul-Health-Monitor\r\n"+
239: 			"Allow: INVITE, ACK, CANCEL, OPTIONS, BYE\r\n"+
240: 			"Content-Length: 0\r\n\r\n",
241: 		serverAddress,
242: 		branch,
243: 		fromTag,
244: 		serverAddress,
245: 		callID,
246: 	)
247: }
248: func (h *HealthMonitor) checkAsterisk(ctx context.Context) {
249: 	h.logger.Debug("Checking Asterisk health")
250: 	client := h.amiManager.GetActiveClient()
251: 	h.mutex.Lock()
252: 	defer h.mutex.Unlock()
253: 	status := h.componentStatus["asterisk"]
254: 	status.LastChecked = time.Now()
255: 	if client == nil {
256: 		status.Status = StatusUnhealthy
257: 		status.Message = "No active AMI client"
258: 		h.logger.Warn("Asterisk AMI check failed: no active client")
259: 		if h.failoverEnabled {
260: 			h.logger.Warn("Initiating Asterisk failover/reconnect")
261: 			h.triggerFailover("asterisk")
262: 		}
263: 		return
264: 	}
265: 	isConnected := client.IsConnected()
266: 	hasBanner := client.IsBannerReceived()
267: 	h.logger.Debug("AMI client status",
268: 		zap.Bool("isConnected", isConnected),
269: 		zap.Bool("hasBanner", hasBanner))
270: 	if hasBanner {
271: 		status.Status = StatusHealthy
272: 		status.Message = "AMI banner received - Asterisk ready"
273: 		return
274: 	}
275: 	if isConnected {
276: 		status.Status = StatusHealthy
277: 		status.Message = "AMI connected but waiting for banner"
278: 	} else {
279: 		status.Status = StatusUnhealthy
280: 		status.Message = "AMI connection not established"
281: 		h.logger.Warn("Asterisk AMI check failed: not connected")
282: 		if h.failoverEnabled {
283: 			h.logger.Warn("Initiating Asterisk failover/reconnect")
284: 			h.triggerFailover("asterisk")
285: 		}
286: 	}
287: }
288: func (h *HealthMonitor) checkRTPEngine(ctx context.Context) {
289: 	h.logger.Debug("Checking RTPEngine health")
290: 	h.mutex.Lock()
291: 	defer h.mutex.Unlock()
292: 	status := h.componentStatus["rtpengine"]
293: 	status.LastChecked = time.Now()
294: 	if h.rtpManager != nil {
295: 		status.Status = StatusHealthy
296: 		status.Message = "RTPEngine manager available"
297: 	} else {
298: 		status.Status = StatusUnhealthy
299: 		status.Message = "RTPEngine manager not available"
300: 		if h.failoverEnabled {
301: 			h.logger.Warn("RTPEngine health check failed")
302: 			h.triggerFailover("rtpengine")
303: 		}
304: 	}
305: }
306: func (h *HealthMonitor) triggerFailover(component string) {
307: 	switch component {
308: 	case "opensips":
309: 		if h.wsServer != nil {
310: 			h.wsServer.PrepareForFailover()
311: 		}
312: 		if h.coordinator != nil && h.coordinator.IsLeader() {
313: 			h.logger.Warn("OpenSIPS failover might require manual intervention")
314: 		}
315: 	case "asterisk":
316: 		if h.amiManager != nil {
317: 			h.logger.Info("Attempting AMI reconnection")
318: 			if err := h.amiManager.Reconnect(); err != nil {
319: 				h.logger.Error("AMI reconnection failed", zap.Error(err))
320: 			}
321: 		}
322: 	case "rtpengine":
323: 		h.logger.Info("RTPEngine failover would need to be handled externally")
324: 	}
325: }
326: func (h *HealthMonitor) storeHealthStatus(ctx context.Context) {
327: 	if h.storage == nil {
328: 		return
329: 	}
330: 	h.mutex.RLock()
331: 	statusCopy := make(map[string]*ComponentHealth)
332: 	for k, v := range h.componentStatus {
333: 		copy := *v
334: 		statusCopy[k] = &copy
335: 	}
336: 	h.mutex.RUnlock()
337: 	jsonData, err := json.Marshal(statusCopy)
338: 	if err != nil {
339: 		h.logger.Error("Failed to marshal health status", zap.Error(err))
340: 		return
341: 	}
342: 	err = h.storage.Set(ctx, "health:status", jsonData, 0)
343: 	if err != nil {
344: 		h.logger.Error("Failed to store health status", zap.Error(err))
345: 	}
346: }
</file>

<file path="gateway/pkg/rtpengine/manager.go">
  1: package rtpengine
  2: import (
  3: 	"context"
  4: 	"errors"
  5: 	"fmt"
  6: 	"sync"
  7: 	"sync/atomic"
  8: 	"time"
  9: 	"go.uber.org/zap"
 10: 	"gateway/pkg/common"
 11: 	"gateway/pkg/coordinator"
 12: 	"gateway/pkg/storage"
 13: )
 14: type Manager struct {
 15: 	engines   []*RTPEngine
 16: 	weights   []int
 17: 	activeIdx int32
 18: 	mutex     sync.RWMutex
 19: 	logger    *zap.Logger
 20: 	registry  *common.GoroutineRegistry
 21: 	storage   storage.StateStorage
 22: }
 23: type ManagerConfig struct {
 24: 	Engines []Config `json:"engines"`
 25: }
 26: func NewManager(config ManagerConfig, logger *zap.Logger, registry *common.GoroutineRegistry, storage storage.StateStorage, coordinator *coordinator.Coordinator) (*Manager, error) {
 27: 	if logger == nil {
 28: 		var err error
 29: 		logger, err = zap.NewProduction()
 30: 		if err != nil {
 31: 			return nil, err
 32: 		}
 33: 	}
 34: 	if len(config.Engines) == 0 {
 35: 		return nil, errors.New("at least one RTPEngine instance required")
 36: 	}
 37: 	var engines []*RTPEngine
 38: 	var weights []int
 39: 	for _, engineConfig := range config.Engines {
 40: 		engine, err := New(engineConfig, logger)
 41: 		if err != nil {
 42: 			logger.Warn("Failed to initialize RTPEngine",
 43: 				zap.String("address", engineConfig.Address),
 44: 				zap.Int("port", engineConfig.Port),
 45: 				zap.Error(err))
 46: 			continue
 47: 		}
 48: 		weight := engineConfig.Weight
 49: 		if weight <= 0 {
 50: 			weight = 1
 51: 		}
 52: 		engines = append(engines, engine)
 53: 		weights = append(weights, weight)
 54: 	}
 55: 	if len(engines) == 0 {
 56: 		return nil, errors.New("all RTPEngine instances failed to initialize")
 57: 	}
 58: 	return &Manager{
 59: 		engines:  engines,
 60: 		weights:  weights,
 61: 		logger:   logger,
 62: 		registry: registry,
 63: 		storage:  storage,
 64: 	}, nil
 65: }
 66: func (m *Manager) Start(ctx context.Context) {
 67: 	for i, engine := range m.engines {
 68: 		i, engine := i, engine
 69: 		m.registry.Go(fmt.Sprintf("rtpengine-health-%d", i), func(ctx context.Context) {
 70: 			ticker := time.NewTicker(10 * time.Second)
 71: 			defer ticker.Stop()
 72: 			for {
 73: 				select {
 74: 				case <-ctx.Done():
 75: 					return
 76: 				case <-ticker.C:
 77: 					if err := engine.Ping(ctx); err != nil {
 78: 						m.logger.Warn("RTPEngine health check failed",
 79: 							zap.String("address", engine.address),
 80: 							zap.Int("port", engine.port),
 81: 							zap.Error(err))
 82: 					} else {
 83: 						m.logger.Debug("RTPEngine health check succeeded",
 84: 							zap.String("address", engine.address),
 85: 							zap.Int("port", engine.port))
 86: 					}
 87: 				}
 88: 			}
 89: 		})
 90: 	}
 91: }
 92: func (m *Manager) Stop() {
 93: 	m.mutex.Lock()
 94: 	defer m.mutex.Unlock()
 95: 	for _, engine := range m.engines {
 96: 		if err := engine.Close(); err != nil {
 97: 			m.logger.Warn("Error closing RTPEngine connection",
 98: 				zap.String("address", engine.address),
 99: 				zap.Int("port", engine.port),
100: 				zap.Error(err))
101: 		}
102: 	}
103: }
104: func (m *Manager) GetEngine(ctx context.Context, callID string) (*RTPEngine, error) {
105: 	if callID != "" && m.storage != nil {
106: 		session, err := m.storage.GetRTPSession(ctx, callID)
107: 		if err == nil && session != nil {
108: 			if session.EngineIdx >= 0 && session.EngineIdx < len(m.engines) {
109: 				return m.engines[session.EngineIdx], nil
110: 			}
111: 		}
112: 	}
113: 	// No existing session or storage error, use the active engine
114: 	activeIdx := atomic.LoadInt32(&m.activeIdx)
115: 	return m.engines[activeIdx], nil
116: }
117: // ProcessOffer processes an SDP offer through RTPEngine
118: func (m *Manager) ProcessOffer(ctx context.Context, callID, fromTag string, sdp string, options map[string]interface{}) (string, error) {
119: 	ctx, cancel := common.ContextWithTimeout(ctx, 5*time.Second)
120: 	defer cancel()
121: 	// Create base parameters
122: 	params := map[string]interface{}{
123: 		"call-id":  callID,
124: 		"from-tag": fromTag,
125: 		"sdp":      sdp,
126: 	}
127: 	for k, v := range options {
128: 		params[k] = v
129: 	}
130: 	engine, err := m.GetEngine(ctx, callID)
131: 	if err != nil {
132: 		return "", fmt.Errorf("failed to get RTPEngine: %w", err)
133: 	}
134: 	result, err := engine.Offer(ctx, params)
135: 	if err != nil {
136: 		m.logger.Warn("RTPEngine offer failed, trying failover",
137: 			zap.String("address", engine.address),
138: 			zap.Int("port", engine.port),
139: 			zap.Error(err))
140: 		return m.failoverOffer(ctx, callID, fromTag, sdp, options)
141: 	}
142: 	sdpResult, ok := result["sdp"].(string)
143: 	if !ok {
144: 		return "", fmt.Errorf("no SDP in RTPEngine response")
145: 	}
146: 	idx := -1
147: 	for i, e := range m.engines {
148: 		if e == engine {
149: 			idx = i
150: 			break
151: 		}
152: 	}
153: 	if idx >= 0 && m.storage != nil {
154: 		m.storage.StoreRTPSession(ctx, &storage.RTPSession{
155: 			CallID:     callID,
156: 			EngineIdx:  idx,
157: 			EngineAddr: fmt.Sprintf("%s:%d", engine.address, engine.port),
158: 			FromTag:    fromTag,
159: 			Created:    time.Now(),
160: 		})
161: 	}
162: 	return sdpResult, nil
163: }
164: func (m *Manager) ProcessAnswer(ctx context.Context, callID, fromTag, toTag string, sdp string, options map[string]interface{}) (string, error) {
165: 	ctx, cancel := common.ContextWithTimeout(ctx, 5*time.Second)
166: 	defer cancel()
167: 	params := map[string]interface{}{
168: 		"call-id":  callID,
169: 		"from-tag": fromTag,
170: 		"to-tag":   toTag,
171: 		"sdp":      sdp,
172: 	}
173: 	for k, v := range options {
174: 		params[k] = v
175: 	}
176: 	engine, err := m.GetEngine(ctx, callID)
177: 	if err != nil {
178: 		return "", fmt.Errorf("failed to get RTPEngine: %w", err)
179: 	}
180: 	result, err := engine.Answer(ctx, params)
181: 	if err != nil {
182: 		m.logger.Warn("RTPEngine answer failed, trying failover",
183: 			zap.String("address", engine.address),
184: 			zap.Int("port", engine.port),
185: 			zap.Error(err))
186: 		return m.failoverAnswer(ctx, callID, fromTag, toTag, sdp, options)
187: 	}
188: 	sdpResult, ok := result["sdp"].(string)
189: 	if !ok {
190: 		return "", fmt.Errorf("no SDP in RTPEngine response")
191: 	}
192: 	if m.storage != nil {
193: 		session, err := m.storage.GetRTPSession(ctx, callID)
194: 		if err == nil && session != nil {
195: 			session.ToTag = toTag
196: 			session.Updated = time.Now()
197: 			m.storage.StoreRTPSession(ctx, session)
198: 		}
199: 	}
200: 	return sdpResult, nil
201: }
202: func (m *Manager) DeleteSession(ctx context.Context, callID string) error {
203: 	ctx, cancel := common.ContextWithTimeout(ctx, 5*time.Second)
204: 	defer cancel()
205: 	engine, err := m.GetEngine(ctx, callID)
206: 	if err != nil {
207: 		return fmt.Errorf("failed to get RTPEngine: %w", err)
208: 	}
209: 	params := map[string]interface{}{
210: 		"call-id": callID,
211: 	}
212: 	_, err = engine.Delete(ctx, params)
213: 	if err != nil {
214: 		m.logger.Warn("RTPEngine delete failed, trying failover",
215: 			zap.String("address", engine.address),
216: 			zap.Int("port", engine.port),
217: 			zap.Error(err))
218: 		return m.failoverDelete(ctx, callID)
219: 	}
220: 	if m.storage != nil {
221: 		m.storage.DeleteRTPSession(ctx, callID)
222: 	}
223: 	return nil
224: }
225: func (m *Manager) failoverOffer(ctx context.Context, callID, fromTag string, sdp string, options map[string]interface{}) (string, error) {
226: 	ctx, cancel := common.ContextWithTimeout(ctx, 5*time.Second)
227: 	defer cancel()
228: 	currentIdx := atomic.LoadInt32(&m.activeIdx)
229: 	for i := 0; i < len(m.engines); i++ {
230: 		idx := (int(currentIdx) + i + 1) % len(m.engines)
231: 		if idx == int(currentIdx) {
232: 			continue
233: 		}
234: 		engine := m.engines[idx]
235: 		params := map[string]interface{}{
236: 			"call-id":  callID,
237: 			"from-tag": fromTag,
238: 			"sdp":      sdp,
239: 		}
240: 		for k, v := range options {
241: 			params[k] = v
242: 		}
243: 		result, err := engine.Offer(ctx, params)
244: 		if err != nil {
245: 			m.logger.Warn("RTPEngine failover attempt failed",
246: 				zap.String("address", engine.address),
247: 				zap.Int("port", engine.port),
248: 				zap.Error(err))
249: 			continue
250: 		}
251: 		atomic.StoreInt32(&m.activeIdx, int32(idx))
252: 		go func(oldIdx, newIdx int) {
253: 			bgCtx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
254: 			defer cancel()
255: 			if err := m.MigrateActiveCalls(bgCtx, oldIdx, newIdx); err != nil {
256: 				m.logger.Error("Failed to migrate active calls",
257: 					zap.Error(err),
258: 					zap.Int("fromIdx", oldIdx),
259: 					zap.Int("toIdx", newIdx))
260: 			}
261: 		}(int(currentIdx), idx)
262: 		m.logger.Info("Switched active RTPEngine",
263: 			zap.String("from", fmt.Sprintf("%s:%d", m.engines[currentIdx].address, m.engines[currentIdx].port)),
264: 			zap.String("to", fmt.Sprintf("%s:%d", engine.address, engine.port)))
265: 		if m.storage != nil {
266: 			m.storage.StoreRTPSession(ctx, &storage.RTPSession{
267: 				CallID:     callID,
268: 				EngineIdx:  idx,
269: 				EngineAddr: fmt.Sprintf("%s:%d", engine.address, engine.port),
270: 				FromTag:    fromTag,
271: 				Created:    time.Now(),
272: 			})
273: 		}
274: 		sdpResult, ok := result["sdp"].(string)
275: 		if !ok {
276: 			return "", fmt.Errorf("no SDP in RTPEngine response")
277: 		}
278: 		return sdpResult, nil
279: 	}
280: 	return "", fmt.Errorf("all RTPEngine instances failed")
281: }
282: func (m *Manager) failoverAnswer(ctx context.Context, callID, fromTag, toTag string, sdp string, options map[string]interface{}) (string, error) {
283: 	ctx, cancel := common.ContextWithTimeout(ctx, 5*time.Second)
284: 	defer cancel()
285: 	currentIdx := atomic.LoadInt32(&m.activeIdx)
286: 	for i := 0; i < len(m.engines); i++ {
287: 		idx := (int(currentIdx) + i + 1) % len(m.engines)
288: 		if idx == int(currentIdx) {
289: 			continue
290: 		}
291: 		engine := m.engines[idx]
292: 		params := map[string]interface{}{
293: 			"call-id":  callID,
294: 			"from-tag": fromTag,
295: 			"to-tag":   toTag,
296: 			"sdp":      sdp,
297: 		}
298: 		for k, v := range options {
299: 			params[k] = v
300: 		}
301: 		result, err := engine.Answer(ctx, params)
302: 		if err != nil {
303: 			m.logger.Warn("RTPEngine failover answer attempt failed",
304: 				zap.String("address", engine.address),
305: 				zap.Int("port", engine.port),
306: 				zap.Error(err))
307: 			continue
308: 		}
309: 		atomic.StoreInt32(&m.activeIdx, int32(idx))
310: 		m.logger.Info("Switched active RTPEngine for answer",
311: 			zap.String("from", fmt.Sprintf("%s:%d", m.engines[currentIdx].address, m.engines[currentIdx].port)),
312: 			zap.String("to", fmt.Sprintf("%s:%d", engine.address, engine.port)))
313: 		if m.storage != nil {
314: 			m.storage.StoreRTPSession(ctx, &storage.RTPSession{
315: 				CallID:     callID,
316: 				EngineIdx:  idx,
317: 				EngineAddr: fmt.Sprintf("%s:%d", engine.address, engine.port),
318: 				FromTag:    fromTag,
319: 				ToTag:      toTag,
320: 				Updated:    time.Now(),
321: 			})
322: 		}
323: 		sdpResult, ok := result["sdp"].(string)
324: 		if !ok {
325: 			return "", fmt.Errorf("no SDP in RTPEngine response")
326: 		}
327: 		return sdpResult, nil
328: 	}
329: 	return "", fmt.Errorf("all RTPEngine instances failed")
330: }
331: func (m *Manager) failoverDelete(ctx context.Context, callID string) error {
332: 	ctx, cancel := common.ContextWithTimeout(ctx, 5*time.Second)
333: 	defer cancel()
334: 	currentIdx := atomic.LoadInt32(&m.activeIdx)
335: 	for i := 0; i < len(m.engines); i++ {
336: 		idx := (int(currentIdx) + i + 1) % len(m.engines)
337: 		if idx == int(currentIdx) {
338: 			continue
339: 		}
340: 		engine := m.engines[idx]
341: 		params := map[string]interface{}{
342: 			"call-id": callID,
343: 		}
344: 		_, err := engine.Delete(ctx, params)
345: 		if err != nil {
346: 			m.logger.Warn("RTPEngine failover delete attempt failed",
347: 				zap.String("address", engine.address),
348: 				zap.Int("port", engine.port),
349: 				zap.Error(err))
350: 			continue
351: 		}
352: 		atomic.StoreInt32(&m.activeIdx, int32(idx))
353: 		m.logger.Info("Switched active RTPEngine for delete",
354: 			zap.String("from", fmt.Sprintf("%s:%d", m.engines[currentIdx].address, m.engines[currentIdx].port)),
355: 			zap.String("to", fmt.Sprintf("%s:%d", engine.address, engine.port)))
356: 		if m.storage != nil {
357: 			m.storage.DeleteRTPSession(ctx, callID)
358: 		}
359: 		return nil
360: 	}
361: 	return fmt.Errorf("all RTPEngine instances failed")
362: }
363: func (m *Manager) MigrateActiveCalls(ctx context.Context, fromIdx, toIdx int) error {
364: 	if fromIdx < 0 || fromIdx >= len(m.engines) || toIdx < 0 || toIdx >= len(m.engines) {
365: 		return fmt.Errorf("invalid engine indices: from=%d, to=%d", fromIdx, toIdx)
366: 	}
367: 	if fromIdx == toIdx {
368: 		return nil
369: 	}
370: 	fromEngine := m.engines[fromIdx]
371: 	toEngine := m.engines[toIdx]
372: 	m.logger.Info("Starting migration of active calls",
373: 		zap.String("fromEngine", fmt.Sprintf("%s:%d", fromEngine.address, fromEngine.port)),
374: 		zap.String("toEngine", fmt.Sprintf("%s:%d", toEngine.address, toEngine.port)))
375: 	sessions, err := m.storage.ListRTPSessions(ctx)
376: 	if err != nil {
377: 		m.logger.Error("Failed to list RTP sessions", zap.Error(err))
378: 		return err
379: 	}
380: 	var migrationCount int
381: 	var errorCount int
382: 	const workerCount = 10
383: 	var wg sync.WaitGroup
384: 	sessionCh := make(chan *storage.RTPSession, len(sessions))
385: 	resultCh := make(chan struct {
386: 		callID string
387: 		err    error
388: 	}, len(sessions))
389: 	for i := 0; i < workerCount; i++ {
390: 		wg.Add(1)
391: 		go func() {
392: 			defer wg.Done()
393: 			for session := range sessionCh {
394: 				if session.EngineIdx != fromIdx {
395: 					continue
396: 				}
397: 				err := m.migrateSession(ctx, session, toEngine, toIdx)
398: 				resultCh <- struct {
399: 					callID string
400: 					err    error
401: 				}{session.CallID, err}
402: 			}
403: 		}()
404: 	}
405: 	for _, session := range sessions {
406: 		sessionCh <- session
407: 	}
408: 	close(sessionCh)
409: 	go func() {
410: 		wg.Wait()
411: 		close(resultCh)
412: 	}()
413: 	for result := range resultCh {
414: 		if result.err != nil {
415: 			m.logger.Error("Failed to migrate RTP session",
416: 				zap.String("callID", result.callID),
417: 				zap.Error(result.err))
418: 			errorCount++
419: 		} else {
420: 			migrationCount++
421: 		}
422: 	}
423: 	m.logger.Info("RTP session migration completed",
424: 		zap.Int("total", len(sessions)),
425: 		zap.Int("migrated", migrationCount),
426: 		zap.Int("errors", errorCount))
427: 	if errorCount > 0 {
428: 		return fmt.Errorf("failed to migrate %d/%d sessions", errorCount, len(sessions))
429: 	}
430: 	return nil
431: }
432: func (m *Manager) migrateSession(ctx context.Context, session *storage.RTPSession, toEngine *RTPEngine, toIdx int) error {
433: 	callID := session.CallID
434: 	fromTag := session.FromTag
435: 	toTag := session.ToTag
436: 	m.logger.Debug("Migrating session",
437: 		zap.String("callID", callID),
438: 		zap.String("fromTag", fromTag),
439: 		zap.String("toTag", toTag))
440: 	params := map[string]interface{}{
441: 		"call-id": callID,
442: 	}
443: 	if fromTag != "" {
444: 		params["from-tag"] = fromTag
445: 	}
446: 	if toTag != "" {
447: 		params["to-tag"] = toTag
448: 	}
449: 	sourceEngine := m.engines[session.EngineIdx]
450: 	queryResult, err := sourceEngine.Query(ctx, params)
451: 	if err != nil {
452: 		return fmt.Errorf("failed to query source engine: %w", err)
453: 	}
454: 	if result, ok := queryResult["result"].(string); !ok || result != "ok" {
455: 		session.EngineIdx = toIdx
456: 		session.EngineAddr = fmt.Sprintf("%s:%d", toEngine.address, toEngine.port)
457: 		session.Updated = time.Now()
458: 		m.storage.StoreRTPSession(ctx, session)
459: 		return nil
460: 	}
461: 	options := make(map[string]interface{})
462: 	totals, ok := queryResult["totals"].(map[string]interface{})
463: 	if ok {
464: 		if _, hasICE := totals["DTLS"]; hasICE {
465: 			options["ICE"] = "force"
466: 			options["DTLS"] = "passive"
467: 		}
468: 	}
469: 	sdpOffer := ""
470: 	if sdp, ok := queryResult["sdp-a"].(string); ok && sdp != "" {
471: 		sdpOffer = sdp
472: 	} else if sdp, ok := queryResult["sdp-b"].(string); ok && sdp != "" {
473: 		sdpOffer = sdp
474: 	}
475: 	if sdpOffer == "" {
476: 		return fmt.Errorf("no SDP available for migration")
477: 	}
478: 	newParams := map[string]interface{}{
479: 		"call-id":  callID,
480: 		"from-tag": fromTag,
481: 		"sdp":      sdpOffer,
482: 		"replace":  "origin,session-connection",
483: 		"label":    "migrated",
484: 	}
485: 	for k, v := range options {
486: 		newParams[k] = v
487: 	}
488: 	offerResult, err := toEngine.Offer(ctx, newParams)
489: 	if err != nil {
490: 		return fmt.Errorf("failed to create offer on destination engine: %w", err)
491: 	}
492: 	if result, ok := offerResult["result"].(string); !ok || result != "ok" {
493: 		return fmt.Errorf("offer creation failed on destination engine")
494: 	}
495: 	if toTag != "" {
496: 		answerSDP := ""
497: 		if sdp, ok := queryResult["sdp-b"].(string); ok && sdp != "" {
498: 			answerSDP = sdp
499: 		} else if sdp, ok := queryResult["sdp-a"].(string); ok && sdp != "" {
500: 			answerSDP = sdp
501: 		}
502: 		if answerSDP != "" {
503: 			answerParams := map[string]interface{}{
504: 				"call-id":  callID,
505: 				"from-tag": fromTag,
506: 				"to-tag":   toTag,
507: 				"sdp":      answerSDP,
508: 				"replace":  "origin,session-connection",
509: 				"label":    "migrated",
510: 			}
511: 			for k, v := range options {
512: 				answerParams[k] = v
513: 			}
514: 			_, err := toEngine.Answer(ctx, answerParams)
515: 			if err != nil {
516: 				toEngine.Delete(ctx, map[string]interface{}{"call-id": callID})
517: 				return fmt.Errorf("failed to create answer on destination engine: %w", err)
518: 			}
519: 		}
520: 	}
521: 	session.EngineIdx = toIdx
522: 	session.EngineAddr = fmt.Sprintf("%s:%d", toEngine.address, toEngine.port)
523: 	session.Updated = time.Now()
524: 	m.storage.StoreRTPSession(ctx, session)
525: 	time.AfterFunc(500*time.Millisecond, func() {
526: 		deleteCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
527: 		defer cancel()
528: 		sourceEngine.Delete(deleteCtx, map[string]interface{}{"call-id": callID})
529: 	})
530: 	return fmt.Errorf("all RTPEngine instances failed")
531: }
</file>

<file path="gateway/pkg/rtpengine/rtpengine.go">
  1: package rtpengine
  2: import (
  3: 	"bytes"
  4: 	"context"
  5: 	"fmt"
  6: 	"math/rand"
  7: 	"net"
  8: 	"sync"
  9: 	"time"
 10: 	"github.com/zeebo/bencode"
 11: 	"go.uber.org/zap"
 12: 	"gateway/pkg/common"
 13: )
 14: type RTPEngine struct {
 15: 	address        string
 16: 	port           int
 17: 	timeout        time.Duration
 18: 	conn           *net.UDPConn
 19: 	serverAddr     *net.UDPAddr
 20: 	logger         *zap.Logger
 21: 	circuitBreaker *common.CircuitBreaker
 22: 	mu             sync.Mutex
 23: }
 24: type Config struct {
 25: 	Address        string                      `json:"address"`
 26: 	Port           int                         `json:"port"`
 27: 	Timeout        time.Duration               `json:"timeout"`
 28: 	Weight         int                         `json:"weight"`
 29: 	CircuitBreaker common.CircuitBreakerConfig `json:"circuit_breaker"`
 30: }
 31: func New(config Config, logger *zap.Logger) (*RTPEngine, error) {
 32: 	if logger == nil {
 33: 		var err error
 34: 		logger, err = zap.NewProduction()
 35: 		if err != nil {
 36: 			return nil, err
 37: 		}
 38: 	}
 39: 	serverAddr, err := net.ResolveUDPAddr("udp", fmt.Sprintf("%s:%d", config.Address, config.Port))
 40: 	if err != nil {
 41: 		return nil, fmt.Errorf("failed to resolve server address: %w", err)
 42: 	}
 43: 	if config.Timeout <= 0 {
 44: 		config.Timeout = 500 * time.Millisecond
 45: 	}
 46: 	cbName := fmt.Sprintf("rtpengine-%s:%d", config.Address, config.Port)
 47: 	cb := common.NewCircuitBreaker(cbName, config.CircuitBreaker, logger)
 48: 	r := &RTPEngine{
 49: 		address:        config.Address,
 50: 		port:           config.Port,
 51: 		timeout:        config.Timeout,
 52: 		serverAddr:     serverAddr,
 53: 		logger:         logger,
 54: 		circuitBreaker: cb,
 55: 	}
 56: 	return r, nil
 57: }
 58: func (r *RTPEngine) ensureConnection() error {
 59: 	r.mu.Lock()
 60: 	defer r.mu.Unlock()
 61: 	if r.conn != nil {
 62: 		r.conn.Close()
 63: 		r.conn = nil
 64: 	}
 65: 	conn, err := net.DialUDP("udp", nil, r.serverAddr)
 66: 	if err != nil {
 67: 		return fmt.Errorf("failed to establish UDP connection: %w", err)
 68: 	}
 69: 	r.conn = conn
 70: 	return nil
 71: }
 72: func (r *RTPEngine) Close() error {
 73: 	r.mu.Lock()
 74: 	defer r.mu.Unlock()
 75: 	if r.conn != nil {
 76: 		err := r.conn.Close()
 77: 		r.conn = nil
 78: 		return err
 79: 	}
 80: 	return nil
 81: }
 82: func (r *RTPEngine) Request(ctx context.Context, command map[string]interface{}) (map[string]interface{}, error) {
 83: 	if !r.circuitBreaker.AllowRequest() {
 84: 		return nil, fmt.Errorf("circuit breaker open for RTPEngine %s:%d", r.address, r.port)
 85: 	}
 86: 	if err := r.ensureConnection(); err != nil {
 87: 		r.circuitBreaker.RecordFailure()
 88: 		return nil, err
 89: 	}
 90: 	defer func() {
 91: 		r.mu.Lock()
 92: 		if r.conn != nil {
 93: 			r.conn.Close()
 94: 			r.conn = nil
 95: 		}
 96: 		r.mu.Unlock()
 97: 	}()
 98: 	rand.Seed(time.Now().UnixNano())
 99: 	cookie := fmt.Sprintf("%d ", rand.Intn(1000000))
100: 	var buf bytes.Buffer
101: 	if err := bencode.NewEncoder(&buf).Encode(command); err != nil {
102: 		return nil, fmt.Errorf("failed to encode command: %w", err)
103: 	}
104: 	packet := buf.Bytes()
105: 	fullPacket := append([]byte(cookie), packet...)
106: 	deadline, ok := ctx.Deadline()
107: 	if !ok {
108: 		deadline = time.Now().Add(r.timeout)
109: 	}
110: 	if err := r.conn.SetWriteDeadline(deadline); err != nil {
111: 		r.circuitBreaker.RecordFailure()
112: 		return nil, fmt.Errorf("failed to set write deadline: %w", err)
113: 	}
114: 	if _, err := r.conn.Write(fullPacket); err != nil {
115: 		r.circuitBreaker.RecordFailure()
116: 		return nil, fmt.Errorf("failed to send packet: %w", err)
117: 	}
118: 	if err := r.conn.SetReadDeadline(deadline); err != nil {
119: 		r.circuitBreaker.RecordFailure()
120: 		return nil, fmt.Errorf("failed to set read deadline: %w", err)
121: 	}
122: 	responseBuffer := make([]byte, 65535)
123: 	n, _, err := r.conn.ReadFromUDP(responseBuffer)
124: 	if err != nil {
125: 		r.circuitBreaker.RecordFailure()
126: 		return nil, fmt.Errorf("failed to receive response: %w", err)
127: 	}
128: 	response := responseBuffer[:n]
129: 	if len(response) < len(cookie) || string(response[:len(cookie)]) != cookie {
130: 		r.circuitBreaker.RecordFailure()
131: 		return nil, fmt.Errorf("cookie mismatch in response")
132: 	}
133: 	response = response[len(cookie):]
134: 	response = bytes.TrimSpace(response)
135: 	var result map[string]interface{}
136: 	if err := bencode.NewDecoder(bytes.NewReader(response)).Decode(&result); err != nil {
137: 		r.circuitBreaker.RecordFailure()
138: 		return nil, fmt.Errorf("failed to decode response: %w", err)
139: 	}
140: 	if res, ok := result["result"]; !ok {
141: 		r.circuitBreaker.RecordFailure()
142: 		return nil, fmt.Errorf("no result field in response: %v", result)
143: 	} else if resStr, ok := res.(string); ok && resStr == "error" {
144: 		r.circuitBreaker.RecordFailure()
145: 		errorReason, _ := result["error-reason"].(string)
146: 		return nil, fmt.Errorf("RTPEngine error: %s", errorReason)
147: 	}
148: 	r.circuitBreaker.RecordSuccess()
149: 	return result, nil
150: }
151: func (r *RTPEngine) Offer(ctx context.Context, params map[string]interface{}) (map[string]interface{}, error) {
152: 	params["command"] = "offer"
153: 	return r.Request(ctx, params)
154: }
155: func (r *RTPEngine) Answer(ctx context.Context, params map[string]interface{}) (map[string]interface{}, error) {
156: 	params["command"] = "answer"
157: 	return r.Request(ctx, params)
158: }
159: func (r *RTPEngine) Delete(ctx context.Context, params map[string]interface{}) (map[string]interface{}, error) {
160: 	params["command"] = "delete"
161: 	return r.Request(ctx, params)
162: }
163: func (r *RTPEngine) Query(ctx context.Context, params map[string]interface{}) (map[string]interface{}, error) {
164: 	params["command"] = "query"
165: 	return r.Request(ctx, params)
166: }
167: func (r *RTPEngine) List(ctx context.Context) (map[string]interface{}, error) {
168: 	params := map[string]interface{}{
169: 		"command": "list",
170: 	}
171: 	return r.Request(ctx, params)
172: }
173: func (r *RTPEngine) Ping(ctx context.Context) error {
174: 	params := map[string]interface{}{
175: 		"command": "ping",
176: 	}
177: 	result, err := r.Request(ctx, params)
178: 	if err != nil {
179: 		return err
180: 	}
181: 	if res, ok := result["result"].(string); !ok || res != "pong" {
182: 		return fmt.Errorf("unexpected ping response: %v", result)
183: 	}
184: 	r.logger.Info("RTPengine healthy: ping returned pong")
185: 	return nil
186: }
187: func (r *RTPEngine) GetStats(ctx context.Context) (map[string]interface{}, error) {
188: 	params := map[string]interface{}{
189: 		"command": "statistics",
190: 	}
191: 	return r.Request(ctx, params)
192: }
</file>

<file path="gateway/pkg/sip/proxy.go">
  1: package sip
  2: import (
  3: 	"context"
  4: 	"errors"
  5: 	"fmt"
  6: 	"log/slog"
  7: 	"net"
  8: 	"strconv"
  9: 	"strings"
 10: 	"sync"
 11: 	"time"
 12: 	"gateway/pkg/rtpengine"
 13: 	"gateway/pkg/storage"
 14: 	"github.com/emiago/sipgo"
 15: 	"github.com/emiago/sipgo/sip"
 16: 	"go.uber.org/zap"
 17: )
 18: type Registry struct {
 19: 	mu    sync.RWMutex
 20: 	store map[string]string
 21: }
 22: func NewRegistry() *Registry {
 23: 	return &Registry{
 24: 		store: make(map[string]string),
 25: 	}
 26: }
 27: func (r *Registry) Add(user, addr string) {
 28: 	r.mu.Lock()
 29: 	defer r.mu.Unlock()
 30: 	r.store[user] = addr
 31: }
 32: func (r *Registry) Get(user string) string {
 33: 	r.mu.RLock()
 34: 	defer r.mu.RUnlock()
 35: 	return r.store[user]
 36: }
 37: func setupSipProxy(proxydst, ip string) (*sipgo.Server, *sipgo.Client, *Registry) {
 38: 	log := slog.Default()
 39: 	host, port, _ := sip.ParseAddr(ip)
 40: 	ua, err := sipgo.NewUA()
 41: 	if err != nil {
 42: 		log.Error("Failed to create UA", "error", err)
 43: 		return nil, nil, nil
 44: 	}
 45: 	srv, err := sipgo.NewServer(ua)
 46: 	if err != nil {
 47: 		log.Error("Failed to create server", "error", err)
 48: 		return nil, nil, nil
 49: 	}
 50: 	client, err := sipgo.NewClient(ua)
 51: 	if err != nil {
 52: 		log.Error("Failed to create client", "error", err)
 53: 		return nil, nil, nil
 54: 	}
 55: 	registry := NewRegistry()
 56: 	var getDestination = func(req *sip.Request) string {
 57: 		toHeader := req.To()
 58: 		if toHeader == nil || toHeader.Address.Host == "" {
 59: 			return proxydst
 60: 		}
 61: 		dst := registry.Get(toHeader.Address.User)
 62: 		if dst == "" {
 63: 			return proxydst
 64: 		}
 65: 		return dst
 66: 	}
 67: 	// reply sends a response with the provided code and reason.
 68: 	var reply = func(tx sip.ServerTransaction, req *sip.Request, code int, reason string) {
 69: 		resp := sip.NewResponseFromRequest(req, code, reason, nil)
 70: 		resp.SetDestination(req.Source())
 71: 		if err := tx.Respond(resp); err != nil {
 72: 			log.Error("Failed to send response", "error", err)
 73: 		}
 74: 	}
 75: 	var route = func(req *sip.Request, tx sip.ServerTransaction) {
 76: 		log.Debug("route() called - forwarding logic", "method", req.Method.String())
 77: 		dstAddr := getDestination(req)
 78: 		if dstAddr == "" {
 79: 			reply(tx, req, 404, "Not found")
 80: 			return
 81: 		}
 82: 		ctx := context.Background()
 83: 		req.SetDestination(dstAddr)
 84: 		clTx, err := client.TransactionRequest(ctx, req,
 85: 			sipgo.ClientRequestAddVia,
 86: 			sipgo.ClientRequestAddRecordRoute,
 87: 		)
 88: 		if err != nil {
 89: 			log.Error("Failed to create client transaction in route()",
 90: 				"error", err,
 91: 				"destination", dstAddr)
 92: 			reply(tx, req, 500, "")
 93: 			return
 94: 		}
 95: 		defer clTx.Terminate()
 96: 		log.Debug("Starting transaction in route()",
 97: 			"method", req.Method.String(),
 98: 			"destination", dstAddr)
 99: 		for {
100: 			select {
101: 			case res, more := <-clTx.Responses():
102: 				if !more {
103: 					return
104: 				}
105: 				res.SetDestination(req.Source())
106: 				res.RemoveHeader("Via")
107: 				if err := tx.Respond(res); err != nil {
108: 					log.Error("Failed to forward response in route()", "error", err)
109: 				}
110: 			case <-clTx.Done():
111: 				if err := clTx.Err(); err != nil {
112: 					log.Error("Client transaction ended with error in route()", "error", err)
113: 				}
114: 				return
115: 			case ack := <-tx.Acks():
116: 				log.Info("Proxying ACK",
117: 					"method", req.Method.String(),
118: 					"dstAddr", dstAddr)
119: 				ack.SetDestination(dstAddr)
120: 				if wErr := client.WriteRequest(ack); wErr != nil {
121: 					log.Error("ACK forward failed", "error", wErr)
122: 				}
123: 			case <-tx.Done():
124: 				if err := tx.Err(); err != nil {
125: 					if errors.Is(err, sip.ErrTransactionCanceled) {
126: 						if req.IsInvite() {
127: 							r := newCancelRequest(req)
128: 							res, cErr := client.Do(ctx, r)
129: 							if cErr != nil {
130: 								log.Error("Canceling downstream transaction failed", "error", cErr)
131: 							} else if res.StatusCode != 200 {
132: 								log.Error("Downstream CANCEL returned non-200 code", "code", res.StatusCode)
133: 							}
134: 						}
135: 					} else {
136: 						log.Error("Server transaction ended with error in route()", "error", err)
137: 					}
138: 				}
139: 				log.Debug("Transaction done in route()", "method", req.Method.String())
140: 				return
141: 			}
142: 		}
143: 	}
144: 	srv.OnRegister(func(req *sip.Request, tx sip.ServerTransaction) {
145: 		contactHeader := req.Contact()
146: 		if contactHeader == nil || contactHeader.Address.Host == "" {
147: 			reply(tx, req, 404, "Missing address of record")
148: 			return
149: 		}
150: 		uri := contactHeader.Address
151: 		if uri.Host == host && uri.Port == port {
152: 			reply(tx, req, 401, "Contact address not provided")
153: 			return
154: 		}
155: 		addr := uri.Host + ":" + strconv.Itoa(uri.Port)
156: 		registry.Add(uri.User, addr)
157: 		log.Debug(fmt.Sprintf("Registered %s -> %s (OnRegister handler)", uri.User, addr))
158: 		res := sip.NewResponseFromRequest(req, 200, "OK", nil)
159: 		uri.UriParams = sip.NewParams()
160: 		uri.UriParams.Add("transport", req.Transport())
161: 		if err := tx.Respond(res); err != nil {
162: 			log.Error("Failed to respond 200 to REGISTER in OnRegister", "error", err)
163: 		}
164: 	})
165: 	srv.OnInvite(func(req *sip.Request, tx sip.ServerTransaction) {
166: 		route(req, tx)
167: 	})
168: 	srv.OnAck(func(req *sip.Request, tx sip.ServerTransaction) {
169: 		dstAddr := getDestination(req)
170: 		if dstAddr == "" {
171: 			log.Debug("OnAck: no destination found, skipping")
172: 			return
173: 		}
174: 		req.SetDestination(dstAddr)
175: 		if err := client.WriteRequest(req, sipgo.ClientRequestAddVia); err != nil {
176: 			log.Error("ACK forward failed in OnAck", "error", err)
177: 			reply(tx, req, 500, "")
178: 		}
179: 	})
180: 	srv.OnCancel(func(req *sip.Request, tx sip.ServerTransaction) {
181: 		route(req, tx)
182: 	})
183: 	srv.OnBye(func(req *sip.Request, tx sip.ServerTransaction) {
184: 		route(req, tx)
185: 	})
186: 	return srv, client, registry
187: }
188: func newCancelRequest(inviteRequest *sip.Request) *sip.Request {
189: 	cancelReq := sip.NewRequest(sip.CANCEL, inviteRequest.Recipient)
190: 	cancelReq.AppendHeader(sip.HeaderClone(inviteRequest.Via()))
191: 	cancelReq.AppendHeader(sip.HeaderClone(inviteRequest.From()))
192: 	cancelReq.AppendHeader(sip.HeaderClone(inviteRequest.To()))
193: 	cancelReq.AppendHeader(sip.HeaderClone(inviteRequest.CallID()))
194: 	sip.CopyHeaders("Route", inviteRequest, cancelReq)
195: 	cancelReq.SetSource(inviteRequest.Source())
196: 	cancelReq.SetDestination(inviteRequest.Destination())
197: 	return cancelReq
198: }
199: type SIPConfig struct {
200: 	UDPBindAddr             string
201: 	ProxyURI                string
202: 	DefaultNextHop          string
203: 	MaxForwards             int
204: 	UserAgent               string
205: 	DisableUDPSIPProcessing bool
206: 	DisableWSSIPProcessing  bool
207: }
208: type Proxy struct {
209: 	server     *sipgo.Server
210: 	client     *sipgo.Client
211: 	registry   *Registry
212: 	logger     *zap.Logger
213: 	storage    storage.StateStorage
214: 	rtpEngine  *rtpengine.Manager
215: 	transports []Transport
216: 	proxyDst   string
217: 	config     SIPConfig
218: }
219: func NewProxy(
220: 	cfg SIPConfig,
221: 	storage storage.StateStorage,
222: 	rtpEngine *rtpengine.Manager,
223: 	logger *zap.Logger,
224: ) (*Proxy, error) {
225: 	srv, client, registry := setupSipProxy(cfg.DefaultNextHop, cfg.UDPBindAddr)
226: 	if srv == nil {
227: 		return nil, errors.New("failed to create SIP server")
228: 	}
229: 	logger.Warn("NewProxy called",
230: 		zap.String("UDPBindAddr", cfg.UDPBindAddr),
231: 		zap.String("DefaultNextHop", cfg.DefaultNextHop),
232: 		zap.Bool("DisableUDPSIPProcessing", cfg.DisableUDPSIPProcessing),
233: 		zap.Bool("DisableWSSIPProcessing", cfg.DisableWSSIPProcessing),
234: 	)
235: 	logger.Warn("Successfully created sipgo.Server + sipgo.Client",
236: 		zap.String("DefaultNextHop", cfg.DefaultNextHop),
237: 		zap.Bool("DisableUDPSIPProcessing", cfg.DisableUDPSIPProcessing),
238: 		zap.Bool("DisableWSSIPProcessing", cfg.DisableWSSIPProcessing),
239: 	)
240: 	return &Proxy{
241: 		server:     srv,
242: 		client:     client,
243: 		registry:   registry,
244: 		logger:     logger,
245: 		storage:    storage,
246: 		rtpEngine:  rtpEngine,
247: 		transports: []Transport{},
248: 		proxyDst:   cfg.DefaultNextHop,
249: 		config:     cfg,
250: 	}, nil
251: }
252: func (p *Proxy) AddTransport(t Transport) {
253: 	p.logger.Debug("AddTransport called", zap.String("bindAddr", t.(*UDPTransport).bindAddr))
254: 	p.transports = append(p.transports, t)
255: }
256: func (p *Proxy) Start(ctx context.Context) error {
257: 	p.logger.Warn("Proxy.Start() called",
258: 		zap.String("UDPBindAddr", p.config.UDPBindAddr),
259: 		zap.String("DefaultNextHop", p.config.DefaultNextHop),
260: 		zap.Bool("DisableUDPSIPProcessing", p.config.DisableUDPSIPProcessing),
261: 		zap.Bool("DisableWSSIPProcessing", p.config.DisableWSSIPProcessing),
262: 	)
263: 	go func() {
264: 		err := p.server.ListenAndServe(ctx, "udp", "")
265: 		if err != nil && err != context.Canceled {
266: 			p.logger.Error("SIP server failed", zap.Error(err))
267: 		}
268: 	}()
269: 	return nil
270: }
271: func (p *Proxy) Stop() error {
272: 	p.logger.Info("Stop() called on SIP proxy")
273: 	return nil
274: }
275: func (p *Proxy) HandleMessage(msg Message, addr net.Addr) error {
276: 	clientAddr := addr.String()
277: 	isWebSocket := false
278: 	network := addr.Network()
279: 	if network == "ws" || network == "wss" || strings.Contains(network, "websocket") {
280: 		isWebSocket = true
281: 	}
282: 	skipProcessing := false
283: 	if isWebSocket {
284: 		skipProcessing = p.config.DisableWSSIPProcessing
285: 		p.logger.Warn("HandleMessage invoked (WebSocket)",
286: 			zap.String("clientAddr", clientAddr),
287: 			zap.String("network", network),
288: 			zap.Bool("skipProcessing", skipProcessing))
289: 	} else {
290: 		skipProcessing = p.config.DisableUDPSIPProcessing
291: 		p.logger.Warn("HandleMessage invoked (UDP)",
292: 			zap.String("clientAddr", clientAddr),
293: 			zap.String("network", network),
294: 			zap.Bool("skipProcessing", skipProcessing))
295: 	}
296: 	if req, ok := msg.(*Request); ok {
297: 		method := req.Method.String()
298: 		p.logger.Debug("Decoded SIP request",
299: 			zap.String("method", method),
300: 			zap.String("clientAddr", clientAddr),
301: 		)
302: 		if skipProcessing {
303: 			p.logger.Debug("Skipping processing due to configuration",
304: 				zap.String("method", method),
305: 				zap.String("clientAddr", clientAddr),
306: 				zap.String("transport", network))
307: 			return nil
308: 		}
309: 		switch method {
310: 		case "REGISTER":
311: 			return p.handleRegister(req, clientAddr)
312: 		case "INVITE":
313: 			return p.handleInvite(req, clientAddr)
314: 		case "BYE":
315: 			return p.handleBye(req, clientAddr)
316: 		case "ACK":
317: 			return p.handleAck(req, clientAddr)
318: 		case "CANCEL":
319: 			return p.handleCancel(req, clientAddr)
320: 		case "OPTIONS":
321: 			return p.handleOptions(req, clientAddr)
322: 		default:
323: 			p.logger.Debug("Unhandled SIP method",
324: 				zap.String("method", method),
325: 				zap.String("client", clientAddr))
326: 		}
327: 	} else if resp, ok := msg.(*Response); ok {
328: 		p.logger.Debug("Decoded SIP response",
329: 			zap.Int("status", resp.StatusCode),
330: 			zap.String("clientAddr", clientAddr),
331: 		)
332: 		return p.handleResponse(resp, clientAddr)
333: 	}
334: 	return nil
335: }
336: func (p *Proxy) handleRegister(req *Request, clientAddr string) error {
337: 	isWebSocket := strings.Contains(clientAddr, "-")
338: 	skipProcessing := false
339: 	if isWebSocket {
340: 		skipProcessing = p.config.DisableWSSIPProcessing
341: 	} else {
342: 		skipProcessing = p.config.DisableUDPSIPProcessing
343: 	}
344: 	p.logger.Warn("handleRegister invoked",
345: 		zap.String("clientAddr", clientAddr),
346: 		zap.Bool("skipProcessing", skipProcessing),
347: 	)
348: 	contactHeader := req.Contact()
349: 	if contactHeader == nil || contactHeader.Address.Host == "" {
350: 		p.logger.Error("Missing address of record in REGISTER",
351: 			zap.String("client", clientAddr))
352: 		return errors.New("missing address of record")
353: 	}
354: 	uri := contactHeader.Address
355: 	host, port, _ := net.SplitHostPort(clientAddr)
356: 	portNum, _ := strconv.Atoi(port)
357: 	if uri.Host == host && uri.Port == portNum {
358: 		p.logger.Error("Contact address not provided in REGISTER",
359: 			zap.String("client", clientAddr))
360: 		return errors.New("contact address not provided")
361: 	}
362: 	addr := uri.Host + ":" + strconv.Itoa(uri.Port)
363: 	p.registry.Add(uri.User, addr)
364: 	p.logger.Debug("Registered user via WebSocket",
365: 		zap.String("user", uri.User),
366: 		zap.String("address", addr),
367: 		zap.String("clientAddr", clientAddr),
368: 	)
369: 	if skipProcessing {
370: 		p.logger.Warn("Skipping forwardRequest for REGISTER (processing disabled)",
371: 			zap.String("client", clientAddr))
372: 		return nil
373: 	}
374: 	return p.forwardRequest(req, clientAddr)
375: }
376: func (p *Proxy) handleInvite(req *Request, clientAddr string) error {
377: 	isWebSocket := strings.Contains(clientAddr, "-")
378: 	skipProcessing := false
379: 	if isWebSocket {
380: 		skipProcessing = p.config.DisableWSSIPProcessing
381: 	} else {
382: 		skipProcessing = p.config.DisableUDPSIPProcessing
383: 	}
384: 	p.logger.Warn("handleInvite invoked",
385: 		zap.String("clientAddr", clientAddr),
386: 		zap.Bool("skipProcessing", skipProcessing),
387: 	)
388: 	if skipProcessing {
389: 		p.logger.Debug("Skipping processing for INVITE request",
390: 			zap.String("clientAddr", clientAddr))
391: 		return nil
392: 	}
393: 	return p.forwardRequest(req, clientAddr)
394: }
395: func (p *Proxy) handleBye(req *Request, clientAddr string) error {
396: 	isWebSocket := strings.Contains(clientAddr, "-")
397: 	skipProcessing := false
398: 	if isWebSocket {
399: 		skipProcessing = p.config.DisableWSSIPProcessing
400: 	} else {
401: 		skipProcessing = p.config.DisableUDPSIPProcessing
402: 	}
403: 	p.logger.Warn("handleBye invoked",
404: 		zap.String("clientAddr", clientAddr),
405: 		zap.Bool("skipProcessing", skipProcessing),
406: 	)
407: 	if skipProcessing {
408: 		p.logger.Debug("Skipping processing for BYE request",
409: 			zap.String("clientAddr", clientAddr))
410: 		return nil
411: 	}
412: 	return p.forwardRequest(req, clientAddr)
413: }
414: func (p *Proxy) handleAck(req *Request, clientAddr string) error {
415: 	isWebSocket := strings.Contains(clientAddr, "-")
416: 	skipProcessing := false
417: 	if isWebSocket {
418: 		skipProcessing = p.config.DisableWSSIPProcessing
419: 	} else {
420: 		skipProcessing = p.config.DisableUDPSIPProcessing
421: 	}
422: 	p.logger.Warn("handleAck invoked",
423: 		zap.String("clientAddr", clientAddr),
424: 		zap.Bool("skipProcessing", skipProcessing),
425: 	)
426: 	if skipProcessing {
427: 		p.logger.Debug("Skipping processing for ACK request",
428: 			zap.String("clientAddr", clientAddr))
429: 		return nil
430: 	}
431: 	return p.forwardRequest(req, clientAddr)
432: }
433: func (p *Proxy) handleCancel(req *Request, clientAddr string) error {
434: 	isWebSocket := strings.Contains(clientAddr, "-")
435: 	skipProcessing := false
436: 	if isWebSocket {
437: 		skipProcessing = p.config.DisableWSSIPProcessing
438: 	} else {
439: 		skipProcessing = p.config.DisableUDPSIPProcessing
440: 	}
441: 	p.logger.Warn("handleCancel invoked",
442: 		zap.String("clientAddr", clientAddr),
443: 		zap.Bool("skipProcessing", skipProcessing),
444: 	)
445: 	if skipProcessing {
446: 		p.logger.Debug("Skipping processing for CANCEL request",
447: 			zap.String("clientAddr", clientAddr))
448: 		return nil
449: 	}
450: 	return p.forwardRequest(req, clientAddr)
451: }
452: func (p *Proxy) handleOptions(req *Request, clientAddr string) error {
453: 	isWebSocket := strings.Contains(clientAddr, "-")
454: 	skipProcessing := false
455: 	if isWebSocket {
456: 		skipProcessing = p.config.DisableWSSIPProcessing
457: 	} else {
458: 		skipProcessing = p.config.DisableUDPSIPProcessing
459: 	}
460: 	p.logger.Warn("handleOptions invoked",
461: 		zap.String("clientAddr", clientAddr),
462: 		zap.Bool("skipProcessing", skipProcessing),
463: 	)
464: 	if skipProcessing {
465: 		p.logger.Debug("Skipping processing for OPTIONS request",
466: 			zap.String("clientAddr", clientAddr))
467: 		return nil
468: 	}
469: 	return p.forwardRequest(req, clientAddr)
470: }
471: func (p *Proxy) handleResponse(resp *Response, clientAddr string) error {
472: 	isWebSocket := strings.Contains(clientAddr, "-")
473: 	skipProcessing := false
474: 	if isWebSocket {
475: 		skipProcessing = p.config.DisableWSSIPProcessing
476: 	} else {
477: 		skipProcessing = p.config.DisableUDPSIPProcessing
478: 	}
479: 	p.logger.Warn("handleResponse invoked (SIP response)",
480: 		zap.Int("statusCode", resp.StatusCode),
481: 		zap.String("clientAddr", clientAddr),
482: 		zap.Bool("skipProcessing", skipProcessing),
483: 	)
484: 	if skipProcessing {
485: 		p.logger.Debug("Skipping processing for SIP response",
486: 			zap.Int("statusCode", resp.StatusCode),
487: 			zap.String("clientAddr", clientAddr))
488: 		return nil
489: 	}
490: 	return nil
491: }
492: func (p *Proxy) forwardRequest(req *Request, clientAddr string) error {
493: 	isWebSocket := strings.Contains(clientAddr, "-")
494: 	skipProcessing := false
495: 	if isWebSocket {
496: 		skipProcessing = p.config.DisableWSSIPProcessing
497: 	} else {
498: 		skipProcessing = p.config.DisableUDPSIPProcessing
499: 	}
500: 	p.logger.Warn("forwardRequest called",
501: 		zap.String("method", req.Method.String()),
502: 		zap.String("clientAddr", clientAddr),
503: 		zap.Bool("skipProcessing", skipProcessing),
504: 	)
505: 	if skipProcessing {
506: 		p.logger.Warn("Short-circuit: skipping local SIP transaction creation (processing disabled)",
507: 			zap.String("method", req.Method.String()),
508: 			zap.String("client", clientAddr),
509: 		)
510: 		return nil
511: 	}
512: 	dstAddr := p.getDestination(req)
513: 	if dstAddr == "" {
514: 		p.logger.Error("No destination found for request",
515: 			zap.String("method", req.Method.String()),
516: 			zap.String("client", clientAddr))
517: 		return errors.New("no destination found")
518: 	}
519: 	req.SetDestination(dstAddr)
520: 	p.logger.Debug("Proceeding with local SIP transaction creation",
521: 		zap.String("method", req.Method.String()),
522: 		zap.String("client", clientAddr),
523: 		zap.String("dstAddr", dstAddr),
524: 	)
525: 	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
526: 	defer cancel()
527: 	var clTx sip.ClientTransaction
528: 	var err error
529: 	maxRetries := 3
530: 	for attempt := 0; attempt < maxRetries; attempt++ {
531: 		clTx, err = p.client.TransactionRequest(ctx, req,
532: 			sipgo.ClientRequestAddVia,
533: 			sipgo.ClientRequestAddRecordRoute,
534: 		)
535: 		if err == nil {
536: 			break
537: 		}
538: 		if strings.Contains(err.Error(), "bind: address already in use") {
539: 			p.logger.Warn("Port binding issue, retrying in forwardRequest()",
540: 				zap.Int("attempt", attempt+1),
541: 				zap.String("client", clientAddr))
542: 			time.Sleep(200 * time.Millisecond)
543: 			continue
544: 		}
545: 		p.logger.Error("Failed to create client transaction for WebSocket request in forwardRequest()",
546: 			zap.Error(err),
547: 			zap.String("client", clientAddr),
548: 			zap.Int("attempt", attempt+1),
549: 		)
550: 		return err
551: 	}
552: 	if err != nil {
553: 		p.logger.Error("Failed to create client transaction after retries in forwardRequest()",
554: 			zap.Error(err),
555: 			zap.String("client", clientAddr),
556: 			zap.Int("maxRetries", maxRetries))
557: 		return err
558: 	}
559: 	defer clTx.Terminate()
560: 	p.logger.Debug("Forwarded WebSocket SIP request successfully",
561: 		zap.String("method", req.Method.String()),
562: 		zap.String("client", clientAddr),
563: 		zap.String("destination", dstAddr),
564: 	)
565: 	return nil
566: }
567: func (p *Proxy) getDestination(req *sip.Request) string {
568: 	toHeader := req.To()
569: 	if toHeader == nil || toHeader.Address.Host == "" {
570: 		p.logger.Debug("getDestination returning proxyDst due to empty To header",
571: 			zap.String("proxyDst", p.proxyDst))
572: 		return p.proxyDst
573: 	}
574: 	dst := p.registry.Get(toHeader.Address.User)
575: 	if dst == "" {
576: 		p.logger.Debug("getDestination: not found in registry, returning proxyDst",
577: 			zap.String("proxyDst", p.proxyDst),
578: 			zap.String("toUser", toHeader.Address.User))
579: 		return p.proxyDst
580: 	}
581: 	p.logger.Debug("getDestination found registry entry", zap.String("finalDst", dst))
582: 	return dst
583: }
584: type Transport interface {
585: 	Send(msg sip.Message, addr net.Addr) error
586: }
587: type UDPTransport struct {
588: 	bindAddr string
589: 	logger   *zap.Logger
590: 	conn     *net.UDPConn
591: }
592: func NewUDPTransportImpl(bindAddr string, logger *zap.Logger) (*UDPTransport, error) {
593: 	udpAddr, err := net.ResolveUDPAddr("udp", bindAddr)
594: 	if err != nil {
595: 		return nil, err
596: 	}
597: 	conn, err := net.ListenUDP("udp", udpAddr)
598: 	if err != nil {
599: 		return nil, err
600: 	}
601: 	return &UDPTransport{
602: 		bindAddr: bindAddr,
603: 		logger:   logger,
604: 		conn:     conn,
605: 	}, nil
606: }
607: func (t *UDPTransport) Send(msg sip.Message, addr net.Addr) error {
608: 	data := []byte(msg.String())
609: 	udpAddr, ok := addr.(*net.UDPAddr)
610: 	if !ok {
611: 		return errors.New("invalid UDP address")
612: 	}
613: 	_, err := t.conn.WriteToUDP(data, udpAddr)
614: 	return err
615: }
616: func NewUDPTransport(bindAddr string, logger *zap.Logger) (Transport, error) {
617: 	return NewUDPTransportImpl(bindAddr, logger)
618: }
</file>

<file path="gateway/pkg/sip/sip.go">
 1: package sip
 2: import (
 3: 	sipgo "github.com/emiago/sipgo/sip"
 4: )
 5: type Message = sipgo.Message
 6: func ParseMessage(data []byte) (Message, error) {
 7: 	return sipgo.ParseMessage(data)
 8: }
 9: type Request = sipgo.Request
10: type Response = sipgo.Response
11: type ServerTransaction = sipgo.ServerTransaction
12: type ClientTransaction = sipgo.ClientTransaction
13: var (
14: 	ErrTransactionCanceled = sipgo.ErrTransactionCanceled
15: 	CANCEL                 = sipgo.CANCEL
16: )
</file>

<file path="gateway/pkg/storage/memory.go">
  1: package storage
  2: import (
  3: 	"context"
  4: 	"encoding/json"
  5: 	"fmt"
  6: 	"os"
  7: 	"path/filepath"
  8: 	"sync"
  9: 	"time"
 10: 	"go.uber.org/zap"
 11: 	"gateway/pkg/common"
 12: )
 13: type MemoryStorage struct {
 14: 	data       []*sync.Map
 15: 	shardCount int
 16: 	dialogs        sync.Map
 17: 	rtpSessions    sync.Map
 18: 	amiActions     sync.Map
 19: 	clientSessions sync.Map
 20: 	wsConnections  sync.Map
 21: 	registrations  sync.Map
 22: 	maxKeys           int
 23: 	cleanupInterval   time.Duration
 24: 	persistPath       string
 25: 	persistOnShutdown bool
 26: 	logger            *zap.Logger
 27: 	stats   StorageStats
 28: 	statsMu sync.RWMutex
 29: 	stopCleanup chan struct{}
 30: 	cleanupDone chan struct{}
 31: }
 32: type MemoryConfig struct {
 33: 	MaxKeys           int           `json:"max_keys"`
 34: 	CleanupInterval   time.Duration `json:"cleanup_interval"`
 35: 	PersistPath       string        `json:"persist_path"`
 36: 	PersistOnShutdown bool          `json:"persist_on_shutdown"`
 37: 	ShardCount        int           `json:"shard_count"`
 38: }
 39: func NewMemoryStorage(config MemoryConfig, logger *zap.Logger) (*MemoryStorage, error) {
 40: 	if logger == nil {
 41: 		var err error
 42: 		logger, err = zap.NewProduction()
 43: 		if err != nil {
 44: 			return nil, err
 45: 		}
 46: 	}
 47: 	maxKeys := config.MaxKeys
 48: 	if maxKeys <= 0 {
 49: 		maxKeys = 10000
 50: 	}
 51: 	cleanupInterval := config.CleanupInterval
 52: 	if cleanupInterval <= 0 {
 53: 		cleanupInterval = 5 * time.Minute
 54: 	}
 55: 	shardCount := config.ShardCount
 56: 	if shardCount <= 0 {
 57: 		shardCount = 32
 58: 	}
 59: 	shards := make([]*sync.Map, shardCount)
 60: 	for i := 0; i < shardCount; i++ {
 61: 		shards[i] = &sync.Map{}
 62: 	}
 63: 	storage := &MemoryStorage{
 64: 		data:              shards,
 65: 		shardCount:        shardCount,
 66: 		maxKeys:           maxKeys,
 67: 		cleanupInterval:   cleanupInterval,
 68: 		persistPath:       config.PersistPath,
 69: 		persistOnShutdown: config.PersistOnShutdown,
 70: 		logger:            logger,
 71: 		stopCleanup:       make(chan struct{}),
 72: 		cleanupDone:       make(chan struct{}),
 73: 	}
 74: 	if config.PersistPath != "" {
 75: 		if err := storage.loadFromFile(); err != nil {
 76: 			logger.Warn("Failed to load persisted data", zap.Error(err))
 77: 		}
 78: 	}
 79: 	go storage.cleanupLoop()
 80: 	logger.Info("In-memory storage initialized",
 81: 		zap.Int("maxKeys", maxKeys),
 82: 		zap.String("cleanupInterval", cleanupInterval.String()),
 83: 		zap.String("persistPath", config.PersistPath),
 84: 		zap.Int("shardCount", shardCount))
 85: 	return storage, nil
 86: }
 87: func (m *MemoryStorage) getShard(key string) *sync.Map {
 88: 	hash := 0
 89: 	for i := 0; i < len(key); i++ {
 90: 		hash = 31*hash + int(key[i])
 91: 	}
 92: 	if hash < 0 {
 93: 		hash = -hash
 94: 	}
 95: 	return m.data[hash%m.shardCount]
 96: }
 97: func (m *MemoryStorage) Get(ctx context.Context, key string) ([]byte, error) {
 98: 	ctx, cancel := common.QuickTimeout(ctx)
 99: 	defer cancel()
100: 	if key == "" {
101: 		return nil, ErrInvalidKey
102: 	}
103: 	shard := m.getShard(key)
104: 	if value, ok := shard.Load(key); ok {
105: 		if kv, ok := value.(KeyValue); ok {
106: 			// Check expiration
107: 			if !kv.Expiration.IsZero() && kv.Expiration.Before(time.Now()) {
108: 				// Expired, remove it
109: 				shard.Delete(key)
110: 				return nil, ErrKeyExpired
111: 			}
112: 			return kv.Value, nil
113: 		}
114: 	}
115: 	return nil, ErrNotFound
116: }
117: // Set stores a value in the key-value store
118: func (m *MemoryStorage) Set(ctx context.Context, key string, value []byte, expiration time.Duration) error {
119: 	if key == "" {
120: 		return ErrInvalidKey
121: 	}
122: 	if value == nil {
123: 		return ErrInvalidValue
124: 	}
125: 	// Calculate expiration time
126: 	var expireTime time.Time
127: 	if expiration > 0 {
128: 		expireTime = time.Now().Add(expiration)
129: 	}
130: 	// Store the value
131: 	shard := m.getShard(key)
132: 	shard.Store(key, KeyValue{
133: 		Value:      value,
134: 		Expiration: expireTime,
135: 	})
136: 	// Update stats
137: 	m.statsMu.Lock()
138: 	m.stats.TotalItems++
139: 	m.statsMu.Unlock()
140: 	return nil
141: }
142: // Delete removes a key from the key-value store
143: func (m *MemoryStorage) Delete(ctx context.Context, key string) error {
144: 	if key == "" {
145: 		return ErrInvalidKey
146: 	}
147: 	shard := m.getShard(key)
148: 	if _, ok := shard.Load(key); ok {
149: 		shard.Delete(key)
150: 		// Update stats
151: 		m.statsMu.Lock()
152: 		m.stats.TotalItems--
153: 		m.statsMu.Unlock()
154: 		return nil
155: 	}
156: 	return ErrNotFound
157: }
158: // GetDialog retrieves a dialog
159: func (m *MemoryStorage) GetDialog(ctx context.Context, callID string) (*Dialog, error) {
160: 	if callID == "" {
161: 		return nil, ErrInvalidKey
162: 	}
163: 	if value, ok := m.dialogs.Load(callID); ok {
164: 		dialog := value.(*Dialog)
165: 		// Check expiration
166: 		if !dialog.ExpireTime.IsZero() && dialog.ExpireTime.Before(time.Now()) {
167: 			m.dialogs.Delete(callID)
168: 			// Update stats
169: 			m.statsMu.Lock()
170: 			m.stats.DialogCount--
171: 			m.stats.ExpiredItems++
172: 			m.statsMu.Unlock()
173: 			return nil, ErrKeyExpired
174: 		}
175: 		return dialog, nil
176: 	}
177: 	return nil, ErrNotFound
178: }
179: // StoreDialog saves a dialog
180: func (m *MemoryStorage) StoreDialog(ctx context.Context, dialog *Dialog) error {
181: 	if dialog == nil || dialog.CallID == "" {
182: 		return ErrInvalidValue
183: 	}
184: 	// Update timestamps
185: 	dialog.UpdateTime = time.Now()
186: 	if dialog.CreateTime.IsZero() {
187: 		dialog.CreateTime = dialog.UpdateTime
188: 	}
189: 	// Set expiration if not already set
190: 	if dialog.ExpireTime.IsZero() {
191: 		dialog.ExpireTime = time.Now().Add(24 * time.Hour)
192: 	}
193: 	// Check if this is a new dialog
194: 	_, exists := m.dialogs.Load(dialog.CallID)
195: 	// Store the dialog
196: 	m.dialogs.Store(dialog.CallID, dialog)
197: 	// Update stats
198: 	if !exists {
199: 		m.statsMu.Lock()
200: 		m.stats.DialogCount++
201: 		m.statsMu.Unlock()
202: 	}
203: 	return nil
204: }
205: // DeleteDialog removes a dialog
206: func (m *MemoryStorage) DeleteDialog(ctx context.Context, callID string) error {
207: 	if callID == "" {
208: 		return ErrInvalidKey
209: 	}
210: 	if _, ok := m.dialogs.Load(callID); ok {
211: 		m.dialogs.Delete(callID)
212: 		// Update stats
213: 		m.statsMu.Lock()
214: 		m.stats.DialogCount--
215: 		m.statsMu.Unlock()
216: 		return nil
217: 	}
218: 	return ErrNotFound
219: }
220: // GetRTPSession retrieves an RTPEngine session
221: func (m *MemoryStorage) GetRTPSession(ctx context.Context, callID string) (*RTPSession, error) {
222: 	if callID == "" {
223: 		return nil, ErrInvalidKey
224: 	}
225: 	if value, ok := m.rtpSessions.Load(callID); ok {
226: 		session := value.(*RTPSession)
227: 		// Check expiration
228: 		if !session.ExpireTime.IsZero() && session.ExpireTime.Before(time.Now()) {
229: 			m.rtpSessions.Delete(callID)
230: 			// Update stats
231: 			m.statsMu.Lock()
232: 			m.stats.RTPSessionCount--
233: 			m.stats.ExpiredItems++
234: 			m.statsMu.Unlock()
235: 			return nil, ErrKeyExpired
236: 		}
237: 		return session, nil
238: 	}
239: 	return nil, ErrNotFound
240: }
241: // StoreRTPSession saves an RTPEngine session
242: func (m *MemoryStorage) StoreRTPSession(ctx context.Context, session *RTPSession) error {
243: 	if session == nil || session.CallID == "" {
244: 		return ErrInvalidValue
245: 	}
246: 	// Update timestamps
247: 	session.Updated = time.Now()
248: 	if session.Created.IsZero() {
249: 		session.Created = session.Updated
250: 	}
251: 	// Set expiration if not already set
252: 	if session.ExpireTime.IsZero() {
253: 		session.ExpireTime = time.Now().Add(24 * time.Hour)
254: 	}
255: 	// Check if this is a new session
256: 	_, exists := m.rtpSessions.Load(session.CallID)
257: 	// Store the session
258: 	m.rtpSessions.Store(session.CallID, session)
259: 	// Update stats
260: 	if !exists {
261: 		m.statsMu.Lock()
262: 		m.stats.RTPSessionCount++
263: 		m.statsMu.Unlock()
264: 	}
265: 	return nil
266: }
267: // DeleteRTPSession removes an RTPEngine session
268: func (m *MemoryStorage) DeleteRTPSession(ctx context.Context, callID string) error {
269: 	if callID == "" {
270: 		return ErrInvalidKey
271: 	}
272: 	if _, ok := m.rtpSessions.Load(callID); ok {
273: 		m.rtpSessions.Delete(callID)
274: 		// Update stats
275: 		m.statsMu.Lock()
276: 		m.stats.RTPSessionCount--
277: 		m.statsMu.Unlock()
278: 		return nil
279: 	}
280: 	return ErrNotFound
281: }
282: // GetAMIAction retrieves an AMI action
283: func (m *MemoryStorage) GetAMIAction(ctx context.Context, actionID string) (*AMIAction, error) {
284: 	if actionID == "" {
285: 		return nil, ErrInvalidKey
286: 	}
287: 	if value, ok := m.amiActions.Load(actionID); ok {
288: 		action := value.(*AMIAction)
289: 		// Check expiration
290: 		if !action.ExpireTime.IsZero() && action.ExpireTime.Before(time.Now()) {
291: 			m.amiActions.Delete(actionID)
292: 			// Update stats
293: 			m.statsMu.Lock()
294: 			m.stats.AMIActionCount--
295: 			m.stats.ExpiredItems++
296: 			m.statsMu.Unlock()
297: 			return nil, ErrKeyExpired
298: 		}
299: 		return action, nil
300: 	}
301: 	return nil, ErrNotFound
302: }
303: // StoreAMIAction saves an AMI action
304: func (m *MemoryStorage) StoreAMIAction(ctx context.Context, action *AMIAction) error {
305: 	if action == nil || action.ActionID == "" {
306: 		return ErrInvalidValue
307: 	}
308: 	// Update timestamp
309: 	if action.Timestamp.IsZero() {
310: 		action.Timestamp = time.Now()
311: 	}
312: 	// Set expiration if not already set
313: 	if action.ExpireTime.IsZero() {
314: 		action.ExpireTime = time.Now().Add(1 * time.Hour)
315: 	}
316: 	// Check if this is a new action
317: 	_, exists := m.amiActions.Load(action.ActionID)
318: 	// Store the action
319: 	m.amiActions.Store(action.ActionID, action)
320: 	// Update stats
321: 	if !exists {
322: 		m.statsMu.Lock()
323: 		m.stats.AMIActionCount++
324: 		m.statsMu.Unlock()
325: 	}
326: 	return nil
327: }
328: // DeleteAMIAction removes an AMI action
329: func (m *MemoryStorage) DeleteAMIAction(ctx context.Context, actionID string) error {
330: 	if actionID == "" {
331: 		return ErrInvalidKey
332: 	}
333: 	if _, ok := m.amiActions.Load(actionID); ok {
334: 		m.amiActions.Delete(actionID)
335: 		// Update stats
336: 		m.statsMu.Lock()
337: 		m.stats.AMIActionCount--
338: 		m.statsMu.Unlock()
339: 		return nil
340: 	}
341: 	return ErrNotFound
342: }
343: // GetClientSession retrieves a client session
344: func (m *MemoryStorage) GetClientSession(ctx context.Context, clientID string) (*ClientSession, error) {
345: 	if clientID == "" {
346: 		return nil, ErrInvalidKey
347: 	}
348: 	if value, ok := m.clientSessions.Load(clientID); ok {
349: 		session := value.(*ClientSession)
350: 		// Check expiration
351: 		if !session.ExpireTime.IsZero() && session.ExpireTime.Before(time.Now()) {
352: 			m.clientSessions.Delete(clientID)
353: 			// Update stats
354: 			m.statsMu.Lock()
355: 			m.stats.ClientCount--
356: 			m.stats.ExpiredItems++
357: 			m.statsMu.Unlock()
358: 			return nil, ErrKeyExpired
359: 		}
360: 		return session, nil
361: 	}
362: 	return nil, ErrNotFound
363: }
364: // StoreClientSession saves a client session
365: func (m *MemoryStorage) StoreClientSession(ctx context.Context, session *ClientSession) error {
366: 	if session == nil || session.ClientID == "" {
367: 		return ErrInvalidValue
368: 	}
369: 	// Update timestamps
370: 	session.LastSeen = time.Now()
371: 	if session.CreateTime.IsZero() {
372: 		session.CreateTime = session.LastSeen
373: 	}
374: 	// Set expiration if not already set
375: 	if session.ExpireTime.IsZero() {
376: 		session.ExpireTime = time.Now().Add(24 * time.Hour)
377: 	}
378: 	// Check if this is a new session
379: 	_, exists := m.clientSessions.Load(session.ClientID)
380: 	// Store the session
381: 	m.clientSessions.Store(session.ClientID, session)
382: 	// Update stats
383: 	if !exists {
384: 		m.statsMu.Lock()
385: 		m.stats.ClientCount++
386: 		m.statsMu.Unlock()
387: 	}
388: 	return nil
389: }
390: // DeleteClientSession removes a client session
391: func (m *MemoryStorage) DeleteClientSession(ctx context.Context, clientID string) error {
392: 	if clientID == "" {
393: 		return ErrInvalidKey
394: 	}
395: 	if _, ok := m.clientSessions.Load(clientID); ok {
396: 		m.clientSessions.Delete(clientID)
397: 		// Update stats
398: 		m.statsMu.Lock()
399: 		m.stats.ClientCount--
400: 		m.statsMu.Unlock()
401: 		return nil
402: 	}
403: 	return ErrNotFound
404: }
405: // GetWSConnection retrieves WebSocket connection info
406: func (m *MemoryStorage) GetWSConnection(ctx context.Context, clientID string) (*WSConnectionInfo, error) {
407: 	if clientID == "" {
408: 		return nil, ErrInvalidKey
409: 	}
410: 	if value, ok := m.wsConnections.Load(clientID); ok {
411: 		info := value.(*WSConnectionInfo)
412: 		// Check expiration
413: 		if !info.ExpireTime.IsZero() && info.ExpireTime.Before(time.Now()) {
414: 			m.wsConnections.Delete(clientID)
415: 			// Update stats
416: 			m.statsMu.Lock()
417: 			m.stats.WSConnCount--
418: 			m.stats.ExpiredItems++
419: 			m.statsMu.Unlock()
420: 			return nil, ErrKeyExpired
421: 		}
422: 		return info, nil
423: 	}
424: 	return nil, ErrNotFound
425: }
426: // StoreWSConnection saves WebSocket connection info
427: func (m *MemoryStorage) StoreWSConnection(ctx context.Context, clientID string, info *WSConnectionInfo) error {
428: 	if clientID == "" || info == nil {
429: 		return ErrInvalidValue
430: 	}
431: 	// Update timestamps
432: 	info.LastSeen = time.Now()
433: 	if info.Created.IsZero() {
434: 		info.Created = info.LastSeen
435: 	}
436: 	// Set expiration if not already set
437: 	if info.ExpireTime.IsZero() {
438: 		info.ExpireTime = time.Now().Add(1 * time.Hour)
439: 	}
440: 	// Check if this is a new connection
441: 	_, exists := m.wsConnections.Load(clientID)
442: 	// Store the connection info
443: 	m.wsConnections.Store(clientID, info)
444: 	// Update stats
445: 	if !exists {
446: 		m.statsMu.Lock()
447: 		m.stats.WSConnCount++
448: 		m.statsMu.Unlock()
449: 	}
450: 	return nil
451: }
452: // DeleteWSConnection removes WebSocket connection info
453: func (m *MemoryStorage) DeleteWSConnection(ctx context.Context, clientID string) error {
454: 	if clientID == "" {
455: 		return ErrInvalidKey
456: 	}
457: 	if _, ok := m.wsConnections.Load(clientID); ok {
458: 		m.wsConnections.Delete(clientID)
459: 		// Update stats
460: 		m.statsMu.Lock()
461: 		m.stats.WSConnCount--
462: 		m.statsMu.Unlock()
463: 		return nil
464: 	}
465: 	return ErrNotFound
466: }
467: // ListAMIActionIDs returns a list of all AMI action IDs
468: func (m *MemoryStorage) ListAMIActionIDs(ctx context.Context) ([]string, error) {
469: 	var actionIDs []string
470: 	m.amiActions.Range(func(key, value interface{}) bool {
471: 		actionID := key.(string)
472: 		action := value.(*AMIAction)
473: 		// Skip expired actions
474: 		if !action.ExpireTime.IsZero() && action.ExpireTime.Before(time.Now()) {
475: 			m.amiActions.Delete(key)
476: 			// Update stats
477: 			m.statsMu.Lock()
478: 			m.stats.AMIActionCount--
479: 			m.stats.ExpiredItems++
480: 			m.statsMu.Unlock()
481: 			return true
482: 		}
483: 		actionIDs = append(actionIDs, actionID)
484: 		return true
485: 	})
486: 	return actionIDs, nil
487: }
488: // GetRegistration retrieves a SIP registration
489: func (m *MemoryStorage) GetRegistration(ctx context.Context, aor string) (*Registration, error) {
490: 	if aor == "" {
491: 		return nil, ErrInvalidKey
492: 	}
493: 	if value, ok := m.registrations.Load(aor); ok {
494: 		reg := value.(*Registration)
495: 		// Check expiration
496: 		if reg.ExpireTime.Before(time.Now()) {
497: 			m.registrations.Delete(aor)
498: 			// Update stats
499: 			m.statsMu.Lock()
500: 			m.stats.RegCount--
501: 			m.stats.ExpiredItems++
502: 			m.statsMu.Unlock()
503: 			return nil, ErrKeyExpired
504: 		}
505: 		return reg, nil
506: 	}
507: 	return nil, ErrNotFound
508: }
509: // StoreRegistration saves a SIP registration
510: func (m *MemoryStorage) StoreRegistration(ctx context.Context, reg *Registration) error {
511: 	if reg == nil || reg.AOR == "" {
512: 		return ErrInvalidValue
513: 	}
514: 	// Update timestamps
515: 	if reg.RegisterTime.IsZero() {
516: 		reg.RegisterTime = time.Now()
517: 	}
518: 	// Calculate expiration time
519: 	if reg.ExpireTime.IsZero() {
520: 		reg.ExpireTime = time.Now().Add(time.Duration(reg.Expires) * time.Second)
521: 	}
522: 	// Check if this is a new registration
523: 	_, exists := m.registrations.Load(reg.AOR)
524: 	// Store the registration
525: 	m.registrations.Store(reg.AOR, reg)
526: 	// Update stats
527: 	if !exists {
528: 		m.statsMu.Lock()
529: 		m.stats.RegCount++
530: 		m.statsMu.Unlock()
531: 	}
532: 	return nil
533: }
534: // DeleteRegistration removes a SIP registration
535: func (m *MemoryStorage) DeleteRegistration(ctx context.Context, aor string) error {
536: 	if aor == "" {
537: 		return ErrInvalidKey
538: 	}
539: 	if _, ok := m.registrations.Load(aor); ok {
540: 		m.registrations.Delete(aor)
541: 		// Update stats
542: 		m.statsMu.Lock()
543: 		m.stats.RegCount--
544: 		m.statsMu.Unlock()
545: 		return nil
546: 	}
547: 	return ErrNotFound
548: }
549: // ListDialogs returns a list of all dialogs
550: func (m *MemoryStorage) ListDialogs(ctx context.Context) ([]*Dialog, error) {
551: 	var dialogs []*Dialog
552: 	m.dialogs.Range(func(key, value interface{}) bool {
553: 		dialog := value.(*Dialog)
554: 		// Skip expired dialogs
555: 		if !dialog.ExpireTime.IsZero() && dialog.ExpireTime.Before(time.Now()) {
556: 			m.dialogs.Delete(key)
557: 			// Update stats
558: 			m.statsMu.Lock()
559: 			m.stats.DialogCount--
560: 			m.stats.ExpiredItems++
561: 			m.statsMu.Unlock()
562: 			return true
563: 		}
564: 		dialogs = append(dialogs, dialog)
565: 		return true
566: 	})
567: 	return dialogs, nil
568: }
569: // ListRTPSessions returns a list of all RTP sessions
570: func (m *MemoryStorage) ListRTPSessions(ctx context.Context) ([]*RTPSession, error) {
571: 	var sessions []*RTPSession
572: 	m.rtpSessions.Range(func(key, value interface{}) bool {
573: 		session := value.(*RTPSession)
574: 		// Skip expired sessions
575: 		if !session.ExpireTime.IsZero() && session.ExpireTime.Before(time.Now()) {
576: 			m.rtpSessions.Delete(key)
577: 			// Update stats
578: 			m.statsMu.Lock()
579: 			m.stats.RTPSessionCount--
580: 			m.stats.ExpiredItems++
581: 			m.statsMu.Unlock()
582: 			return true
583: 		}
584: 		sessions = append(sessions, session)
585: 		return true
586: 	})
587: 	return sessions, nil
588: }
589: // ListClientSessions returns a list of all client sessions
590: func (m *MemoryStorage) ListClientSessions(ctx context.Context) ([]*ClientSession, error) {
591: 	var sessions []*ClientSession
592: 	m.clientSessions.Range(func(key, value interface{}) bool {
593: 		session := value.(*ClientSession)
594: 		// Skip expired sessions
595: 		if !session.ExpireTime.IsZero() && session.ExpireTime.Before(time.Now()) {
596: 			m.clientSessions.Delete(key)
597: 			// Update stats
598: 			m.statsMu.Lock()
599: 			m.stats.ClientCount--
600: 			m.stats.ExpiredItems++
601: 			m.statsMu.Unlock()
602: 			return true
603: 		}
604: 		sessions = append(sessions, session)
605: 		return true
606: 	})
607: 	return sessions, nil
608: }
609: // ListRegistrations returns a list of all registrations
610: func (m *MemoryStorage) ListRegistrations(ctx context.Context) ([]*Registration, error) {
611: 	var registrations []*Registration
612: 	m.registrations.Range(func(key, value interface{}) bool {
613: 		reg := value.(*Registration)
614: 		// Skip expired registrations
615: 		if reg.ExpireTime.Before(time.Now()) {
616: 			m.registrations.Delete(key)
617: 			// Update stats
618: 			m.statsMu.Lock()
619: 			m.stats.RegCount--
620: 			m.stats.ExpiredItems++
621: 			m.statsMu.Unlock()
622: 			return true
623: 		}
624: 		registrations = append(registrations, reg)
625: 		return true
626: 	})
627: 	return registrations, nil
628: }
629: // Ping performs a health check - always healthy for in-memory
630: func (m *MemoryStorage) Ping(ctx context.Context) error {
631: 	return nil
632: }
633: // Stats returns storage statistics
634: func (m *MemoryStorage) Stats(ctx context.Context) (*StorageStats, error) {
635: 	m.statsMu.RLock()
636: 	defer m.statsMu.RUnlock()
637: 	// Create a copy of the stats
638: 	stats := StorageStats{
639: 		TotalItems:      m.stats.TotalItems,
640: 		DialogCount:     m.stats.DialogCount,
641: 		RTPSessionCount: m.stats.RTPSessionCount,
642: 		AMIActionCount:  m.stats.AMIActionCount,
643: 		ClientCount:     m.stats.ClientCount,
644: 		WSConnCount:     m.stats.WSConnCount,
645: 		RegCount:        m.stats.RegCount,
646: 		ExpiredItems:    m.stats.ExpiredItems,
647: 		EvictedItems:    m.stats.EvictedItems,
648: 	}
649: 	return &stats, nil
650: }
651: // Cleanup removes expired items
652: func (m *MemoryStorage) Cleanup(ctx context.Context) error {
653: 	// Clean up general key-value store
654: 	for i := 0; i < m.shardCount; i++ {
655: 		shard := m.data[i]
656: 		// Create a list of keys to delete to avoid modifying while iterating
657: 		var keysToDelete []interface{}
658: 		shard.Range(func(key, value interface{}) bool {
659: 			if kv, ok := value.(KeyValue); ok {
660: 				if !kv.Expiration.IsZero() && kv.Expiration.Before(time.Now()) {
661: 					keysToDelete = append(keysToDelete, key)
662: 				}
663: 			}
664: 			return true
665: 		})
666: 		// Delete expired keys
667: 		for _, key := range keysToDelete {
668: 			shard.Delete(key)
669: 			// Update stats
670: 			m.statsMu.Lock()
671: 			m.stats.TotalItems--
672: 			m.stats.ExpiredItems++
673: 			m.statsMu.Unlock()
674: 		}
675: 	}
676: 	// Clean up specialized stores - each store handles its own expiration in its List methods
677: 	_, _ = m.ListDialogs(ctx)
678: 	_, _ = m.ListRTPSessions(ctx)
679: 	_, _ = m.ListClientSessions(ctx)
680: 	_, _ = m.ListRegistrations(ctx)
681: 	m.logger.Debug("Cleanup completed",
682: 		zap.Int("expiredItems", m.stats.ExpiredItems),
683: 		zap.Int("totalItems", m.stats.TotalItems))
684: 	return nil
685: }
686: func (m *MemoryStorage) Close() error {
687: 	close(m.stopCleanup)
688: 	<-m.cleanupDone
689: 	if m.persistOnShutdown && m.persistPath != "" {
690: 		if err := m.persistToFile(); err != nil {
691: 			m.logger.Error("Failed to persist data", zap.Error(err))
692: 			return err
693: 		}
694: 	}
695: 	return nil
696: }
697: func (m *MemoryStorage) cleanupLoop() {
698: 	defer close(m.cleanupDone)
699: 	ticker := time.NewTicker(m.cleanupInterval)
700: 	defer ticker.Stop()
701: 	for {
702: 		select {
703: 		case <-m.stopCleanup:
704: 			m.logger.Debug("Cleanup loop stopped")
705: 			return
706: 		case <-ticker.C:
707: 			m.Cleanup(context.Background())
708: 		}
709: 	}
710: }
711: func (m *MemoryStorage) persistToFile() error {
712: 	dir := filepath.Dir(m.persistPath)
713: 	if err := os.MkdirAll(dir, 0755); err != nil {
714: 		return fmt.Errorf("failed to create directory: %w", err)
715: 	}
716: 	tempFile := m.persistPath + ".tmp"
717: 	file, err := os.Create(tempFile)
718: 	if err != nil {
719: 		return fmt.Errorf("failed to create temp file: %w", err)
720: 	}
721: 	defer file.Close()
722: 	encoder := json.NewEncoder(file)
723: 	if err := encoder.Encode(map[string]interface{}{
724: 		"version":   1,
725: 		"stats":     m.stats,
726: 		"timestamp": time.Now(),
727: 	}); err != nil {
728: 		return fmt.Errorf("failed to encode header: %w", err)
729: 	}
730: 	dialogs, _ := m.ListDialogs(context.Background())
731: 	if err := encoder.Encode(dialogs); err != nil {
732: 		return fmt.Errorf("failed to encode dialogs: %w", err)
733: 	}
734: 	rtpSessions, _ := m.ListRTPSessions(context.Background())
735: 	if err := encoder.Encode(rtpSessions); err != nil {
736: 		return fmt.Errorf("failed to encode RTP sessions: %w", err)
737: 	}
738: 	clientSessions, _ := m.ListClientSessions(context.Background())
739: 	if err := encoder.Encode(clientSessions); err != nil {
740: 		return fmt.Errorf("failed to encode client sessions: %w", err)
741: 	}
742: 	registrations, _ := m.ListRegistrations(context.Background())
743: 	if err := encoder.Encode(registrations); err != nil {
744: 		return fmt.Errorf("failed to encode registrations: %w", err)
745: 	}
746: 	var amiActions []*AMIAction
747: 	m.amiActions.Range(func(key, value interface{}) bool {
748: 		action := value.(*AMIAction)
749: 		if !action.ExpireTime.IsZero() && !action.ExpireTime.Before(time.Now()) {
750: 			amiActions = append(amiActions, action)
751: 		}
752: 		return true
753: 	})
754: 	if err := encoder.Encode(amiActions); err != nil {
755: 		return fmt.Errorf("failed to encode AMI actions: %w", err)
756: 	}
757: 	file.Close()
758: 	if err := os.Rename(tempFile, m.persistPath); err != nil {
759: 		return fmt.Errorf("failed to rename file: %w", err)
760: 	}
761: 	m.logger.Info("Data persisted to file",
762: 		zap.String("path", m.persistPath),
763: 		zap.Int("dialogs", len(dialogs)),
764: 		zap.Int("rtpSessions", len(rtpSessions)),
765: 		zap.Int("clientSessions", len(clientSessions)),
766: 		zap.Int("registrations", len(registrations)),
767: 		zap.Int("amiActions", len(amiActions)))
768: 	return nil
769: }
770: func (m *MemoryStorage) loadFromFile() error {
771: 	if _, err := os.Stat(m.persistPath); os.IsNotExist(err) {
772: 		return nil
773: 	}
774: 	file, err := os.Open(m.persistPath)
775: 	if err != nil {
776: 		return fmt.Errorf("failed to open file: %w", err)
777: 	}
778: 	defer file.Close()
779: 	decoder := json.NewDecoder(file)
780: 	var header map[string]interface{}
781: 	if err := decoder.Decode(&header); err != nil {
782: 		return fmt.Errorf("failed to decode header: %w", err)
783: 	}
784: 	var dialogs []*Dialog
785: 	if err := decoder.Decode(&dialogs); err != nil {
786: 		return fmt.Errorf("failed to decode dialogs: %w", err)
787: 	}
788: 	var rtpSessions []*RTPSession
789: 	if err := decoder.Decode(&rtpSessions); err != nil {
790: 		return fmt.Errorf("failed to decode RTP sessions: %w", err)
791: 	}
792: 	var clientSessions []*ClientSession
793: 	if err := decoder.Decode(&clientSessions); err != nil {
794: 		return fmt.Errorf("failed to decode client sessions: %w", err)
795: 	}
796: 	var registrations []*Registration
797: 	if err := decoder.Decode(&registrations); err != nil {
798: 		return fmt.Errorf("failed to decode registrations: %w", err)
799: 	}
800: 	var amiActions []*AMIAction
801: 	if err := decoder.Decode(&amiActions); err != nil {
802: 		return fmt.Errorf("failed to decode AMI actions: %w", err)
803: 	}
804: 	for _, dialog := range dialogs {
805: 		if dialog.ExpireTime.IsZero() || !dialog.ExpireTime.Before(time.Now()) {
806: 			m.dialogs.Store(dialog.CallID, dialog)
807: 			m.statsMu.Lock()
808: 			m.stats.DialogCount++
809: 			m.statsMu.Unlock()
810: 		}
811: 	}
812: 	for _, session := range rtpSessions {
813: 		if session.ExpireTime.IsZero() || !session.ExpireTime.Before(time.Now()) {
814: 			m.rtpSessions.Store(session.CallID, session)
815: 			m.statsMu.Lock()
816: 			m.stats.RTPSessionCount++
817: 			m.statsMu.Unlock()
818: 		}
819: 	}
820: 	for _, session := range clientSessions {
821: 		if session.ExpireTime.IsZero() || !session.ExpireTime.Before(time.Now()) {
822: 			m.clientSessions.Store(session.ClientID, session)
823: 			m.statsMu.Lock()
824: 			m.stats.ClientCount++
825: 			m.statsMu.Unlock()
826: 		}
827: 	}
828: 	for _, reg := range registrations {
829: 		if !reg.ExpireTime.Before(time.Now()) {
830: 			m.registrations.Store(reg.AOR, reg)
831: 			m.statsMu.Lock()
832: 			m.stats.RegCount++
833: 			m.statsMu.Unlock()
834: 		}
835: 	}
836: 	for _, action := range amiActions {
837: 		if action.ExpireTime.IsZero() || !action.ExpireTime.Before(time.Now()) {
838: 			m.amiActions.Store(action.ActionID, action)
839: 			m.statsMu.Lock()
840: 			m.stats.AMIActionCount++
841: 			m.statsMu.Unlock()
842: 		}
843: 	}
844: 	m.logger.Info("Data loaded from file",
845: 		zap.String("path", m.persistPath),
846: 		zap.Int("dialogs", m.stats.DialogCount),
847: 		zap.Int("rtpSessions", m.stats.RTPSessionCount),
848: 		zap.Int("clientSessions", m.stats.ClientCount),
849: 		zap.Int("registrations", m.stats.RegCount),
850: 		zap.Int("amiActions", m.stats.AMIActionCount))
851: 	return nil
852: }
</file>

<file path="gateway/pkg/storage/storage.go">
  1: package storage
  2: import (
  3: 	"context"
  4: 	"encoding/json"
  5: 	"errors"
  6: 	"time"
  7: )
  8: var (
  9: 	ErrNotFound      = errors.New("item not found")
 10: 	ErrAlreadyExists = errors.New("item already exists")
 11: 	ErrInvalidKey    = errors.New("invalid key")
 12: 	ErrInvalidValue  = errors.New("invalid value")
 13: 	ErrStorageFull   = errors.New("storage is full")
 14: 	ErrKeyExpired    = errors.New("key expired")
 15: )
 16: type KeyValue struct {
 17: 	Value      []byte
 18: 	Expiration time.Time
 19: }
 20: type Dialog struct {
 21: 	CallID       string            `json:"call_id"`
 22: 	FromTag      string            `json:"from_tag"`
 23: 	ToTag        string            `json:"to_tag,omitempty"`
 24: 	State        string            `json:"state"`
 25: 	Route        []string          `json:"route,omitempty"`
 26: 	RemoteSeq    int               `json:"remote_seq,omitempty"`
 27: 	LocalSeq     int               `json:"local_seq,omitempty"`
 28: 	RemoteURI    string            `json:"remote_uri,omitempty"`
 29: 	LocalURI     string            `json:"local_uri,omitempty"`
 30: 	RemoteTarget string            `json:"remote_target,omitempty"`
 31: 	CreateTime   time.Time         `json:"create_time"`
 32: 	UpdateTime   time.Time         `json:"update_time"`
 33: 	ExpireTime   time.Time         `json:"expire_time,omitempty"`
 34: 	Data         map[string]string `json:"data,omitempty"`
 35: }
 36: type RTPSession struct {
 37: 	CallID     string    `json:"call_id"`
 38: 	EngineIdx  int       `json:"engine_idx"`
 39: 	EngineAddr string    `json:"engine_addr,omitempty"`
 40: 	FromTag    string    `json:"from_tag"`
 41: 	ToTag      string    `json:"to_tag,omitempty"`
 42: 	MediaInfo  string    `json:"media_info,omitempty"`
 43: 	Created    time.Time `json:"created"`
 44: 	Updated    time.Time `json:"updated"`
 45: 	ExpireTime time.Time `json:"expire_time,omitempty"`
 46: }
 47: type AMIAction struct {
 48: 	ActionID   string            `json:"action_id"`
 49: 	Command    string            `json:"command"`
 50: 	Params     map[string]string `json:"params,omitempty"`
 51: 	ClientID   string            `json:"client_id"`
 52: 	Timestamp  time.Time         `json:"timestamp"`
 53: 	Retries    int               `json:"retries"`
 54: 	ExpireTime time.Time         `json:"expire_time,omitempty"`
 55: }
 56: type ClientSession struct {
 57: 	ClientID   string            `json:"client_id"`
 58: 	UserAgent  string            `json:"user_agent,omitempty"`
 59: 	SIPAddress string            `json:"sip_address,omitempty"`
 60: 	CallIDs    []string          `json:"call_ids,omitempty"`
 61: 	CreateTime time.Time         `json:"create_time"`
 62: 	LastSeen   time.Time         `json:"last_seen"`
 63: 	ExpireTime time.Time         `json:"expire_time,omitempty"`
 64: 	Data       map[string]string `json:"data,omitempty"`
 65: }
 66: type WSConnectionInfo struct {
 67: 	ClientID   string    `json:"client_id"`
 68: 	ServerAddr string    `json:"server_addr"`
 69: 	RemoteAddr string    `json:"remote_addr"`
 70: 	Protocol   string    `json:"protocol,omitempty"`
 71: 	Created    time.Time `json:"created"`
 72: 	LastSeen   time.Time `json:"last_seen"`
 73: 	ExpireTime time.Time `json:"expire_time,omitempty"`
 74: }
 75: type Registration struct {
 76: 	AOR          string    `json:"aor"`
 77: 	Contact      string    `json:"contact"`
 78: 	Expires      int       `json:"expires"`
 79: 	UserAgent    string    `json:"user_agent,omitempty"`
 80: 	CallID       string    `json:"call_id,omitempty"`
 81: 	CSeq         int       `json:"cseq,omitempty"`
 82: 	RegisterTime time.Time `json:"register_time"`
 83: 	ExpireTime   time.Time `json:"expire_time"`
 84: }
 85: type StorageStats struct {
 86: 	TotalItems      int `json:"total_items"`
 87: 	DialogCount     int `json:"dialog_count"`
 88: 	RTPSessionCount int `json:"rtp_session_count"`
 89: 	AMIActionCount  int `json:"ami_action_count"`
 90: 	ClientCount     int `json:"client_count"`
 91: 	WSConnCount     int `json:"ws_conn_count"`
 92: 	RegCount        int `json:"reg_count"`
 93: 	ExpiredItems    int `json:"expired_items"`
 94: 	EvictedItems    int `json:"evicted_items"`
 95: }
 96: type StateStorage interface {
 97: 	Get(ctx context.Context, key string) ([]byte, error)
 98: 	Set(ctx context.Context, key string, value []byte, expiration time.Duration) error
 99: 	Delete(ctx context.Context, key string) error
100: 	GetDialog(ctx context.Context, callID string) (*Dialog, error)
101: 	StoreDialog(ctx context.Context, dialog *Dialog) error
102: 	DeleteDialog(ctx context.Context, callID string) error
103: 	GetRTPSession(ctx context.Context, callID string) (*RTPSession, error)
104: 	StoreRTPSession(ctx context.Context, session *RTPSession) error
105: 	DeleteRTPSession(ctx context.Context, callID string) error
106: 	GetAMIAction(ctx context.Context, actionID string) (*AMIAction, error)
107: 	StoreAMIAction(ctx context.Context, action *AMIAction) error
108: 	DeleteAMIAction(ctx context.Context, actionID string) error
109: 	GetClientSession(ctx context.Context, clientID string) (*ClientSession, error)
110: 	StoreClientSession(ctx context.Context, session *ClientSession) error
111: 	DeleteClientSession(ctx context.Context, clientID string) error
112: 	GetWSConnection(ctx context.Context, clientID string) (*WSConnectionInfo, error)
113: 	StoreWSConnection(ctx context.Context, clientID string, info *WSConnectionInfo) error
114: 	DeleteWSConnection(ctx context.Context, clientID string) error
115: 	GetRegistration(ctx context.Context, aor string) (*Registration, error)
116: 	StoreRegistration(ctx context.Context, reg *Registration) error
117: 	DeleteRegistration(ctx context.Context, aor string) error
118: 	ListDialogs(ctx context.Context) ([]*Dialog, error)
119: 	ListRTPSessions(ctx context.Context) ([]*RTPSession, error)
120: 	ListClientSessions(ctx context.Context) ([]*ClientSession, error)
121: 	ListRegistrations(ctx context.Context) ([]*Registration, error)
122: 	Ping(ctx context.Context) error
123: 	Stats(ctx context.Context) (*StorageStats, error)
124: 	Cleanup(ctx context.Context) error
125: 	Close() error
126: 	ListAMIActionIDs(ctx context.Context) ([]string, error)
127: }
128: func marshalJSON(v interface{}) ([]byte, error) {
129: 	return json.Marshal(v)
130: }
131: func unmarshalJSON(data []byte, v interface{}) error {
132: 	return json.Unmarshal(data, v)
133: }
</file>

<file path="gateway/pkg/websocket/server.go">
   1: package websocket
   2: import (
   3: 	"context"
   4: 	"crypto/tls"
   5: 	"encoding/json"
   6: 	"fmt"
   7: 	"net"
   8: 	"net/http"
   9: 	"os"
  10: 	"strings"
  11: 	"sync"
  12: 	"time"
  13: 	"github.com/gorilla/websocket"
  14: 	"gateway/pkg/common"
  15: 	"gateway/pkg/sip"
  16: 	"gateway/pkg/storage"
  17: 	"go.uber.org/zap"
  18: )
  19: type Server struct {
  20: 	config         ServerConfig
  21: 	upgrader       websocket.Upgrader
  22: 	httpServer     *http.Server
  23: 	storage        storage.StateStorage
  24: 	registry       *common.GoroutineRegistry
  25: 	handler        SIPHandler
  26: 	logger         *zap.Logger
  27: 	circuitBreaker *common.CircuitBreaker
  28: 	mu            sync.RWMutex
  29: 	connections   map[string]*ClientConnection
  30: 	wg            sync.WaitGroup
  31: 	backendHealth map[string]bool
  32: 	backendMu     sync.RWMutex
  33: }
  34: type ServerConfig struct {
  35: 	BindAddr             string
  36: 	CertFile             string
  37: 	KeyFile              string
  38: 	MaxConnections       int
  39: 	ReadTimeout          time.Duration
  40: 	WriteTimeout         time.Duration
  41: 	IdleTimeout          time.Duration
  42: 	EnableIPv4Only       bool
  43: 	ServerName           string
  44: 	BackendServers       []string
  45: 	FailoverThreshold    int
  46: 	DisableSIPProcessing bool
  47: 	DisableWSSIPProcessing bool
  48: }
  49: type SIPHandler interface {
  50: 	HandleMessage(msg sip.Message, addr net.Addr) error
  51: }
  52: type ClientConnection struct {
  53: 	ID               string
  54: 	Conn             *websocket.Conn
  55: 	RemoteAddr       string
  56: 	LocalAddr        string
  57: 	Protocol         string
  58: 	CreateTime       time.Time
  59: 	LastActivity     time.Time
  60: 	SIPAddress       string
  61: 	BackendConn      *websocket.Conn
  62: 	BackendAddr      string
  63: 	CurrentBackend   string
  64: 	ErrorCount       int
  65: 	LastSIPCallID    string
  66: 	LastSIPFromTag   string
  67: 	LastSIPToTag     string
  68: 	closed           bool
  69: 	closeMu          sync.Mutex
  70: 	clientDone       chan struct{}
  71: 	backendDone      chan struct{}
  72: 	cancelFunc       context.CancelFunc
  73: }
  74: func NewServer(config ServerConfig, storage storage.StateStorage, logger *zap.Logger) (*Server, error) {
  75: 	if logger == nil {
  76: 		var err error
  77: 		logger, err = zap.NewProduction()
  78: 		if err != nil {
  79: 			return nil, err
  80: 		}
  81: 	}
  82: 	if config.MaxConnections <= 0 {
  83: 		config.MaxConnections = 1000
  84: 	}
  85: 	if config.ReadTimeout <= 0 {
  86: 		config.ReadTimeout = 30 * time.Second
  87: 	}
  88: 	if config.WriteTimeout <= 0 {
  89: 		config.WriteTimeout = 30 * time.Second
  90: 	}
  91: 	if config.IdleTimeout <= 0 {
  92: 		config.IdleTimeout = 120 * time.Second
  93: 	}
  94: 	if config.ServerName == "" {
  95: 		config.ServerName = "WebRTC-SIP-Gateway"
  96: 	}
  97: 	if config.FailoverThreshold <= 0 {
  98: 		config.FailoverThreshold = 1
  99: 	}
 100: 	if len(config.BackendServers) == 0 && config.ServerName != "" {
 101: 		config.BackendServers = []string{config.ServerName}
 102: 	}
 103: 	logger.Info("Creating WebSocket server with configuration",
 104: 		zap.String("bindAddr", config.BindAddr),
 105: 		zap.String("serverName", config.ServerName),
 106: 		zap.Strings("backendServers", config.BackendServers),
 107: 		zap.Int("failoverThreshold", config.FailoverThreshold),
 108: 		zap.Bool("disableSIPProcessing", config.DisableSIPProcessing),
 109: 		zap.Bool("disableWSSIPProcessing", config.DisableWSSIPProcessing))
 110: 	backendHealth := make(map[string]bool)
 111: 	for _, backend := range config.BackendServers {
 112: 		backendHealth[backend] = true
 113: 	}
 114: 	server := &Server{
 115: 		config:        config,
 116: 		storage:       storage,
 117: 		registry:      common.NewGoroutineRegistry(logger),
 118: 		logger:        logger,
 119: 		connections:   make(map[string]*ClientConnection),
 120: 		backendHealth: backendHealth,
 121: 		upgrader: websocket.Upgrader{
 122: 			ReadBufferSize:  4096,
 123: 			WriteBufferSize: 4096,
 124: 			CheckOrigin: func(r *http.Request) bool {
 125: 				return true
 126: 			},
 127: 			Subprotocols: []string{"sip"},
 128: 		},
 129: 		circuitBreaker: common.NewCircuitBreaker(
 130: 			"websocket",
 131: 			common.CircuitBreakerConfig{
 132: 				FailureThreshold: 5,
 133: 				ResetTimeout:     30 * time.Second,
 134: 				HalfOpenMaxReqs:  3,
 135: 			},
 136: 			logger,
 137: 		),
 138: 	}
 139: 	return server, nil
 140: }
 141: func (s *Server) SetSIPHandler(handler SIPHandler) {
 142: 	s.handler = handler
 143: }
 144: func (s *Server) UpdateBackendHealth(backend string, healthy bool) {
 145: 	s.backendMu.Lock()
 146: 	defer s.backendMu.Unlock()
 147: 	s.backendHealth[backend] = healthy
 148: 	s.logger.Info("Backend health status updated",
 149: 		zap.String("backend", backend),
 150: 		zap.Bool("healthy", healthy))
 151: }
 152: func (s *Server) CheckBackendHealth(ctx context.Context) {
 153: 	for _, backend := range s.config.BackendServers {
 154: 		healthy := s.testBackendConnection(backend)
 155: 		s.UpdateBackendHealth(backend, healthy)
 156: 	}
 157: }
 158: func (s *Server) testBackendConnection(backend string) bool {
 159: 	if backend == "" {
 160: 		return false
 161: 	}
 162: 	// Ensure proper WebSocket URL format
 163: 	backendURL := backend
 164: 	if !strings.HasPrefix(backendURL, "ws") {
 165: 		backendURL = "wss://" + backendURL
 166: 	}
 167: 	dialer := websocket.Dialer{
 168: 		HandshakeTimeout: 5 * time.Second,
 169: 		TLSClientConfig: &tls.Config{
 170: 			InsecureSkipVerify: true,
 171: 		},
 172: 	}
 173: 	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
 174: 	defer cancel()
 175: 	headers := http.Header{}
 176: 	headers.Add("User-Agent", "QalqulVoiceGateway-HealthCheck/1.0")
 177: 	conn, _, err := dialer.DialContext(ctx, backendURL, headers)
 178: 	if err != nil {
 179: 		s.logger.Debug("Backend health check failed",
 180: 			zap.String("backend", backendURL),
 181: 			zap.Error(err))
 182: 		return false
 183: 	}
 184: 	conn.WriteMessage(websocket.CloseMessage,
 185: 		websocket.FormatCloseMessage(websocket.CloseNormalClosure, "Health check"))
 186: 	conn.Close()
 187: 	return true
 188: }
 189: func (s *Server) selectHealthyBackend() string {
 190: 	if len(s.config.BackendServers) == 0 {
 191: 		return s.config.ServerName
 192: 	}
 193: 	s.backendMu.RLock()
 194: 	defer s.backendMu.RUnlock()
 195: 	for _, backend := range s.config.BackendServers {
 196: 		if healthy, exists := s.backendHealth[backend]; exists && healthy {
 197: 			return backend
 198: 		}
 199: 	}
 200: 	return s.config.BackendServers[0]
 201: }
 202: func (s *Server) Start(ctx context.Context) error {
 203: 	s.logger.Info("Starting WebSocket server",
 204: 		zap.String("bindAddr", s.config.BindAddr),
 205: 		zap.Bool("tlsEnabled", s.config.CertFile != "" && s.config.KeyFile != ""),
 206: 		zap.Strings("backendServers", s.config.BackendServers),
 207: 		zap.Bool("disableWSSIPProcessing", s.config.DisableWSSIPProcessing))
 208: 	mux := http.NewServeMux()
 209: 	mux.HandleFunc("/", s.handleWebSocket)
 210: 	s.logger.Debug("Registered WebSocket handler at root path (/)")
 211: 	s.httpServer = &http.Server{
 212: 		Addr:         s.config.BindAddr,
 213: 		Handler:      mux,
 214: 		ReadTimeout:  s.config.ReadTimeout,
 215: 		WriteTimeout: s.config.WriteTimeout,
 216: 		IdleTimeout:  s.config.IdleTimeout,
 217: 	}
 218: 	s.logger.Debug("HTTP server configured",
 219: 		zap.String("bindAddr", s.config.BindAddr),
 220: 		zap.Duration("readTimeout", s.config.ReadTimeout),
 221: 		zap.Duration("writeTimeout", s.config.WriteTimeout),
 222: 		zap.Duration("idleTimeout", s.config.IdleTimeout),
 223: 	)
 224: 	s.registry.Go("connection-cleaner", func(ctx context.Context) {
 225: 		s.logger.Debug("Connection cleaner goroutine started")
 226: 		ticker := time.NewTicker(5 * time.Minute)
 227: 		defer ticker.Stop()
 228: 		s.StartHealthMonitoring(ctx)
 229: 		for {
 230: 			select {
 231: 			case <-ctx.Done():
 232: 				s.logger.Debug("Connection cleaner shutting down: context canceled")
 233: 				return
 234: 			case <-ticker.C:
 235: 				s.logger.Debug("Running scheduled connection cleanup")
 236: 				s.cleanConnections()
 237: 			}
 238: 		}
 239: 	})
 240: 	if len(s.config.BackendServers) > 0 {
 241: 		s.registry.Go("backend-health-checker", func(ctx context.Context) {
 242: 			ticker := time.NewTicker(30 * time.Second)
 243: 			defer ticker.Stop()
 244: 			for {
 245: 				select {
 246: 				case <-ctx.Done():
 247: 					s.logger.Debug("Backend health checker shutting down: context canceled")
 248: 					return
 249: 				case <-ticker.C:
 250: 					s.CheckBackendHealth(ctx)
 251: 				}
 252: 			}
 253: 		})
 254: 	}
 255: 	s.registry.Go("http-server", func(ctx context.Context) {
 256: 		s.logger.Debug("Starting HTTP server goroutine")
 257: 		var err error
 258: 		if s.config.CertFile != "" && s.config.KeyFile != "" {
 259: 			s.logger.Debug("Using TLS configuration",
 260: 				zap.String("certFile", s.config.CertFile),
 261: 				zap.String("keyFile", s.config.KeyFile),
 262: 			)
 263: 			if s.config.EnableIPv4Only {
 264: 				s.logger.Debug("Creating IPv4-only listener")
 265: 				ln, err := net.Listen("tcp4", s.config.BindAddr)
 266: 				if err != nil {
 267: 					s.logger.Error("Failed to create IPv4 listener", zap.Error(err))
 268: 					return
 269: 				}
 270: 				s.logger.Debug("Successfully created IPv4 listener",
 271: 					zap.String("localAddress", ln.Addr().String()),
 272: 				)
 273: 				s.logger.Debug("Loading TLS certificate")
 274: 				cert, err := tls.LoadX509KeyPair(s.config.CertFile, s.config.KeyFile)
 275: 				if err != nil {
 276: 					s.logger.Error("Failed to load TLS certificate", zap.Error(err))
 277: 					return
 278: 				}
 279: 				tlsConfig := &tls.Config{
 280: 					Certificates: []tls.Certificate{cert},
 281: 					MinVersion:   tls.VersionTLS12,
 282: 				}
 283: 				s.httpServer.TLSConfig = tlsConfig
 284: 				s.logger.Info("Starting TLS server on IPv4 listener")
 285: 				err = s.httpServer.ServeTLS(ln, "", "")
 286: 			} else {
 287: 				s.logger.Info("Starting TLS server with IPv4/IPv6 support")
 288: 				err = s.httpServer.ListenAndServeTLS(s.config.CertFile, s.config.KeyFile)
 289: 			}
 290: 		} else {
 291: 			s.logger.Info("Starting non-TLS server")
 292: 			if s.config.EnableIPv4Only {
 293: 				s.logger.Debug("Creating IPv4-only listener (non-TLS)")
 294: 				ln, err := net.Listen("tcp4", s.config.BindAddr)
 295: 				if err != nil {
 296: 					s.logger.Error("Failed to create IPv4 listener (non-TLS)",
 297: 						zap.Error(err),
 298: 					)
 299: 					return
 300: 				}
 301: 				s.logger.Debug("Starting non-TLS server on IPv4 listener")
 302: 				err = s.httpServer.Serve(ln)
 303: 			} else {
 304: 				s.logger.Debug("Starting non-TLS server with IPv4/IPv6 support")
 305: 				err = s.httpServer.ListenAndServe()
 306: 			}
 307: 		}
 308: 		if err != nil && err != http.ErrServerClosed {
 309: 			s.logger.Error("HTTP server failed with error", zap.Error(err))
 310: 			if opErr, ok := err.(*net.OpError); ok {
 311: 				s.logger.Error("Network operation error details",
 312: 					zap.String("op", opErr.Op),
 313: 					zap.String("net", opErr.Net),
 314: 					zap.Any("addr", opErr.Addr),
 315: 					zap.Bool("timeout", opErr.Timeout()),
 316: 					zap.Bool("temporary", opErr.Temporary()),
 317: 				)
 318: 			}
 319: 		} else if err == http.ErrServerClosed {
 320: 			s.logger.Info("WebSocket server closed normally")
 321: 		}
 322: 	})
 323: 	s.logger.Info("WebSocket server initialization complete")
 324: 	return nil
 325: }
 326: func (s *Server) Stop() error {
 327: 	s.logger.Info("Stopping WebSocket server")
 328: 	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
 329: 	defer cancel()
 330: 	if err := s.httpServer.Shutdown(ctx); err != nil {
 331: 		s.logger.Error("HTTP server shutdown failed", zap.Error(err))
 332: 	}
 333: 	s.closeAllConnections()
 334: 	s.wg.Wait()
 335: 	return s.registry.Shutdown(30 * time.Second)
 336: }
 337: func (s *Server) handleWebSocket(w http.ResponseWriter, r *http.Request) {
 338: 	clientAddr := r.RemoteAddr
 339: 	s.logger.Debug("Incoming WebSocket handshake request",
 340: 		zap.String("client", clientAddr),
 341: 		zap.String("url", r.URL.String()),
 342: 		zap.String("path", r.URL.Path),
 343: 		zap.String("userAgent", r.UserAgent()),
 344: 	)
 345: 	s.mu.RLock()
 346: 	if len(s.connections) >= s.config.MaxConnections {
 347: 		s.mu.RUnlock()
 348: 		s.logger.Warn("Connection rejected: too many connections",
 349: 			zap.String("client", clientAddr),
 350: 			zap.Int("maxConnections", s.config.MaxConnections),
 351: 		)
 352: 		http.Error(w, "Too many connections", http.StatusServiceUnavailable)
 353: 		return
 354: 	}
 355: 	s.mu.RUnlock()
 356: 	if !s.circuitBreaker.AllowRequest() {
 357: 		s.logger.Warn("Connection rejected: circuit breaker open",
 358: 			zap.String("client", clientAddr),
 359: 		)
 360: 		http.Error(w, "Service temporarily unavailable", http.StatusServiceUnavailable)
 361: 		return
 362: 	}
 363: 	clientSubProtocols := websocket.Subprotocols(r)
 364: 	sipTransport := "wss"
 365: 	if r.TLS == nil {
 366: 		sipTransport = "ws"
 367: 	}
 368: 	if transportParam := r.URL.Query().Get("transport"); transportParam != "" {
 369: 		sipTransport = transportParam
 370: 	}
 371: 	s.logger.Debug("SIP protocol details",
 372: 		zap.String("client", clientAddr),
 373: 		zap.Strings("subprotocols", clientSubProtocols),
 374: 		zap.String("sipTransport", sipTransport),
 375: 	)
 376: 	if !websocket.IsWebSocketUpgrade(r) {
 377: 		s.logger.Warn("Not a valid WebSocket upgrade request",
 378: 			zap.String("client", clientAddr),
 379: 		)
 380: 		http.Error(w, "Not a WebSocket handshake", http.StatusBadRequest)
 381: 		return
 382: 	}
 383: 	var protocols []string
 384: 	if len(clientSubProtocols) > 0 {
 385: 		protocols = clientSubProtocols
 386: 	} else {
 387: 		protocols = []string{"sip"}
 388: 	}
 389: 	s.upgrader.Subprotocols = protocols
 390: 	conn, err := s.upgrader.Upgrade(w, r, nil)
 391: 	if err != nil {
 392: 		s.logger.Error("WebSocket upgrade failed",
 393: 			zap.String("remoteAddr", clientAddr),
 394: 			zap.Error(err),
 395: 		)
 396: 		s.circuitBreaker.RecordFailure()
 397: 		return
 398: 	}
 399: 	conn.SetWriteDeadline(time.Now().Add(30 * time.Second))
 400: 	clientID := fmt.Sprintf("%s-%d", clientAddr, time.Now().UnixNano())
 401: 	wsCtx, wsCancel := context.WithCancel(context.Background())
 402: 	client := &ClientConnection{
 403: 		ID:             clientID,
 404: 		Conn:           conn,
 405: 		RemoteAddr:     clientAddr,
 406: 		LocalAddr:      r.Host,
 407: 		Protocol:       conn.Subprotocol(),
 408: 		CreateTime:     time.Now(),
 409: 		LastActivity:   time.Now(),
 410: 		clientDone:     make(chan struct{}),
 411: 		backendDone:    make(chan struct{}),
 412: 		cancelFunc:     wsCancel,
 413: 		ErrorCount:     0,
 414: 	}
 415: 	s.mu.Lock()
 416: 	s.connections[clientID] = client
 417: 	s.mu.Unlock()
 418: 	ctx := context.Background()
 419: 	s.storage.Set(ctx, "ws:"+clientID, []byte(clientAddr), 1*time.Hour)
 420: 	s.logger.Info("WebSocket connection established",
 421: 		zap.String("clientID", clientID),
 422: 		zap.String("remoteAddr", clientAddr),
 423: 		zap.String("protocol", client.Protocol),
 424: 		zap.String("sipTransport", sipTransport),
 425: 	)
 426: 	s.wg.Add(1)
 427: 	go func() {
 428: 		defer s.wg.Done()
 429: 		conn.SetWriteDeadline(time.Time{})
 430: 		s.handleClient(wsCtx, client, sipTransport)
 431: 	}()
 432: 	s.circuitBreaker.RecordSuccess()
 433: }
 434: func (s *Server) handleClient(ctx context.Context, client *ClientConnection, sipTransport string) {
 435: 	defer s.closeConnection(client)
 436: 	errChan := make(chan error, 3)
 437: 	backendURL := s.selectHealthyBackend()
 438: 	if backendURL == "" {
 439: 		// This is a serious error - no backends available
 440: 		s.logger.Error("No healthy backends available",
 441: 			zap.String("clientID", client.ID))
 442: 		return
 443: 	}
 444: 	s.logger.Debug("Establishing backend connection",
 445: 		zap.String("clientID", client.ID),
 446: 		zap.String("backend", backendURL),
 447: 	)
 448: 	backendConn, resp, err := s.connectToBackend(backendURL, client)
 449: 	if err != nil {
 450: 		s.logger.Error("Failed to connect to backend",
 451: 			zap.String("clientID", client.ID),
 452: 			zap.String("backend", backendURL),
 453: 			zap.Error(err),
 454: 		)
 455: 		if resp != nil {
 456: 			s.logger.Error("Backend response details",
 457: 				zap.Int("statusCode", resp.StatusCode),
 458: 				zap.String("status", resp.Status),
 459: 				zap.Any("headers", resp.Header),
 460: 			)
 461: 		}
 462: 		return
 463: 	}
 464: 	client.BackendConn = backendConn
 465: 	client.BackendAddr = backendURL
 466: 	client.CurrentBackend = backendURL
 467: 	s.logger.Info("Established backend connection",
 468: 		zap.String("clientID", client.ID),
 469: 		zap.String("backend", backendURL),
 470: 	)
 471: 	clientOptionsTicker := time.NewTicker(30 * time.Second)
 472: 	defer clientOptionsTicker.Stop()
 473: 	s.wg.Add(1)
 474: 	go func() {
 475: 		defer s.wg.Done()
 476: 		for {
 477: 			select {
 478: 			case <-ctx.Done():
 479: 				s.logger.Debug("Keepalive routine stopping - context done",
 480: 					zap.String("client", client.ID),
 481: 				)
 482: 				return
 483: 			case <-client.clientDone:
 484: 				s.logger.Debug("Keepalive routine stopping - client done",
 485: 					zap.String("client", client.ID),
 486: 				)
 487: 				return
 488: 			case <-clientOptionsTicker.C:
 489: 				optionsMsg := s.buildSipOptionsKeepAlive(client.RemoteAddr, backendURL)
 490: 				client.closeMu.Lock()
 491: 				if client.closed {
 492: 					client.closeMu.Unlock()
 493: 					return
 494: 				}
 495: 				if err := client.Conn.WriteMessage(websocket.TextMessage, []byte(optionsMsg)); err != nil {
 496: 					s.logger.Debug("Failed to send SIP OPTIONS keepalive to client",
 497: 						zap.String("error", err.Error()),
 498: 						zap.String("client", client.ID),
 499: 					)
 500: 					client.closeMu.Unlock()
 501: 					return
 502: 				}
 503: 				client.closeMu.Unlock()
 504: 				s.logger.Debug("Sent SIP OPTIONS keepalive to client",
 505: 					zap.String("client", client.ID),
 506: 				)
 507: 			}
 508: 		}
 509: 	}()
 510: 	s.wg.Add(1)
 511: 	go func() {
 512: 		defer s.wg.Done()
 513: 		defer close(client.clientDone)
 514: 		for {
 515: 			select {
 516: 			case <-ctx.Done():
 517: 				s.logger.Debug("Client reader stopping - context done",
 518: 					zap.String("client", client.ID),
 519: 				)
 520: 				return
 521: 			default:
 522: 				client.Conn.SetReadDeadline(time.Now().Add(2 * time.Hour))
 523: 				msgType, msg, err := client.Conn.ReadMessage()
 524: 				if err != nil {
 525: 					if websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
 526: 						s.logger.Debug("Client closed connection normally",
 527: 							zap.String("client", client.ID),
 528: 						)
 529: 					} else {
 530: 						s.logger.Debug("WebSocket read error",
 531: 							zap.String("client", client.ID),
 532: 							zap.Error(err),
 533: 						)
 534: 						errChan <- fmt.Errorf("client read: %w", err)
 535: 					}
 536: 					return
 537: 				}
 538: 				client.LastActivity = time.Now()
 539: 				msgTypeStr := msgTypeToString(msgType)
 540: 				s.logger.Debug("Received message from client",
 541: 					zap.String("client", client.ID),
 542: 					zap.String("msgType", msgTypeStr),
 543: 					zap.Int("length", len(msg)),
 544: 				)
 545: 				if (msgType == websocket.TextMessage || msgType == websocket.BinaryMessage) && len(msg) > 0 {
 546: 					sipMsg, parseErr := sip.ParseMessage(msg)
 547: 					if parseErr == nil && sipMsg != nil {
 548: 						s.extractSIPState(sipMsg, client)
 549: 					}
 550: 				}
 551: 				if client.BackendConn != nil {
 552: 					err = client.BackendConn.WriteMessage(msgType, msg)
 553: 					if err != nil {
 554: 						s.logger.Error("Failed to forward message to backend",
 555: 							zap.String("client", client.ID),
 556: 							zap.String("backend", client.CurrentBackend),
 557: 							zap.Error(err),
 558: 						)
 559: 						client.ErrorCount++
 560: 						if client.ErrorCount >= s.config.FailoverThreshold {
 561: 							s.logger.Warn("Backend error threshold reached, attempting failover",
 562: 								zap.String("clientID", client.ID),
 563: 								zap.String("currentBackend", client.CurrentBackend),
 564: 								zap.Int("errorCount", client.ErrorCount),
 565: 								zap.Int("threshold", s.config.FailoverThreshold))
 566: 							s.UpdateBackendHealth(client.CurrentBackend, false)
 567: 							newBackendURL := s.selectHealthyBackend()
 568: 							if newBackendURL != "" && newBackendURL != client.CurrentBackend {
 569: 								newConn, _, connErr := s.connectToBackend(newBackendURL, client)
 570: 								if connErr == nil {
 571: 									s.logger.Info("Successfully connected to new backend after failover",
 572: 										zap.String("clientID", client.ID),
 573: 										zap.String("oldBackend", client.CurrentBackend),
 574: 										zap.String("newBackend", newBackendURL))
 575: 									client.BackendConn.Close()
 576: 									client.BackendConn = newConn
 577: 									client.BackendAddr = newBackendURL
 578: 									client.CurrentBackend = newBackendURL
 579: 									client.ErrorCount = 0
 580: 									if retryErr := newConn.WriteMessage(msgType, msg); retryErr != nil {
 581: 										s.logger.Error("Failed to forward message to new backend after failover",
 582: 											zap.String("clientID", client.ID),
 583: 											zap.Error(retryErr))
 584: 									} else {
 585: 										s.logger.Debug("Successfully forwarded message to new backend after failover",
 586: 											zap.String("clientID", client.ID),
 587: 											zap.String("backend", newBackendURL))
 588: 									}
 589: 									continue
 590: 								} else {
 591: 									s.logger.Error("Failed to connect to new backend during failover",
 592: 										zap.String("clientID", client.ID),
 593: 										zap.String("newBackend", newBackendURL),
 594: 										zap.Error(connErr))
 595: 								}
 596: 							} else {
 597: 								s.logger.Error("No alternative backend available for failover",
 598: 									zap.String("clientID", client.ID),
 599: 									zap.String("currentBackend", client.CurrentBackend))
 600: 							}
 601: 						}
 602: 						errChan <- fmt.Errorf("backend write: %w", err)
 603: 						return
 604: 					}
 605: 					client.ErrorCount = 0
 606: 					s.logger.Debug("Forwarded message to backend",
 607: 						zap.String("client", client.ID),
 608: 						zap.String("backend", client.BackendAddr),
 609: 						zap.Int("length", len(msg)),
 610: 					)
 611: 				}
 612: 				if (msgType == websocket.TextMessage || msgType == websocket.BinaryMessage) && len(msg) > 0 {
 613: 					sipMsg, parseErr := sip.ParseMessage(msg)
 614: 					if parseErr == nil {
 615: 						if req, ok := sipMsg.(*sip.Request); ok {
 616: 							if req.From() != nil {
 617: 								client.SIPAddress = req.From().Address.String()
 618: 								if s.handler != nil && !s.config.DisableWSSIPProcessing {
 619: 									addr := &websocketAddr{
 620: 										clientID: client.ID,
 621: 										network:  sipTransport,
 622: 										address:  client.RemoteAddr,
 623: 									}
 624: 									s.logger.Debug("Processing SIP message from WebSocket",
 625: 										zap.String("clientID", client.ID),
 626: 										zap.String("method", req.Method.String()),
 627: 										zap.Bool("DisableWSSIPProcessing", s.config.DisableWSSIPProcessing))
 628: 									if err := s.handler.HandleMessage(sipMsg, addr); err != nil {
 629: 										s.logger.Error("SIP handler error",
 630: 											zap.String("clientID", client.ID),
 631: 											zap.Error(err),
 632: 										)
 633: 									}
 634: 								} else {
 635: 									s.logger.Debug("Skipping SIP processing (disabled by config)",
 636: 										zap.String("clientID", client.ID),
 637: 										zap.Bool("DisableWSSIPProcessing", s.config.DisableWSSIPProcessing))
 638: 								}
 639: 							}
 640: 						}
 641: 					}
 642: 				}
 643: 			}
 644: 		}
 645: 	}()
 646: 	s.wg.Add(1)
 647: 	go func() {
 648: 		defer s.wg.Done()
 649: 		defer close(client.backendDone)
 650: 		for {
 651: 			select {
 652: 			case <-ctx.Done():
 653: 				s.logger.Debug("Backend reader stopping - context done",
 654: 					zap.String("client", client.ID),
 655: 				)
 656: 				return
 657: 			case <-client.clientDone:
 658: 				s.logger.Debug("Backend reader stopping - client done",
 659: 					zap.String("client", client.ID),
 660: 				)
 661: 				return
 662: 			default:
 663: 				client.BackendConn.SetReadDeadline(time.Now().Add(2 * time.Hour))
 664: 				msgType, msg, err := client.BackendConn.ReadMessage()
 665: 				if err != nil {
 666: 					if websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
 667: 						s.logger.Debug("Backend closed connection normally",
 668: 							zap.String("client", client.ID),
 669: 							zap.String("backend", client.BackendAddr),
 670: 						)
 671: 					} else {
 672: 						s.logger.Debug("Backend read error",
 673: 							zap.String("client", client.ID),
 674: 							zap.String("backend", client.BackendAddr),
 675: 							zap.Error(err),
 676: 						)
 677: 						client.ErrorCount++
 678: 						if client.ErrorCount >= s.config.FailoverThreshold {
 679: 							s.logger.Warn("Backend read error threshold reached, attempting failover",
 680: 								zap.String("clientID", client.ID),
 681: 								zap.String("currentBackend", client.CurrentBackend),
 682: 								zap.Int("errorCount", client.ErrorCount),
 683: 								zap.Int("threshold", s.config.FailoverThreshold))
 684: 							s.UpdateBackendHealth(client.CurrentBackend, false)
 685: 							newBackendURL := s.selectHealthyBackend()
 686: 							if newBackendURL != "" && newBackendURL != client.CurrentBackend {
 687: 								newConn, _, connErr := s.connectToBackend(newBackendURL, client)
 688: 								if connErr == nil {
 689: 									s.logger.Info("Successfully connected to new backend after read error",
 690: 										zap.String("clientID", client.ID),
 691: 										zap.String("oldBackend", client.CurrentBackend),
 692: 										zap.String("newBackend", newBackendURL))
 693: 									client.BackendConn = newConn
 694: 									client.BackendAddr = newBackendURL
 695: 									client.CurrentBackend = newBackendURL
 696: 									client.ErrorCount = 0
 697: 									continue
 698: 								}
 699: 							}
 700: 						}
 701: 						errChan <- fmt.Errorf("backend read: %w", err)
 702: 					}
 703: 					return
 704: 				}
 705: 				client.closeMu.Lock()
 706: 				if client.closed {
 707: 					client.closeMu.Unlock()
 708: 					return
 709: 				}
 710: 				err = client.Conn.WriteMessage(msgType, msg)
 711: 				client.closeMu.Unlock()
 712: 				if err != nil {
 713: 					s.logger.Debug("Failed to forward backend message to client",
 714: 						zap.String("client", client.ID),
 715: 						zap.Error(err),
 716: 					)
 717: 					errChan <- fmt.Errorf("client write: %w", err)
 718: 					return
 719: 				}
 720: 				s.logger.Debug("Forwarded message from backend to client",
 721: 					zap.String("client", client.ID),
 722: 					zap.String("msgType", msgTypeToString(msgType)),
 723: 					zap.Int("length", len(msg)),
 724: 				)
 725: 			}
 726: 		}
 727: 	}()
 728: 	select {
 729: 	case <-ctx.Done():
 730: 		s.logger.Debug("Context done, closing WebSocket",
 731: 			zap.String("client", client.ID),
 732: 		)
 733: 		return
 734: 	case err := <-errChan:
 735: 		s.logger.Debug("WebSocket error, closing connection",
 736: 			zap.String("client", client.ID),
 737: 			zap.Error(err),
 738: 		)
 739: 		return
 740: 	}
 741: }
 742: func (s *Server) connectToBackend(backendURL string, client *ClientConnection) (*websocket.Conn, *http.Response, error) {
 743: 	if !strings.HasPrefix(backendURL, "ws") {
 744: 		backendURL = "wss://" + backendURL
 745: 	}
 746: 	backendHeaders := http.Header{}
 747: 	host := strings.Split(strings.TrimPrefix(strings.TrimPrefix(backendURL, "wss://"), "ws://"), ":")[0]
 748: 	backendHeaders.Add("Origin", "https://"+host)
 749: 	backendHeaders.Add("Host", host)
 750: 	backendHeaders.Add("User-Agent", "QalqulVoiceGateway/1.0")
 751: 	if client.LastSIPCallID != "" {
 752: 		backendHeaders.Add("X-SIP-Call-ID", client.LastSIPCallID)
 753: 	}
 754: 	if client.LastSIPFromTag != "" {
 755: 		backendHeaders.Add("X-SIP-From-Tag", client.LastSIPFromTag)
 756: 	}
 757: 	if client.LastSIPToTag != "" {
 758: 		backendHeaders.Add("X-SIP-To-Tag", client.LastSIPToTag)
 759: 	}
 760: 	s.logger.Debug("Connecting to backend with headers",
 761: 		zap.String("backendURL", backendURL),
 762: 		zap.Any("headers", backendHeaders),
 763: 	)
 764: 	dialer := websocket.Dialer{
 765: 		TLSClientConfig: &tls.Config{
 766: 			InsecureSkipVerify: true,
 767: 		},
 768: 		HandshakeTimeout: 10 * time.Second,
 769: 		Subprotocols:     []string{client.Protocol},
 770: 	}
 771: 	fmt.Fprintf(os.Stderr, "CONSOLE: Attempting backend connection to %s\n", backendURL)
 772: 	conn, resp, err := dialer.Dial(backendURL, backendHeaders)
 773: 	if err != nil {
 774: 		fmt.Fprintf(os.Stderr, "CONSOLE ERROR: Backend connection failed: %v\n", err)
 775: 		return nil, resp, err
 776: 	}
 777: 	return conn, resp, nil
 778: }
 779: func (s *Server) extractSIPState(sipMsg sip.Message, client *ClientConnection) {
 780:     if req, ok := sipMsg.(*sip.Request); ok {
 781:         if callID := req.CallID(); callID != nil {
 782:             client.LastSIPCallID = callID.Value()
 783:         }
 784:         if from := req.From(); from != nil && from.Params != nil {
 785:             if tag, exists := from.Params.Get("tag"); exists && tag != "" {
 786:                 client.LastSIPFromTag = tag
 787:             }
 788:         }
 789:         // Extract To tag
 790:         if to := req.To(); to != nil && to.Params != nil {
 791:             if tag, exists := to.Params.Get("tag"); exists && tag != "" {
 792:                 client.LastSIPToTag = tag
 793:             }
 794:         }
 795:         // Store SIP identity in storage for recovery purposes
 796:         if client.LastSIPCallID != "" {
 797:             ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
 798:             defer cancel()
 799:             stateKey := fmt.Sprintf("sip:session:%s", client.LastSIPCallID)
 800:             stateData := map[string]string{
 801:                 "clientID": client.ID,
 802:                 "callID": client.LastSIPCallID,
 803:                 "fromTag": client.LastSIPFromTag,
 804:                 "toTag": client.LastSIPToTag,
 805:                 "backend": client.CurrentBackend,
 806:                 "timestamp": fmt.Sprintf("%d", time.Now().Unix()),
 807:             }
 808:             jsonBytes, err := json.Marshal(stateData)
 809:             if err == nil {
 810:                 s.storage.Set(ctx, stateKey, jsonBytes, 1*time.Hour)
 811:             }
 812:         }
 813:     }
 814: }
 815: type websocketAddr struct {
 816: 	clientID string
 817: 	network  string
 818: 	address  string
 819: }
 820: func (a *websocketAddr) Network() string {
 821: 	return a.network
 822: }
 823: func (a *websocketAddr) String() string {
 824: 	return a.address
 825: }
 826: func (s *Server) SendMessage(ctx context.Context, clientID string, msg []byte) error {
 827: 	ctx, cancel := common.QuickTimeout(context.Background())
 828: 	defer cancel()
 829: 	s.mu.RLock()
 830: 	client, ok := s.connections[clientID]
 831: 	s.mu.RUnlock()
 832: 	if !ok {
 833: 		return fmt.Errorf("client not found: %s", clientID)
 834: 	}
 835: 	client.closeMu.Lock()
 836: 	defer client.closeMu.Unlock()
 837: 	if client.closed {
 838: 		return fmt.Errorf("connection closed")
 839: 	}
 840: 	client.Conn.SetWriteDeadline(time.Now().Add(10 * time.Second))
 841: 	return client.Conn.WriteMessage(websocket.TextMessage, msg)
 842: }
 843: func (s *Server) PrepareForFailover() {
 844: 	s.logger.Info("Preparing clients for potential failover")
 845: 	s.mu.RLock()
 846: 	clients := make([]*ClientConnection, 0, len(s.connections))
 847: 	for _, client := range s.connections {
 848: 		clients = append(clients, client)
 849: 	}
 850: 	s.mu.RUnlock()
 851: 	failoverData := map[string]interface{}{
 852: 		"event":     "system-notification",
 853: 		"type":      "failover-preparation",
 854: 		"message":   "Server maintenance imminent, please prepare for reconnection",
 855: 		"timestamp": time.Now().Unix(),
 856: 	}
 857: 	jsonBytes, err := json.Marshal(failoverData)
 858: 	if err != nil {
 859: 		s.logger.Error("Failed to encode failover message", zap.Error(err))
 860: 		return
 861: 	}
 862: 	for _, client := range clients {
 863: 		client.closeMu.Lock()
 864: 		if !client.closed {
 865: 			client.Conn.SetWriteDeadline(time.Now().Add(5 * time.Second))
 866: 			err := client.Conn.WriteMessage(websocket.TextMessage, jsonBytes)
 867: 			if err != nil {
 868: 				s.logger.Warn("Failed to send failover notification",
 869: 					zap.String("clientID", client.ID),
 870: 					zap.Error(err),
 871: 				)
 872: 			}
 873: 		}
 874: 		client.closeMu.Unlock()
 875: 	}
 876: }
 877: func (s *Server) RedirectClient(clientID string, newServerAddr string) error {
 878: 	s.mu.RLock()
 879: 	client, ok := s.connections[clientID]
 880: 	s.mu.RUnlock()
 881: 	if !ok {
 882: 		return fmt.Errorf("client not found: %s", clientID)
 883: 	}
 884: 	redirectData := map[string]interface{}{
 885: 		"event":      "system-redirect",
 886: 		"serverAddr": newServerAddr,
 887: 		"timestamp":  time.Now().Unix(),
 888: 	}
 889: 	jsonBytes, err := json.Marshal(redirectData)
 890: 	if err != nil {
 891: 		return fmt.Errorf("failed to encode redirect message: %w", err)
 892: 	}
 893: 	client.closeMu.Lock()
 894: 	defer client.closeMu.Unlock()
 895: 	if client.closed {
 896: 		return fmt.Errorf("connection closed")
 897: 	}
 898: 	client.Conn.SetWriteDeadline(time.Now().Add(5 * time.Second))
 899: 	return client.Conn.WriteMessage(websocket.TextMessage, jsonBytes)
 900: }
 901: func (s *Server) StartHealthMonitoring(ctx context.Context) {
 902: 	s.registry.Go("ws-health-monitor", func(ctx context.Context) {
 903: 		ticker := time.NewTicker(10 * time.Second)
 904: 		defer ticker.Stop()
 905: 		for {
 906: 			select {
 907: 			case <-ctx.Done():
 908: 				return
 909: 			case <-ticker.C:
 910: 				s.mu.RLock()
 911: 				connectionCount := len(s.connections)
 912: 				s.mu.RUnlock()
 913: 				healthData := map[string]interface{}{
 914: 					"addr":        s.config.BindAddr,
 915: 					"connections": connectionCount,
 916: 					"timestamp":   time.Now().Unix(),
 917: 					"status":      "healthy",
 918: 				}
 919: 				healthBytes, err := json.Marshal(healthData)
 920: 				if err != nil {
 921: 					s.logger.Error("Failed to encode health data", zap.Error(err))
 922: 					continue
 923: 				}
 924: 				hostname, _ := os.Hostname()
 925: 				healthKey := fmt.Sprintf("ws-health:%s", hostname)
 926: 				storeCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
 927: 				err = s.storage.Set(storeCtx, healthKey, healthBytes, 30*time.Second)
 928: 				cancel()
 929: 				if err != nil {
 930: 					s.logger.Error("Failed to store health data", zap.Error(err))
 931: 				}
 932: 			}
 933: 		}
 934: 	})
 935: }
 936: func (s *Server) HasHealthyBackends() bool {
 937:     s.backendMu.RLock()
 938:     defer s.backendMu.RUnlock()
 939:     for _, healthy := range s.backendHealth {
 940:         if healthy {
 941:             return true
 942:         }
 943:     }
 944:     return false
 945: }
 946: func (s *Server) closeConnection(client *ClientConnection) {
 947: 	client.closeMu.Lock()
 948: 	if client.closed {
 949: 		client.closeMu.Unlock()
 950: 		return
 951: 	}
 952: 	client.closed = true
 953: 	if client.cancelFunc != nil {
 954: 		client.cancelFunc()
 955: 	}
 956: 	client.closeMu.Unlock()
 957: 	closeMsg := websocket.FormatCloseMessage(websocket.CloseNormalClosure, "Connection closed")
 958: 	client.Conn.WriteControl(websocket.CloseMessage, closeMsg, time.Now().Add(5*time.Second))
 959: 	client.Conn.Close()
 960: 	if client.BackendConn != nil {
 961: 		client.BackendConn.WriteControl(websocket.CloseMessage, closeMsg, time.Now().Add(5*time.Second))
 962: 		client.BackendConn.Close()
 963: 	}
 964: 	s.mu.Lock()
 965: 	delete(s.connections, client.ID)
 966: 	s.mu.Unlock()
 967: 	ctx := context.Background()
 968: 	s.storage.Delete(ctx, "ws:"+client.ID)
 969: 	s.logger.Info("WebSocket connection closed",
 970: 		zap.String("clientID", client.ID),
 971: 		zap.String("remoteAddr", client.RemoteAddr),
 972: 	)
 973: }
 974: func (s *Server) closeAllConnections() {
 975: 	s.mu.Lock()
 976: 	clients := make([]*ClientConnection, 0, len(s.connections))
 977: 	for _, client := range s.connections {
 978: 		clients = append(clients, client)
 979: 	}
 980: 	s.mu.Unlock()
 981: 	s.logger.Info("Closing all WebSocket connections",
 982: 		zap.Int("connectionCount", len(clients)),
 983: 	)
 984: 	for _, client := range clients {
 985: 		s.closeConnection(client)
 986: 	}
 987: }
 988: func (s *Server) cleanConnections() {
 989: 	now := time.Now()
 990: 	threshold := now.Add(-30 * time.Minute)
 991: 	s.mu.Lock()
 992: 	var toClose []*ClientConnection
 993: 	for _, client := range s.connections {
 994: 		if client.LastActivity.Before(threshold) {
 995: 			toClose = append(toClose, client)
 996: 		}
 997: 	}
 998: 	s.mu.Unlock()
 999: 	for _, client := range toClose {
1000: 		s.logger.Warn("Closing inactive WebSocket connection",
1001: 			zap.String("clientID", client.ID),
1002: 			zap.Time("lastActivity", client.LastActivity),
1003: 			zap.Duration("inactive", now.Sub(client.LastActivity)),
1004: 		)
1005: 		s.closeConnection(client)
1006: 	}
1007: }
1008: func (s *Server) buildSipOptionsKeepAlive(clientAddr string, serverName string) string {
1009: 	callID := fmt.Sprintf("keepalive-%d", time.Now().UnixNano())
1010: 	branch := fmt.Sprintf("z9hG4bK-%d", time.Now().UnixNano())
1011: 	fromTag := fmt.Sprintf("fromTag-%d", time.Now().UnixNano())
1012: 	return fmt.Sprintf(
1013: 		`OPTIONS sip:keepalive@%s SIP/2.0
1014: Via: SIP/2.0/WSS %s;branch=%s;rport
1015: Max-Forwards: 70
1016: From: <sip:monitor@%s>;tag=%s
1017: To: <sip:keepalive@%s>
1018: Call-ID: %s
1019: CSeq: 1 OPTIONS
1020: User-Agent: %s
1021: Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, REFER, SUBSCRIBE, NOTIFY, INFO, PUBLISH, MESSAGE
1022: Supported: replaces, timer
1023: Content-Length: 0
1024: `,
1025: 		clientAddr,
1026: 		serverName,
1027: 		branch,
1028: 		serverName,
1029: 		fromTag,
1030: 		clientAddr,
1031: 		callID,
1032: 		s.config.ServerName,
1033: 	)
1034: }
1035: func msgTypeToString(mt int) string {
1036: 	switch mt {
1037: 	case websocket.TextMessage:
1038: 		return "text"
1039: 	case websocket.BinaryMessage:
1040: 		return "binary"
1041: 	case websocket.CloseMessage:
1042: 		return "close"
1043: 	case websocket.PingMessage:
1044: 		return "ping"
1045: 	case websocket.PongMessage:
1046: 		return "pong"
1047: 	default:
1048: 		return "unknown"
1049: 	}
1050: }
</file>

<file path="gateway/go.mod">
 1: module gateway
 2: 
 3: go 1.24.0
 4: 
 5: require (
 6: 	github.com/emiago/sipgo v0.30.0
 7: 	github.com/gorilla/websocket v1.5.3
 8: 	github.com/prometheus/client_golang v1.21.1
 9: 	github.com/zeebo/bencode v1.0.0
10: 	go.uber.org/zap v1.27.0
11: 	gopkg.in/yaml.v3 v3.0.1
12: )
13: 
14: require (
15: 	github.com/beorn7/perks v1.0.1 // indirect
16: 	github.com/cespare/xxhash/v2 v2.3.0 // indirect
17: 	github.com/gobwas/httphead v0.1.0 // indirect
18: 	github.com/gobwas/pool v0.2.1 // indirect
19: 	github.com/gobwas/ws v1.3.2 // indirect
20: 	github.com/google/uuid v1.6.0 // indirect
21: 	github.com/icholy/digest v0.1.22 // indirect
22: 	github.com/klauspost/compress v1.17.11 // indirect
23: 	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
24: 	github.com/prometheus/client_model v0.6.1 // indirect
25: 	github.com/prometheus/common v0.62.0 // indirect
26: 	github.com/prometheus/procfs v0.15.1 // indirect
27: 	github.com/satori/go.uuid v1.2.1-0.20181028125025-b2ce2384e17b // indirect
28: 	go.uber.org/multierr v1.10.0 // indirect
29: 	golang.org/x/sys v0.28.0 // indirect
30: 	google.golang.org/protobuf v1.36.1 // indirect
31: )
</file>

</files>
